{
  "title": "[DUBUCE] 1. laboratorijska vjeÅ¾ba - 2020/2021",
  "creator": "neZnamNista",
  "slug": "dubuce-1-laboratorijska-vjezba-20202021",
  "tags": [
    "FER",
    "Duboko uÄenje",
    "Laboratorijske vjeÅ¾be"
  ],
  "posts": {
    "155383": {
      "poster": "neZnamNista",
      "content": "je li predaja 1. labosa do cetvrtaka 25.3?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "155452": {
      "poster": "login",
      "content": "@neZnamNista#155383 Je.\n\n\"Studenti na provjeru trebaju donijeti otisnuti izvorni kod koji treba biti identiÄan kodu koji se predaje u Ferku do sljedeÄ‡eg Äetvrtka do kraja dana.\"",
      "votes": {
        "upvoters": [
          "neZnamNista"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "155530": {
      "poster": "Yasuke (Bono)",
      "content": "U drugom zadatku kad radimo klasifikaciju kako se izraÄuna dijagonalna matrica koja je Jakobijan zglobnice i koje se komponente gledaju kad je raÄunamo? Tu je uputa ali nisam bas skuzio iz nje.\n\n![](assets/2021-03-19/00020.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "155628": {
      "poster": "tonkec",
      "content": "@Yasuke#155530 uzmeÅ¡ jedan redak matrice s (s_i) i oni elementi koji su pozitivni u tom retku postaju jedinice u dijagonalnoj matrici, a inaÄe su nule",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "155846": {
      "poster": "tre_besty (luk)",
      "content": "@tonkec#155628 Kolike su dimenzije te diagonalne matrice onda? Jel za svaki redak matrice s1 stvaramo diagonalnu matricu ili imamo samo jednu diagonalnu matricu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "155944": {
      "poster": "tonkec",
      "content": "@tre_besty#155846 piÅ¡e ti u formuli da je parcijalno L po parcijalno s_i Å¡to znaÄi da moraÅ¡ za svaki redak imati posebnu matricu, a ona je dimenzija koliko i redak matrice s, vidiÅ¡ da iz mnoÅ¾enja matrice W_2 i diag mora biti dimenzija koliko W_2 ima stupaca kako bi matriÄni raÄun imao smisla",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "tre_besty (luk)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "155950": {
      "poster": "InCogNiTo124",
      "content": "@tonkec#155944 tako je, potvrdujem\n\nInace tips&tricks ne morate zaista konstruirat dijagonalnu matricu, jer kad budete generalizirali na batch_size >1 dobit cete tenzor treceg reda (ko matrica ali u kocku) i pogubit cete se\n\nRadije to implementirajte po definiciji kao elementwise mnozenje: tamo di je je aktivacija bila veca od nule, tamo gradient prolazi, odnosno dL_ds = (P-Y)â€¢W_2*(s > 0), di je â€¢ matrix product a * elementwise (ilitiga hadamard)",
      "votes": {
        "upvoters": [
          "Miskina666",
          "Vrba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "156046": {
      "poster": "orange",
      "content": "miÄ‡o je u labosu napisao `grad_loss_wrt_weights_1 = np.mean(x.T @ grad_loss_wrt_hidden, axis=0)` kod raÄunanja gradijenta Å¡to daje vektor Hx1, u pripremi piÅ¡e da se radi o matrici dimenzija HxD, a tako sam i ja implementirao. Zanima me ima li neki povod napraviti mean jer mi se Äini da daje bolje rezultate?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "156078": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "@orange#156046 mean ti daje manji gradijent (od npr. sum) koji je neovisan o veliÄini batcha\n\nSuma u nekim sluÄajevima moÅ¾e dovesti do brÅ¾e konvergencije ali to je bolje hendlati s adaptivnim stopama uÄenja, gradijent je koristan viÅ¡e manje samo za smjer kretnje\n\nAko taj gradijent ne odgovara shapeu weightova onda sam ja neÅ¡to sjebo xD, to mi je bio prvi susret s numpyjem i veÄ‡ vidim da ne bih ovak baÅ¡ stvari napisao danas. Svakako bi shape svakog gradijenta trebao biti jednak shapeu teÅ¾ina.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "orange"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "156993": {
      "poster": "login",
      "content": "Zanima me jedna stvar vezana uz prvi zadatak. Ako je to logisticka regresija koju implementiramo i dodajemo neki regularization loss, u strojnom ucenju smo i taj regularization loss derivirali kod trazenja gradijenata i ugradili ga u optimizacijski postupak. Sad kod neuronskih mreza ne znam kako bi to interpretirao. Pretpostavljam da ga ne treba ugradit u gradijente, al opet mi nije jasno kaj nam on tu tocno predstavlja, osim da ce ukupna greska bit tim veca sto je norma tezina veca",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157009": {
      "poster": "tonkec",
      "content": "@login#156993 pa Å¡to nije ugraÄ‘en kad raÄunaÅ¡ korak unazad kroz one sve matrice?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157038": {
      "poster": "login",
      "content": "Pa tipa ako gledamo ove izvode iz 1. labosa i ako na taj nacin racunamo greske, mislim da nije, il mi je nesto promaklo:\n\n![](assets/2021-03-23/00008.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157107": {
      "poster": "BigD",
      "content": "Jel itko zna odgovore na ona teorijska pitanja u 6.? Koji moÅ¾e primiti viÅ¡e parametara i koji daje garantirano bolju performansu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157121": {
      "poster": "[deleted]",
      "content": "@login#156993 [imath]L_1[/imath] i [imath]L_2[/imath] regularizacija, odnosno opÄ‡enito [imath]L^p[/imath] regularizacija, vuku svoje motivacije iz opaÅ¾anja da pretrenirani modeli imaju veliku amplitudu/normu slobodnih parametara (parametara koje treniraÅ¡) [Bishop 2006.]. BuduÄ‡i da ne Å¾elimo pretrenirane modele, onda ima smisla u gubitak dodati normu vektora slobodnih parametara (bez vektora pristranosti). Dakle, kada deriviraÅ¡ gubitak po vektorima parametara onda uzimaÅ¡ i gradijente po normi u obzir (jer se oni nalaze u gubitku), odnosno moraÅ¡ ih ukljuÄiti u gradijent jer se oni nalaze u gubitku.\n\nP.S. Nema razlike izmeÄ‘u algoritma logistiÄke regresije izmeÄ‘u kolegija strojnog uÄenja i dubokog uÄenja, to su isti algoritmi. Imaju istu funkciju pogreÅ¡ke, isti skup hipoteza (model) i isti optimizacijski postupak.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "login",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157160": {
      "poster": "MJ3",
      "content": "jel moÅ¾e netko napisat kakva su proÅ¡lih godina otprilike bila pitanja na blicu, jesu viÅ¡e vezana za raÄunanje ili se traÅ¾e objaÅ¡njenja i analize rezultata?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157170": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "@MJ3#157160 Nije bilo proÅ¡lih godina blica, sve je bila demonstracija + pitanje asistenata",
      "votes": {
        "upvoters": [
          "Fran_- (random_trooper)",
          "InCogNiTo124",
          "MJ3"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157327": {
      "poster": "BigD",
      "content": "Kod MNIST skupa treba li konvertirati ulazne podatke 29x29 u vektore 1x784, ili ima neki bolji naÄin?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157337": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "@BigD#157327 moÅ¾eÅ¡ i ne moraÅ¡\n\nnpr. ako imaÅ¡ 1x29x29 matricu, i na nju lupiÅ¡ linearni sloj od 64 neurona, dobit Ä‡eÅ¡ shape (1, 29, 64). Tek Ä‡eÅ¡ na kraju za klasifikaciju trebati spljoÅ¡Ä‡ivati stvari, a kako Ä‡eÅ¡ to tad raditi, bog zna\n\nNpr. arhitektura tipa\n\n```\nLinear(29, 64)\nReLU\nLinear(64, 10)\nSum(axis=1)\nSoftmax(axis=-1)\n```\n\nje totalno validna. Ako spljoÅ¡tiÅ¡ matricu u vektor na poÄetku imat Ä‡eÅ¡ viÅ¡e parametara i neÄ‡eÅ¡ trebati lupiti akumulacijsku funkciju da izgubiÅ¡ jednu os tenzora.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157350": {
      "poster": "BigD",
      "content": "S obzirom da svi bodovi dolaze od blica i programskog zadatka, ima li veze ako ne rijeÅ¡imo sve podzadatke ili nam neÅ¡to ne radi?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "157870": {
      "poster": "[deleted]",
      "content": "@BigD#157350 Moglo bi eventualno doÄ‡i nadopuniti svoj kod u nekom zadatku (tako je bilo jucer na oblikovnima), ali mislim da je vjerojatnije da to bude baÅ¡ da implementaciju neÄega nego za podzadatke gdje ispitujeÅ¡ ponaÅ¡anje",
      "votes": {
        "upvoters": [
          "Vrba",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158169": {
      "poster": "Sharich",
      "content": "kako ste rjesili u 7. zadatku ovaj train val split ? jedio sto sam nasao je ovako nesto ali mi onda pretvara u torch.utils.data.dataset.Subset i pol funkcija mi vise ne rade jer nije vise torch.tensor\n\n`x_train, x_val = utils.data.random_split(x_train, [N-N_val, N_val], generator=torch.Generator().manual_seed(42))\n\ny_train, y_val = utils.data.random_split(y_train, [N-N_val, N_val], generator=torch.Generator().manual_seed(42))\n`",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158215": {
      "poster": "orange",
      "content": "@Sharich#158169 `  idx = torch.randperm(X.size()[0])\n\n        X = X[idx]`",
      "votes": {
        "upvoters": [
          "Sharich"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158353": {
      "poster": "moji_prsti_prsti_klize_po_njoj",
      "content": "Na koji naÄin da sredimo izgled labosa? U smislu da organiziramo slike, odgovore i zakljuÄke u jupiter biljeznicu ili mozda ko neko izvijesce.pdf? tribamo li uopce to raditğŸ˜‚ il mogu ostavit u PyCharmu pa ako triba rjesenja onda runnan program?ğŸ’€",
      "votes": {
        "upvoters": [
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158357": {
      "poster": "[deleted]",
      "content": "@moji_prsti_prsti_klize_po_njoj#158353 nigdje ne pise da treba rezultate isprintati tako da  mislim da ce samo proletit kroz kod koji doneses isprintan i vidit jesi li sve rijesio i otprilike ima li to smisla.",
      "votes": {
        "upvoters": [
          "ls_123 (KimuraKong)",
          "member",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158358": {
      "poster": "moji_prsti_prsti_klize_po_njoj",
      "content": "@maki#158357 pff zast ja razbijan glavu s ovin ğŸ˜‚ tenks â™¥",
      "votes": {
        "upvoters": [
          "Watson (112)",
          "member",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158686": {
      "poster": "Vrba",
      "content": "Jel trebamo zip na ferku nazvati odredenim imenom ili je svejedno?",
      "votes": {
        "upvoters": [
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158710": {
      "poster": "Ziher",
      "content": "@BigD#157350 Nije da je 2.5 kod, 2.5 ovo sutra?\n\nNemojte mi reci da sam bezveze glancao kod...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
          "moji_prsti_prsti_klize_po_njoj",
          "sane_insane"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "158715": {
      "poster": "member",
      "content": "@Ziher#158710 Ja sam shvatila kao da su svi bodovi blic",
      "votes": {
        "upvoters": [
          "Ziher",
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "158899": {
      "poster": "BigD",
      "content": "@member#158715 2.5 bodova blic, 2.5 bodova neki zadatci koje cemo morati rjesavati na papiru",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "161650": {
      "poster": "neZnamNista",
      "content": "nisam bio na prvom labosu, pa moze li netko opisati kakva je procedura na labosu? je li istina da kod koji je poslan na ferko ne treba za rjesavanje zadataka na papiru?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "161739": {
      "poster": "tonkec",
      "content": "@neZnamNista#161650 mogao se koristiti isprintan kod na blicu/testu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}