{
  "title": "[UUUI] 4. laboratorijska vježba - 2020/2021",
  "creator": "TheNubKiller (Lumpy)",
  "slug": "uuui-4-laboratorijska-vjezba-20202021",
  "tags": [
    "FER",
    "Uvod u umjetnu inteligenciju",
    "Laboratorijske vježbe"
  ],
  "posts": {
    "197745": {
      "poster": "TheNubKiller (Lumpy)",
      "content": "Jel itko krenuo ovo rješavati? Gledam pripremu i uopće nemam pojma što trebam raditi... Ima tko koje savjete kako ovo čudo dešifrirati?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "197867": {
      "poster": "bernard (macabrus)",
      "content": "Mene bi zanimalo:\n1. jel moraju mreže imati bias težinu jer na slici nije nacrtan?\n2. kak crossover? samo flattenam sve težine mreža, odaberem crossover point i onda zamjenim težine i dobim 2 nove mreže?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "197900": {
      "poster": "viliml",
      "content": "@bernard#197867 \n\n1. Da, bez biasa ti ništa neće raditi\n2. Pročitaj zadatak ![](assets/2021-05-29/00008.png)",
      "votes": {
        "upvoters": [
          "bernard (macabrus)"
        ],
        "downvoters": [
          "SuperSjajan3"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198008": {
      "poster": "TheNubKiller (Lumpy)",
      "content": "\"Početne vrijednosti svih težina neuronske mreže uzorkujte iz normalne razdiobe sa stan-\n\ndardnom devijacijom 0.01.\"\n\nKako to izračunati?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198037": {
      "poster": "viliml",
      "content": "@TheNubKiller#198008 Pozoveš funkciju.\n\nU sva tri jezika postoji ta funkcija.\n\nNe znam koji jezik ti koristiš pa ti ne mogu odmah reći, ali koji god bio, guglanjem ćeš ju sigurno lako naći.",
      "votes": {
        "upvoters": [
          "TheNubKiller (Lumpy)"
        ],
        "downvoters": [
          "SuperSjajan3",
          "benac (caneb)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198063": {
      "poster": "TheNubKiller (Lumpy)",
      "content": "@viliml#198037 ne mogu naći, koristim javu. Što funkcija prima kao argument i što vraća?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198072": {
      "poster": "sphera",
      "content": "@TheNubKiller#198063 koristiš java.util.Random paket, Random random = new Random(); funkcija je nextGaussian() koja po defaultu ima aritmetičku sredinu 0.0 i standardnu devijaciju 1.0 i onda ako ti želiš aritmetičku sredinu 0.1 imat ćeš izraz random.nextGaussian() + 0.1; a standardna devijacija onda ostaje 1.0",
      "votes": {
        "upvoters": [
          "TheNubKiller (Lumpy)",
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198176": {
      "poster": "Retard00",
      "content": "Koja predavanja/prezentacije bi trebao pogledat za ovu vježbu?",
      "votes": {
        "upvoters": [
          "Gulbash"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198214": {
      "poster": "bernard (macabrus)",
      "content": "@viliml#197900 vidio sam to, znači li to aritmetičku sredinu težina mreža?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198227": {
      "poster": "viliml",
      "content": "@bernard#198214 Da.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198698": {
      "poster": "Krisle",
      "content": "Cijenio bih ako bi netko mogao otprilike reći kako mu zasad ide ovaj labos? Koliko je zeznuto pohvatati?\n\nBodovi mi realno trebaju, ali ako me čeka tuckaranje skroz do nedjelje, volio bih odma prekrižiti ovaj labos. \n\nMožda usporediti barem prema 3. labosu?\n\nVjerujem da nisam jedini u ovoj situaciji...",
      "votes": {
        "upvoters": [
          "5ani (5af)",
          "Nocna_smjena",
          "Retard00",
          "feel_d_boot (iNut)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198700": {
      "poster": "Lyras",
      "content": "@Krisle#198698",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "198701": {
      "poster": "Lyras",
      "content": "@Krisle#198698 going well so far\n\n![](assets/2021-05-31/00001.png)",
      "votes": {
        "upvoters": [
          "Daeyarn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Han"
        ]
      }
    },
    "199113": {
      "poster": "viliml",
      "content": "@Krisle#198698 Mislim da ti moje \"riješio sam ga u jednom popodnevu\" neće biti baš korisno...\n\nKompliciranije je od lab3, pogotovo ako nemaš prijašnjeg iskustva s neuronskim mrežama i genetskim algoritmima (ja sam imao s oboje).\n\nSami \"algoritmi\" su jako jednostavni gledano s visoke razine apstrakcije, ali konkretni implementacijski detalji u kodu su pakleno zeznuti ako to radiš prvi put.",
      "votes": {
        "upvoters": [
          "SuperSjajan3",
          "Wayk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199223": {
      "poster": "Spuk",
      "content": "Mi moze neko pojasnit sta je pjesnik htio rec s ovim:\n\nMreza (1) se sastoji od dvije linearne transformacije { matricna mnozenja pracena\n\npribrajanjem vektora pristranosti, te jedne primjene prijenosne funkcije. Ulazni podaci\n\nse prvo projiciraju u skriveni sloj dimenzije 5, potom se primjeni prijenosna funkcija, i\n\nkonačno se pomoću druge linearne transformacije podaci transformiraju u izlaznu vrijed-\n\nnost.\n\nKontam kako izvest matricno mnozenje i onda pribrajanje biasa ali ne kontam kako onda tu matricu koju dobijem kao rjesenje zbuksat u jedan broj? Dodatno jel neko moze pojasnit sliku jer me zbunjuje razdvajanje funkcije sigma od neurona koji su prikazani kao h.\n\nEDIT: koliko kontam trebam pozvat onu sigmoidalnu funkciju nad matricom i nez kako to izvest. Garant nes krivo kontam pa ako neko moze razjasnit",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199346": {
      "poster": "viliml",
      "content": ">@Spuk#199223 matricu koju dobijem kao rjesenje\n\nMnoženjem vektora matricom dobivaš vektor.\n\nSvaki sloj je jedan vektor. Matrice su težine koje spajaju neurone u susjednim slojevima. Prijenosna funkcija se primjenjuje na neurone u sloju nakon što se njihova početna vrijednost izračuna težinskim zbrajanjem prošlog sloja i biasa (a.k.a. množenjem vektora prošlog sloja matricom težina i dodavanjem vektora biasa).",
      "votes": {
        "upvoters": [
          "SuperSjajan3"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199380": {
      "poster": "Spuk",
      "content": "@viliml#199346 To je za opcenito i to kuzim. Ima ona formula kad cupic objasnjava i to je sve ok. Mene sam zanima zasto je na slici funkcija odvojena van neurona kad se radi o jednom skrivenom sloju. Ispada da ju ne provodi svaki neuron nego se ona izvodi jednom sa svih 5 rjesenja i onda ona da jedno rjesenje, sto mi je jos gore. Jer svaki neuron ce mi dat vektor koji treba provuc kroz sigm funkciju. Opet ne znam kako jedan vektor provuc kroz tu funkciju, a kamo li 5 odnosno 20 njih.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199470": {
      "poster": "viliml",
      "content": "@Spuk#199380 Neuron je broj. Sloj je vektor.\n\nOna slika je malo čudna ali [imath]h[/imath] i [imath]\\sigma[/imath] su zajedno jedan sloj.\n\nFunkcija se na vektor primjenjuje element po element.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199474": {
      "poster": "Spuk",
      "content": "@viliml#199470 ajme da, nmg vjerovat da me to zbunilo, svaki red u matrici je jedan nauron i onda rpakticki mogu izvodit funkciju sigme nad svakim redom u vektoru i dobit cu prijelaz za svaki neuron. Al sta to ne znaci da ce mi svaki neuron onda dat neki y i da cu na kraju imat vektor s 5 vrijednosti a trebam imat samo jedan broj? ili opet nesto krivo razmisljam",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199476": {
      "poster": "Spuk",
      "content": "@viliml#199470 da da slika je cudna, mene je to bunilo totalno.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199486": {
      "poster": "viliml",
      "content": "> @Spuk#199474 Al sta to ne znaci da ce mi svaki neuron onda dat neki y i da cu na kraju imat vektor s 5 vrijednosti a trebam imat samo jedan broj?\n\nPa prvi skriveni sloj ima 5 neurona dakle treba ti 5 vrijednosti. Zašto misliš da to nije dobro?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199487": {
      "poster": "Spuk",
      "content": "@viliml#199486 al sta nije po onoj slici da nakon sigma funkcije prelazi u y. Ne kuzim kako trebam onda iz 5 vrijednosti dobit output koji samo jedna vrijednost \n\nEDIT:\n\nzato meni onaj cijel itekst nije jasan, jer spominje dvije linerane transformacije, jedna je ono matricno mnozenje i zbrajanje vektora sto se radi u skrivenom sloju i to kontam, a druga je prijenosna funkcija sto bi trebala bit sigma funkcija. I onda kasnije spominje da se nakon primjene prijenosne funkcije pomocu druge linerane transformacije podaci transformiraju u izlaznu vrijednsot. Koje druge linerane transformacije kad je druga linearna transformacija ta prijenosta funkcija???",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199536": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Spuk#199487 Prijenosna funkcija definitivno nije linearna (jer to ne bi imalo nikakvog smisla), nego nelinearna transformacija.\n\nDakle postupak je linearna -> sigmoida -> linearna -> ...\n\nA ono na slici je neka shit skica s jednom linearnom transformacijom, a 2. bude kako se shvati. Može biti samo suma aktivacija, umnožak, može biti bilo što. U svakom slučaju ta slika donosi više pitanja nego odgovora...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199541": {
      "poster": "Spuk",
      "content": "@micho#199536 kontam sad, na konzultacijama objasnili asistenti. Uopce mi nijepalo na pamet da onaj izlazni isto trebam gledat kao neuron koji treba opet provest matricno mnozenje i zbrajanje i opet sigma funkciju da bi dobili jedno rjesenje",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199679": {
      "poster": "viliml",
      "content": "> @Spuk#199541 Uopce mi nijepalo na pamet da onaj izlazni isto trebam gledat kao neuron\n\nTo doslovno je neuron.\n\nSlojevi neurona u sredini se zovu \"skriveni slojevi\" zato što postoje i slojevi koji nisu skriveni - ulazni i izlazni.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199682": {
      "poster": "Spuk",
      "content": "@viliml#199679 ma znam da, ali zbog slike nije mi palo na pamet da je neuron kad je skriveni sloj prikazan krivo. A dodatno cinilo mi se da ulazni neuron ne radi nista nego samo daje ulaze skrivenom sloju. Zato je prva pomisao bila da izlazni neuron isto ne treba nista radit nego samo primit rezultat",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199688": {
      "poster": "Dlaid (Peter Jordanson)",
      "content": "Kolki je prihvatljiv train error za sinusoidu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199707": {
      "poster": "kix7 (Fish99)",
      "content": "@viliml#199113 imas neki dobar savjet onda?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199711": {
      "poster": "viliml",
      "content": "@Dlaid#199688 2x koliki je ispisan u njihovom primjeru.\n\n@kix7#199707 Nemam.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199713": {
      "poster": "KitKat (H(x))",
      "content": "Pitanje za ove kromosome iz genetskog:\n\nKad kažu \"kromosom se sastoji od težina iz neuronke\", misle jedan kromosom je samo vektor težina i ništa drugo ili? Ovi x i y iz fja me više ne zanimaju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "199751": {
      "poster": "viliml",
      "content": "@KitKat#199713 Ne znam što točno misliš pod \"x i y iz fja\", ali primijeti da su vrijednosti neurona vezane za pojedini specifični input, a ne dio same mreže. Treba trenirati mrežu općenito neovisno o inputima i outputima. Oni se koriste samo za izračun dobrote.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200174": {
      "poster": "kix7 (Fish99)",
      "content": "Ako sam dobro shvatio ovo \"pribrajanje vektora pristranosti\" možemo implementirat il doslovno kao vektor koji cemo zbrojit sa matricom težina ili bolje (mozda) dodamo matrici težina u svakom sloju jos jedan stupac samo jedinica pa on glumi taj dodatni bias? Jel bi to bio pametan pristup, s tim da onda lakse i genetskom algoritmu šaljemo sve te težine?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200190": {
      "poster": "viliml",
      "content": "@kix7#200174 Oba pristupa se koriste u praksi. Nema razlike. Slijedi svoje srce.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200253": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@kix7#200174 Ispravnije rješenje je imati zaseban vektor koji se zbraja\n\nUostalom tad genetski algoritam kod te komponente ima lakši posao jer je neovisan o ostalim težinama, osim ako se implementira na način da se konkateniraju težine s time, što će biti teže genetskom algoritmu za riješiti s obzirom na to da težine modeliraju osobine pojedinih podataka, a pomaci modeliraju osobine distribucije podataka, tj. to su semantički 2 različite uloge.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200259": {
      "poster": "dobro",
      "content": "ja sam elitizam, križanje i selekciju shvatio ovako pa ako bi netko mogao pročitati i uvidjeti greške ako postoje. bio bih zahvalan. \n\npočetne vrijednosti težina izmutiramo _popsize_ puta te to sačinjava prvu populaciju. Nakon toga provedemo selekciju tj. sortiramo populaciju prema dobroti. Potom izvadimo _elitism_ najboljih i međusobno ih iskrižamo tako da dobijemo jednu jedinku. Zatim izmutiramo tu dobivenu jedinku _popsize_ puta i time dobijamo populaciju sljedeće generacije. Rinse and repeat nadalje\n\nje li ovo ispravno?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200265": {
      "poster": "dobro",
      "content": "@dobro#200259 skužio sam da je u skripti detaljno opisan Generacijski genetski algoritam i sad sam skužio ideju toga hahah, modovi slobodno izbrišite ova moja dva posta, ne vidim izbrisi oopciju",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200278": {
      "poster": "viliml",
      "content": "@micho#200253 Nije ništa ispravnije. Bias se vrlo često implementira pomoću virtualnog neurona s vrijednošću 1.\n\nA genetski kod bi imao lakši posao kad bi se samo trebao brinuti o težinama, a ne zasebno o težinama i biasima.\n\nJa sam ovaj specifični labos implementirao sa zasebnim vektorima biasa jer mi je tako došao hir, ali kad sam prije za jedan projekt radio neuronsku mrežu, radio sam to kao proširenje matrice težine.\n\nZa oba načina se može naći mnogo materijala na internetu. Zbilja ne postoji jedan točan odgovor.",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Han"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "200308": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "> @viliml#200278 Bias se vrlo često implementira pomoću virtualnog neurona s vrijednošću 1.\n\nNaravno da ovo nije istina jer je na taj način puno nefleksibilnije, a i manje je efikasno, pogotovo u bakcpropu. Najveći problem je što ako želiš isključiti bias potrebno je ili resizeati matricu, staviti nul masku ili oduzeti bias, sve što je vrlo neelegantno i neoptimalno.\n\nDa ne ulazim u implementacijske detalje koji se svode na BLAS, preporučam da pogledaš high level implementacije u popularnijim knjižnicama - Pytorch, Tensorflow i Caffe.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200345": {
      "poster": "JBQ",
      "content": "Moze netko objasnit kako izgradit pocetnu populaciju koja je npr velicine 5. Dobijem pocetne vrijednosti tezina mreze uzorkovanjem kako vec pise..ali to je samo jedan vektor(jedna jedinka) ili se varam? Kako onda uzet jos 4 jedinke?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200360": {
      "poster": "viliml",
      "content": "@micho#200308 Ali nama tu zadatak nije da napravimo knjižnicu, mi radimo jednostavan mali programčić. Argument ne drži vodu. Ako kolega želi napraviti na taj način nema razloga zašto ne bi.",
      "votes": {
        "upvoters": [
          "teta_iz_menze"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Han"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "200426": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@viliml#200360 Naravno da može napraviti kako želi. Ja sam argumentirao zašto je i iz drugih razloga specifičnih za zadatak bolje tako napraviti kako sugeriram. Onaj koji je ušao u raspravu o praksi IRL ste Vi, samo pobijam argument da je suprotno u tom smislu bolje 🙃",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Han",
          "djeno"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "200632": {
      "poster": "dobro",
      "content": "@JBQ#200345 5 puta mutiraš tu prvu \n\n(\"Mutacija: operator mutacije implementirajte kao Gaussov šum, tako da kromosomu\n\ntežina pribrojite vektor uzorkovan iz normalne razdiobe sa standardnom devijacijom\n\nK. Svaku težinu kromosoma mutirajte s vjerojatnošću p;\")",
      "votes": {
        "upvoters": [
          "JBQ"
        ],
        "downvoters": [
          "JBQ"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200733": {
      "poster": "viliml",
      "content": "@JBQ#200345 Pa ako znaš napraviti jednu, napravi ju opet, i opet, i opet, i opet.\n\nDokle god ne resetiraš seed randoma, bit će sve različite.",
      "votes": {
        "upvoters": [
          "JBQ"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200744": {
      "poster": "viliml",
      "content": "@dobro#200632 To nije dobro, nećeš imati nikakvu genetsku raznolikost ako samo mutiraš početnu jedinku.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200878": {
      "poster": "Fikalo",
      "content": "@sphera#198072 al nije mi jasno zasto bi pomico aritmeticku sredinu ako se ni ne spominje koja treba bit, i zasto bi htio da je standardna devijacija 1.0 ako u zadatku kaze da treba bit 0.01",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200879": {
      "poster": "dobro",
      "content": "@viliml#200744 kužim te, hvala",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200973": {
      "poster": "Fikalo",
      "content": "Znači ako sam dobro shvatio, za primjer 5s, ulazni x-ovi se šalju u 5 neurona, i onda tih 5 neurona šalju svoje izlaze u jedan neuron koji daje rezultat mreže. A u pojedinom neuronu se svaki ulaz množi težinom za tu vezu, te se te vrijednosti zbrajaju sa biasom, a početni bias i početne težine se računaju kao random.nextGaussian()*0.001; ako radimo u javi, i onda se taj zbroj provede kroz Sigmoid() funkciju i taj izlaz se šalje dalje. Jel to sve drži vodu il sam nešto krivo shvatio? i dal onda te poočetne težine možemo računati sa random.nextGaussian()*0.001, ili je potrebno promjeniti medijan, jer se medijan ne spominje nigdje u zadatku samo da standardna devijacija mora biti 0.01",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200985": {
      "poster": "viliml",
      "content": "@Fikalo#200878 Možeš ili predati argument funkciji da namjestiš standardnu devijaciju ili ju namjestiti ručno množenjem. U nekim jezicima i bibliotekama je ponuđena samo standardna normalna razdioba (SD 1.0) pa se moraju rezultati množiti s 0.01 da se dobije SD 0.01.\n\n@Fikalo#200973 Da.",
      "votes": {
        "upvoters": [
          "Fikalo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "200989": {
      "poster": "Fikalo",
      "content": "@viliml#200985 Da, ali ono što je mene zbunilo je to što kolega mjenja aritmetičku sredinu, što mi nije bilo jasno zašto, tj dali imamo neku određenu aritmetičku sredinu za te početne težine jer ništa o tome ne piše u uputama",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201099": {
      "poster": "Bioxed",
      "content": "Zašto su nam pokazali backpropagation i onda u labosu moramo pomoću genetskog algoritma?\n\nDi je literatura za genetski, di da ja to skužim? (neretoričko pitanje)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201101": {
      "poster": "dobro",
      "content": "@Bioxed#201099 imaš skriptu Evolucijsko račuanrstvo od Čupića",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201119": {
      "poster": "viliml",
      "content": "@Bioxed#201099 Predavanje broj 13",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201177": {
      "poster": "Bioxed",
      "content": "Kako biramo točku prijeloma kod križanja?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201184": {
      "poster": "dobro",
      "content": "@Bioxed#201177 nemaš toga, radiš novo dijete tako da napraviš aritmetičku sredinu gena majke i oca",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201194": {
      "poster": "teta_iz_menze",
      "content": "je li se gaussov šum dodaje samo nadodavanjem izraza \"random.nextGaussian() * K\" na gen (svaki gen koji mutira po vjerojatnosti)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201198": {
      "poster": "teta_iz_menze",
      "content": "takoder, znam da je malo genericko pitanje, ali labos mi radi ali ima vrlo loše greške (u test data je 0.28) jel ima netko kakav prijedlog gdje bi greska mogla biti",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201204": {
      "poster": "teta_iz_menze",
      "content": "greska kod mreza koje su nasumicno generirane su mi oko prilike  1.1526926373267663 jel to uredu (da znam je li greska u mrezi ili u algoritmu) i onda se smanji na oko prilike 0.4",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201208": {
      "poster": "Fikalo",
      "content": "@teta_iz_menze#201204 i meni je prvo bilo 1.15, ali tada sam radio sigmoid na izlaz, kad sam maknuo sigmoid sa izlaza mi je palo na 0.84, provjeri si da da ti izlaz nema funkciju prijelaza, dodali su ti eddit u upute \n\n![](assets/2021-06-04/00015.png)",
      "votes": {
        "upvoters": [
          "teta_iz_menze"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201210": {
      "poster": "teta_iz_menze",
      "content": "@Fikalo#201208 thx stari",
      "votes": {
        "upvoters": [
          "Fikalo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201228": {
      "poster": "JBQ",
      "content": "Da li se bias napočetku isto stvara kao i tezine  i dali bias onda isto treba mijenjat genetskim algoritmom il on ostaje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201234": {
      "poster": "Zivot_nije_FER",
      "content": "Kako vama ispadaju rješenja za pojedine slučajeve?\n\nMeni u prvom primjeru sa sinusoidom ispadaju sljedeći rezultati:\n\n[Train error @2000]: 0.081447\n[Train error @4000]: 0.057636\n[Train error @6000]: 0.046911\n[Train error @8000]: 0.037310\n[Train error @10000]: 0.032213\n[Test error]: 0.017633",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201240": {
      "poster": "Zivot_nije_FER",
      "content": "Kako vama ispadaju rješenja za pojedine slučajeve?\n\nMeni za onaj prvi primjer sa sinusoidom ispada sljedeće:\n\n![](assets/2021-06-04/00017.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201245": {
      "poster": "teta_iz_menze",
      "content": "@JBQ#201228 mijenjas i biase, i krizaju se i mutiraju, da takoder se random stvaraju na pocektu",
      "votes": {
        "upvoters": [
          "JBQ"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201246": {
      "poster": "teta_iz_menze",
      "content": "@Zivot_nije_FER#201240 ![](assets/2021-06-04/00019.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201259": {
      "poster": "teta_iz_menze",
      "content": "zna netko neke tipove za optimizaciju brzine izvodenja? koristio sam treeset za spreamnje temp Populacije",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201282": {
      "poster": "nimble",
      "content": "Kako dobit dobrotu iz odstupanja? Ne vidim da su to igdje objasnili pa sam razmisljao ili 1/odstupanje ili exp(-odstupanje) ali ne znam jel treba nesto sofisticiranije.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201285": {
      "poster": "Zivot_nije_FER",
      "content": "ja sam stavio (1/odstupanje)/100 tako da kada mi se sva odstupanja od svih populacija zbroje daju 1, onda napadam na Math.random() i izvlačim ih preko roulette algoritma kao na predavanju što je Čupić pokazao. Ali nisam ni ja siguran da li je to u redu. Prema gore slikama usporedbe mojih rješenja i rješenja kolege, mislim da nešto ne radim dobro.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201287": {
      "poster": "Bioxed",
      "content": "Koji pseudokod gledate ako ijedan ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201289": {
      "poster": "Gulbash",
      "content": "Koje prezentacije obuhvaca ovaj labos?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201292": {
      "poster": "teta_iz_menze",
      "content": "@Gulbash#201289 umjetne neur. mreze i genetski alg",
      "votes": {
        "upvoters": [
          "Gulbash"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201361": {
      "poster": "Spuk",
      "content": "@Bioxed#201287 ja gledam onaj sa prezentacije 13 sa 46. strane sto Cupic objasnjava na snimljenom predavanju, ali moras ga ajme popravljat, bar koliko ja kontam zadatak.",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201436": {
      "poster": "benac (caneb)",
      "content": "jel zadnji output neuron ima svoj bias?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201439": {
      "poster": "teta_iz_menze",
      "content": "@benac#201436 da, zadnji neuron radi sve sto i ostali, samo taj zavrsni rezultat ne provlaci kroz sigmoidu, ako si to pitao",
      "votes": {
        "upvoters": [
          "benac (caneb)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201444": {
      "poster": "Retard00",
      "content": "@teta_iz_menze#201439 jel to znači da tim zadnjim neuronima samo dam funkciju tipa f(x) = x kao step?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201445": {
      "poster": "teta_iz_menze",
      "content": "@Retard00#201444 da, mozes tako, ja sam imao odvojene metode za prolaz kroz jedan konkretan sloj i za primjenu sigmoide na vektor koji bude rezultat prolaza kroz taj sloj i onda kako sam imao te metode mogao sam za sve slojeve osim zadnjeg primijeniti zasebno prolaz kroz sloj (mnozenje s matricom i pribrajanje biasa) i prolaz kroz sigmoidu, a u zadnjem (izlaznom) sloju samo propustim kroz sloj",
      "votes": {
        "upvoters": [
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201477": {
      "poster": "Fikalo",
      "content": "Ovaj labos nema svoj autograder nikakav? znaci sam je bitno da su nam rezultati slicni ko u primjerima i mozemo predat?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201496": {
      "poster": "viliml",
      "content": "@Fikalo#201477 Autograder će nam biti iznenađenje na odgovaranju.\n\n(Trebali smo ga dobiti do kraja prošlog tjedna)",
      "votes": {
        "upvoters": [
          "Fikalo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201571": {
      "poster": "zastozato (studoš)",
      "content": "koliko bi trebalo za ovaj labos nekome tko nema nikakvog iskustva u ovom podrucju?",
      "votes": {
        "upvoters": [
          "Gulbash"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201572": {
      "poster": "Bioxed",
      "content": "Što je nama populacija? Lista y-ona koje smo izračunali ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201578": {
      "poster": "benac (caneb)",
      "content": "@Bioxed#201572 lista neuronskih mreži veličine popsize. Jedna jedinka u generaciji ti je jedna neuronska mreža",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201580": {
      "poster": "Bioxed",
      "content": "@benac#201578 \n\nŠto nam je jedna jedinka onda jedna neuronska mreža ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201581": {
      "poster": "benac (caneb)",
      "content": "@Bioxed#201580 Da",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201582": {
      "poster": "Bioxed",
      "content": "@benac#201581 \n\nKako odrediš onda koliko jedinki imaš, odnosno koliko češ neuronskih mreža stvoriti ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201583": {
      "poster": "benac (caneb)",
      "content": "@Bioxed#201582 imas zastavicu popsize koja se unosi preko argumenata. Znaci ako ti je popsize 50, stvaras generaciju od 50 razlicitih jedinki, tj 50 razlicitih neuronskih mreza",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201584": {
      "poster": "Bioxed",
      "content": "@benac#201583 \n\nAha sorry\n\nHvala!",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201594": {
      "poster": "benac (caneb)",
      "content": "Jel ima netko ideju kako implementirat fitness proportionate selection, pošto primjer s predavanja radi kada je veći fitness bolji, a u našem labosu je manji fitness bolji ?\n\nedit: našao odgovor:  https://stackoverflow.com/questions/4394724/inverse-probability-selection-inverse-fitness-selection-of-evolutionary-algorit",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201613": {
      "poster": "Bioxed",
      "content": "Kad selektiramo neku NN kao najbolju/roditelja, što je to što šaljemo dalje? y vrijednosti koje smo izgenerirali ? Omege? Oboje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201619": {
      "poster": "benac (caneb)",
      "content": "@Bioxed#201613 evo napisao sam neki pseudokod, pa mozda pomogne za shvatit.\n\n![](assets/2021-06-05/00015.png)\n\n\nedit: roditelji se biraju iz trenutna_generacija naravno, novo dijete se pravi operacijom križanja ta dva roditelja.",
      "votes": {
        "upvoters": [
          "Bioxed",
          "Jaster111",
          "Retard00",
          "SonGoku (~~~~~~~~)",
          "snowman"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201620": {
      "poster": "Retard00",
      "content": "@benac#201619 koje roditelje točno trebam birat za križanje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201623": {
      "poster": "benac (caneb)",
      "content": "@Retard00#201620 ![](assets/2021-06-05/00016.png)",
      "votes": {
        "upvoters": [
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201643": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@zastozato#201571 Nije kao da te plašim, ali ono što čujem od drugih je da ćeš si počupati kosu 😂\n\nAli da budem iskren, labos je praktički genetski algoritam + forward pass neuronske mreže. Znači jedino što je teško će ti biti složiti apstrakciju za sloj (moraš skužiti koje su dimenzije matrica, kak se množi i s čim) i genetski algoritam (što ovisi kak ćeš to implementirati, ali hardkodiranje toga ti ne bi trebalo uzeti više od par do deset sati).\n\nOvo drugo je jednostavno ako skineš npr. PyTorch i proučiš `torch.nn.Linear` strukturu jer zapravo to trebaš i napraviti, a za prvo samo gledaj NAISP, AIPR ili NEINR labose s materijala, s obzirom na to da se tamo radi genetski algoritam.",
      "votes": {
        "upvoters": [
          "zastozato (studoš)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201647": {
      "poster": "Bioxed",
      "content": "@benac#201619 \n\nKao prvo hvala puno,\n\nnapisao si u prvom foru <= broj_iteracija a krećeš od 0, što ih nećeš onda napravit npr 2001 ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201649": {
      "poster": "Jaster111",
      "content": "Ako nam elitizam prenese samo jednog roditelja u iduću generaciju, kako onda biramo roditelje za crossover kad imamo samo jednog?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201651": {
      "poster": "benac (caneb)",
      "content": "@Bioxed#201647 ne znam, mozda, al realno nije ni bitno hoce ti se izvrtit 10000 ili 10001 generacija jer ces ionako svakim drugim pokretanjem algoritma dobit drugacije rezultate, jedino sto moras pazit je da na svakih 2000 generacija ispišeš onaj error",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201652": {
      "poster": "Bioxed",
      "content": "@Jaster111#201649 \n\nMislim da ti elitizam prenese roditelja neovisno o ova ostala dva roditelja koja selektiras.\n\nDakle dodas elitnu jedinku u novu populaciju i dalje normalno križaš s neka druga dva roditelja.\n\nNek me neko ispravi ako sam u krivu.",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201653": {
      "poster": "benac (caneb)",
      "content": "@Jaster111#201649 elitizam PREKOPIRA roditelja u iducu generaciju, a roditelje za crossover biramo iz cijelog poola trenutne generacije(znaci odabir za crossover moze odabrati i ovog roditelja kojeg smo prekopirali na iducu generaciju)",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201654": {
      "poster": "Jaster111",
      "content": "Hvala momci",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201655": {
      "poster": "benac (caneb)",
      "content": "@Bioxed#201652 da sad kad razmislim, bolje bi bilo promijenit u i=1 na ovom mom pseudokodu",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201695": {
      "poster": "Haki",
      "content": "Koliko vam traje treniranje i jel uopće ima vremenskog ograničenja za ovaj labos? Ja radim u pythonu sa numpyjem i treba mi malo preko 2min za 10000 iteracija sa 5s neuronskom mrežom",
      "votes": {
        "upvoters": [
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201710": {
      "poster": "Retard00",
      "content": "@benac#201623 Jel onda po tome može ispast da jedno dijete može dobit dva ista parenta ili već odabranog parenta treba izbacit iz liste?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201714": {
      "poster": "Bioxed",
      "content": "@benac#201619 \n\ne ali kuzis mene muci sto je uopce u generaciji;\n\nda skup jedinki, odnosno skup neuronskih mreža, ali što je to? Ovako po vrsti varijable (npr ArrayList<Double> u javi)\n\nZato sam pitao što se prenosi dalje, kao što nam je uopće spremljeno, što sadržava jedna neuronska mreža od podataka ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201716": {
      "poster": "Bioxed",
      "content": "Ili možda imate klasu neuronska mreža",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201717": {
      "poster": "Haki",
      "content": "@Bioxed#201714 Napravis klasu koja u sebi sadržava slojeve.\n\nSlojevi su isto tvoje custom klase koje sadržavanju matrice težina i biaseva",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201718": {
      "poster": "Retard00",
      "content": "Što znači \"Svaku tezinu kromosoma mutirajte s vjerojatnoscu p;\"?\n\nJel da za svaku težinu izgeneriram neki random broj od 0 do 1 i onda ako je taj broj veci od p mutirat taj weight ili nešto drugo?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201723": {
      "poster": "Jaster111",
      "content": "@Retard00#201718 Vjerojatno ako je taj broj manji od p, onda mutiraš. Jer ako je p=0.1, postoji 10% šanse da će ti random generator izgenerirat broj u intervalu [0, 0.1]",
      "votes": {
        "upvoters": [
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201731": {
      "poster": "Jaster111",
      "content": "Jel se treba ispisivat fitness ili srednja kvadratna greska?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201732": {
      "poster": "benac (caneb)",
      "content": "@Retard00#201710 E vidis nisam siguran, ja sam skroz zaboravio napravit provjeru da su mi roditelji dvije različite jedinke i algoritam mi radi ¯\\_(ツ)_/¯",
      "votes": {
        "upvoters": [
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201753": {
      "poster": "Retard00",
      "content": "@Haki#201695 Imam isti problem. Čini mi se da je python malo pre spor za ovaj labos ili možda ja u njemu ne znam ovo dobro napisat. Za rastrigina (nn = 20s) mi treba oko pola sata da sve izvrti. U uputama nisam nigdje vidio da su navedena ikakva vremenska ograničenja pa ak daju par sati za trenutne i nove test primjerke mislim da bi se sve trebalo izvršit do kraja.",
      "votes": {
        "upvoters": [
          "Haki"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201768": {
      "poster": "Artemis",
      "content": "Što sve imate u metodi fit, tj. metodi koja trenira neuronsku mrežu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201769": {
      "poster": "steve (Mr_mr)",
      "content": "Zanima me ako napravim samo prvi zadatak, a drugi uopce ne rijesim hocu li dobiti onda 12/24 ako sve radi?",
      "votes": {
        "upvoters": [
          "nnn (dinoo)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201784": {
      "poster": "Bioxed",
      "content": "\"operator križanja implementirajte kao aritmetičku sredinu\"\n\naritmetičku sredinu čega, težina na istoj grani dviju NN ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201799": {
      "poster": "Jaster111",
      "content": "Jel imao netko problem da mu se weightovi inicijaliziraju na neke slicne vrijednosti pa onda u odabiru ruleta budu isto jako slicne vjerojatnosti (oko 10% za svaku)? Problem je vise u tome sto iako prolazi selekciju crossover i mutaciju, weightovi se ne mijenjaju znacajno cak i nakon 10000 iteracija.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201801": {
      "poster": "Lukak",
      "content": "@Bioxed#201784 Kada odaberes 2 nn, za svaku težinu svakog neurona racunas aritmeticku izmedu te 2 mreže ako se ne varam",
      "votes": {
        "upvoters": [
          "Bioxed"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201804": {
      "poster": "Lukak",
      "content": "@Jaster111#201799 To sam baš i ja htio pitati jer mi se slična stvar događa. Čini mi se da je to zbog vrlo male standardne devijacije u normalnoj razdiobi pa su i razlike weightova vrlo male. Zna li netko nekakav popravak za ovaj problem?",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201833": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Lukak#201804 \n\nPovećaš mutaciju",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201838": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "Ajmo generalni tipsi kako će vam ovo najbolje raditi:\n\n## Inicijalizacija\n\nTežine inicijalizirajte uz radiobu [imath] \\mathcal{U}(-10^{-3}, 10^{-3})[/imath]. Pomake sve samo na 0. Da ne ulazimo previše zašto - pokazano je kao dobra praksa, iako ima optimalnijih i kompliciranijih metoda.\n\n## Pretvorbe\n\nTežine spljoštite u redak (uz npr. `numpy.reshape((1, -1))`) i konkatenirajte ih, time ćete dobiti jedan dugačak vektor. Zapamtite duljine da možete obrnuti situaciju. I onda je te stvari lako crossoversti i lako ih je mutirati.\n\nKad trebate evaluirati mrežu, rastavite vektor na vektore i opet ih reshapeajte u inicijalni oblik. Npr.\n\n```python\nfirst = vector[:5]\nsecond = vector[len(first):len(first) + 5*5]\nthird = vector[len(first) + len(second):]\n\nfirst = first.reshape((1, 5))\nsecond = second.reshape((5, 5))\nthird = third.reshape((5, 1))\n```\n\n## Trening\n\nAko vam stvari ne konvergiraju, smanjite mutaciju. Ako vam stvari zapinju, povećajte mutaciju. Ne vrtite algoritam predugo, bar ne bez periodički alternirajuće mutacije jer genetski algoritam lako zapinje pa nema ni smisla ga dugo vrtiti. Rađe ga ponovno pokrenite. Pa čuvajte neki leaderboard.",
      "votes": {
        "upvoters": [
          "Lukak"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201853": {
      "poster": "Jaster111",
      "content": "Za sine_train dobivam ovakve errore:\n```\n0.8559116261766178\n0.8182618260867435\n0.8187921715682862\n0.8184416720218295\n0.8177543113505844\n0.8189204011392947\n```\nJel imao netko ovakav problem?\n\nMreža koju koristim izgleda ovako:\n```\nclass NeuralNetwork5S():\n    def __init__(self, x, y):\n        self.input = x\n        self.weights1 = np.random.normal(0, 0.01, size=(1, 5))\n        self.weights2 = np.random.normal(0, 0.01, size=(5, 1))\n        self.bias = np.random.normal(0, 0.01)\n        self.y = y\n        self.output = np.zeros(y.shape)\n        self.weights = [self.weights1, self.weights2]\n        self.feedForward()\n        #print(meanSquaredError(self.y, self.output))\n\n    def feedForward(self):\n        for i in range(self.input.size):\n            layer1 = sigmoid(np.dot(self.input[i], self.weights1) + self.bias)\n            self.output[i] = np.dot(layer1, self.weights2)\n```\nOva mreža je trenutno naštimana samo da radi za točno taj sine primjer, znam da neće raditi kad imamo više od jednog inputa, ali bih samo htio da proradi na jednom primjeru pa bi onda znao da mi algoritam štima.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201857": {
      "poster": "Gulbash",
      "content": "Kad stvaram pocetnu generaciju recimo velicine 5, ja moram napraviti 5 mreza koje ce medusobno imati drugacije tezine?\n\nI u pojedinoj mrezi kad inicijaliziram tezine i biasove, sve tezine i svi biasovi bi se trebali razlikovati (cak i oni koji su u istom layeru)?",
      "votes": {
        "upvoters": [
          "Fica (Prof)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201859": {
      "poster": "hellvetica",
      "content": "Meni je na nekim testinm primjerima mutacija premalena pa mreze jako sporo konvergiraju a na nekima je prevelika da nakon neke tocke dobijem samo noise. Ne mogu naci sweetspot takav da mi se cca poklapa sa primjerima. Jel to normalno ili nesto propustam?",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201898": {
      "poster": "Spuk",
      "content": "@micho#201838 Ako mi treniranje ovisi o mutaciji kako onda oni planiraju provjerit to sa autograderom??  Jos dodatno sto ovisi o onome sto ce se stvroit na pocetku. Ispada da to nije do algoritma greska nego jednostavno do toga koje ce ti brojeve izbacit i koju ce ti mutaciju oni zadat??",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201904": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Spuk#201898 Piše u uputama prilično jasno da neće provjeravati brojeve egzaktno. Znači onda će jedino što će imati utjecaj uz hardkodirane vrijednosti biti početna inicijalizacija. S tim se možete igrati, tj. podešavati parametre te uniformne distribucije. Po meni je jedino bitno da to bude simetrično oko nule, a sad granice mogu imati i normu 1 ako baš želite, ali bi bilo dobro da su norme granica male, tako negdje kako sam rekao, oko [imath]10^{-3}[/imath].\n\nZbog sigmoide vam vrlo vjerojatno i neće toliko pomoći finetuneanje u početnoj populaciji, već će veći utjecaj imati mutacija, s ozbirom na to da je crossover aritmetičkom sredinom apsolutno beskoristan za pretragu prostora, i ima jedino ulogu minimizacije u nekoj dolini funkcije gubitka. Tako da je za očekivati da ćete uz neku racionalnu inicijalizaciju težina doći do istog mjesta uz njihove zadane mutacije, pa se pobrinite da vam inicijalizacija ne stvara neke retard mreže, a to ćete postići tako\n\n- da je srednja vrijednost težina 0\n- da su težine sumjerljive mutaciji",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201922": {
      "poster": "viliml",
      "content": "> @micho#201838 Težine inicijalizirajte uz radiobu  [imath] \\mathcal{U}(-10^{-3}, 10^{-3})[/imath]. Pomake sve samo na 0. Da ne ulazimo previše zašto - pokazano je kao dobra praksa, iako ima optimalnijih i kompliciranijih metoda.\n\n> Ako vam stvari ne konvergiraju, smanjite mutaciju. Ako vam stvari zapinju, povećajte mutaciju.\n\nTo je sve istina općenito, ali ovdje je zadatak da napravimo program koji će raditi pod njihovim zadanim uvjetima.\n\nZnači sve težine i pomake treba inicijalizirati normalnom razdiobom i mutacija mora biti kako je zadano u njihovim test primjerima.\n\nIstina da to nisu idealni parametri ali meni trening radi savršeno unatoč tome dakle kolege su sigurno nešto drugo krivo iskodirali.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201923": {
      "poster": "nnn (dinoo)",
      "content": "> Mreža (1) se sastoji od dvije linearne transformacije – matrična množenja praćena pribrajanjem **vektora pristranosti**, te jedne primjene prijenosne funkcije\n\nOtkud nama vektor pristranosti?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201924": {
      "poster": "viliml",
      "content": "@nnn#201923 Otkud ti matrica?\n\nOtkud ti išta?\n\nNapravi ga.",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "kix7 (Fish99)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "201925": {
      "poster": "kix7 (Fish99)",
      "content": "jesu rekli koji je otprilike interval u kojem ce nam nase rjesenje priznati kao tocno? Isprobavao sam zasad samo za sine 5s primjere i redovito mi su mi greske oko 2x vece (meni je za test set 0.0008, njima 0.0004)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201930": {
      "poster": "viliml",
      "content": "@kix7#201925 Ako je u istom redu veličine sigurno ti to neće zamjeriti. Samo nemoj da bude 100x veća.\n\nTakođer nasumičnost igra veliku ulogu pa možeš gledati npr najbolji rezultat od 5.",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201932": {
      "poster": "Haki",
      "content": "Jel nekome još samo 2. rosenbrock test sa 5s5s mrezom dosta odudara od njihovih vrijednosti? Konstantno dobivam 3-4 puta veći error nego oni u uputama.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201938": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@viliml#201922 Pa okej, i ovim parametrima je lako istestirati funkcioniraju li stvari jer bi ovakav setup trebao raditi. Drukčije, nasumičnim parametrima, ne možeš s dovoljno sigurnošću reći jel nešto radi ili ne.\n\nDakle ja nisam dao savjet kako dobiti sve bodove, nego kako s relativno visokom sigurnošću provjeriti jel nešto funkcionira, s obzirom na to da je algoritam u većoj mjeri stohastički pa se ne mogu provjeriti egzaktne brojke.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201950": {
      "poster": "viliml",
      "content": "@Jaster111#201853 Bias mora biti različit za svaki neuron.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201952": {
      "poster": "SwingWorker",
      "content": "Moze pomoć netko? Ovakav mi je izlaz i češto mi se dogodi da zapne error na nekoj vrijednosti. \n\nSelekciju proporcionalnu dobroti sam napisao kao  na ovom videu:\n\nhttps://www.youtube.com/watch?v=9JzFcGdpT8E&ab_channel=NoureddinSadawi \n\nOsim što sam unutra ubacio funkciju 1/1+x tako da velike greške imaju mali udio a male veći.  Sve ostalo radim valjda kak bi se trebalo po onom pseudokodu koji je kolega gore stavio.\n\nIspis za sinus 5s:\n\n[Train error @1]4.684691\n\n[Train error @2000]1.223179\n\n[Train error @4000]0.888150\n\n[Train error @6000]0.888150\n\n[Train error @8000]0.888150\n\n[Train error @10000]0.888150\n\n[Test error]: \n\n1.055621",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201966": {
      "poster": "nimble",
      "content": "@Haki#201932 Meni je za sve rosenbrockove tako",
      "votes": {
        "upvoters": [
          "Haki"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201972": {
      "poster": "Fica (Prof)",
      "content": "@SwingWorker#201952 Probaj malo parametre promijeniti, povećati populaciju i elitism i možda mutaciju malo ako ti prebrzo konvergira.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201976": {
      "poster": "Haki",
      "content": "@nimble#201966 Nije mi jasno zas se to dogada, nadam se da ce bit tolerantni na takva odstupanja",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201977": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@SwingWorker#201952 Imao sam isti problem. U mom slučaju je do problema došlo jer  fitness jedinke računam kao negativni error jedinke. To mi odgovara jer onda jedinka koja savrseno preslikava zeljenu funkciju ima error = 0, a sto vise jedinka gresi, fitness ide u negativu. \n\nGenericna implementacija selekcije proporcionalne fitnessu izracuna sumu fitnessa i onda se generira roulette wheel.\n\nto izgleda ovak:\n\ndouble[] wheel = new double[population.size()];\n\ndouble fitnessSum = population.getFitnessSum();\n\nwheel[0] = population[0].getfitness() / fitnessSum;\n\nfor(int i = 0; i < population.size(); ++i){\n\n    wheel[i] = wheel[i-1] + (population[i].getFitness() / fitnessSum);\n\n}\n\n\n\nE fora s ovom najjednostavnijom implementacijom kotaca je sto radi samo ako su ti fitness populacije unutar [0, inf>.\n\nAko imas fitnesse u rasponu <-inf, 0], ovakva implementacija ce jedinki s najboljim fitnessom dati najmanji prostor na roullete wheelu. Nadam se da je pomoglo :)",
      "votes": {
        "upvoters": [
          "SwingWorker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201978": {
      "poster": "nimble",
      "content": "Ako vam se odstupanje ne smanjuje, neki checklist jednostavnih greski:\n\n-Mutirate li djecu. Nakon krizanja djecu koja idu u sljedecu generaciju potrebno je mutirati dodavanjem onog gaussovog suma s devijacijom K tezini u p posto slucajeva.\n\n-Osvjezavate li zaista populaciju. Gledao sam pol sata da bi skuzio da mi fali newGeneration = oldGeneration.\n\n-Prenosenje najboljih elitism jedinki u sljedecu generaciju. Ispada da ako ne, jako se sporo uci mreza, Medutim, te najbolje jedinke nemojte mutirati (neka me neko ispravi tu ali dobivam losije rezultate ako ih mutiram)\n\n-Da ne sortirate slucajno u krivom smjeru pa uzimate one s najlosijim fitnessom\n\n-Pravilno uzorkovanje za odabir roditelja. Zbroj fitnessa vjerojatno nece biti 1 pa pazite da uzimate random u intervalu od 0 do zbroj ako koristite onaj roulette wheel.",
      "votes": {
        "upvoters": [
          "Ducky",
          "SwingWorker",
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201981": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "Kolko vam se dugo vrte programi?\n\nKonkretno, za 2. primjer mi se vrti 4-5 min...\n\n2. primjer (--train sine_train.txt --test sine_test.txt --nn\n\n20s --popsize 20 --elitism 1 --p 0.7 --K 0.1 --iter 10000)",
      "votes": {
        "upvoters": [
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201986": {
      "poster": "Ljepilo",
      "content": "Dobivam ovaj error kada izvodim njihovu naredbu za kompajliranje programa zato što mi program koristi matrice iz Apache commons math library, pretpostavljam da će to bit problem za autograder, da li netko zna koje je rješenje? U inteliju se sve izvodi bez problema, dodan je dependency u pom.xml. \n\n![](assets/2021-06-06/00026.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201989": {
      "poster": "Haki",
      "content": "@bodilyfluids#201981 same, nez jel to problem",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "201991": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@Haki#201989 stvaran broj iteracija = iter/10, a za ispis dodas jednu nulu, ez fix.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Haki",
          "blablajar",
          "nnn (dinoo)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "201999": {
      "poster": "nimble",
      "content": "@Haki#201976 Mozda su slucajno koristili drugacije parametre, sumnjam da ce biti problem posto za jednu implementaciju ionako greske mogu bit i do 10 puta razlicite od jednog pokretanja do drugog.",
      "votes": {
        "upvoters": [
          "Haki",
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202022": {
      "poster": "blablajar",
      "content": "moze mi netko objasnit implementaciju vjerojatnosti mutacije i skalu mutacije?\n\nI sto je jedan kromosom, jedna tezina, tezine jednog neurona? Stvarno ne kuzim to",
      "votes": {
        "upvoters": [
          "Gulbash"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202038": {
      "poster": "SwingWorker",
      "content": "Ajmo proc kroz psuedokod neuronskih mreža čisto da nisam tu negdje zajebao\n\nUzmem sve ulaze stavim ih u matricu tu matricu pomnožim sa težinama. \n\nOnda svaki clan jednog reda zbrajam i na kraju dodajem bias i to stvaljam u sigma funkciju.\n\nNakon toga za svaki dio (ajmo to nazvat) sigma vektora izracunam  srednje kvadratno odstupanje i to sve sumiram.\n\nTa suma svih kvadratnih odstupanja / ukupan broj ulaza je dobrota mreže. Nakon toga radim genetski dio.\n\nJel ovo ok?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202040": {
      "poster": "Jaster111",
      "content": "@blablajar#202022 Ako sam dobro shvatio, uzmeš sve težine od djeteta i prolaskom kroz svaku težinu uzmeš nasumični broj između 0 i 1. Ukoliko je tvoj nasumično odabrani broj manji od vjerojatnosti mutacije, izvršava se mutacija tako da izgeneriraš broj iz normalne distribucije sa očekivanjem 0 i standardnom devijacijom K te taj broj pribrojiš na težinu. Nek me netko slobodno ispravi ako sam u krivu jer mi možda zato i ne radi program kako treba.",
      "votes": {
        "upvoters": [
          "Gulbash",
          "blablajar",
          "bodilyfluids (Dragi prijatelj strojnog učenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202041": {
      "poster": "bega (brga)",
      "content": "glupo pitanje incoming, kako se stvori pocetna populacija velicine popsize nakon kaj imam neuronsku mrežu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202042": {
      "poster": "SwingWorker",
      "content": "@bega#202041 stvoris popsize neuronskih mreža. Znaci ak je popsize 50 imat ces 50 neuronsik mreza.\n\nJa sam ih stavljao u Listu",
      "votes": {
        "upvoters": [
          "bega (brga)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202043": {
      "poster": "blablajar",
      "content": "@bega#202041 \n\n`for(int i = 0; i < popsize; i++) {\n\n      neuralNetworks.add(new NeuralNetwork());\n\n}`",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202044": {
      "poster": "SwingWorker",
      "content": "Ako predamo i ne radi bas dobro jel mozemo racunati na neke bodove ili je to odmah 0. Cuo sam za neke ljude koji su imali 0 na autograderu i da su jos dobili dosta bodova.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202045": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@blablajar#202022 Ovo je puno osnovnih pitanja, mislim da bi trebao pogledat neki tldr kako neuronska mreza racuna output. Onda pogledat kako funkcionira genetski algoritam. \n\n\nNakon što to pogledaš, onda ponovo pročitaj zadatak lab vježbe, pa javi ako nešto i dalje nije jasno",
      "votes": {
        "upvoters": [
          "blablajar"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202047": {
      "poster": "blablajar",
      "content": "@bodilyfluids#202045 ma znam to sve, neke detalje sam krivo skuzio u labosu al sad mi je jasno",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog učenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202060": {
      "poster": "Jaster111",
      "content": "@SwingWorker#202044 Pretpostavljam da se barem ovdje mogu dobit neki bodovi čak ako ništa ne radi jer postoji dobra šansa da je nešto zeznuto u genetskom algoritmu, a da ti je izvedba neuronskih mreža sasvim ok, što autograderom ne mogu direktno testirat, a to ipak nosi 12 bodova.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202073": {
      "poster": "Bioxed",
      "content": "Može neko pojasnit mutaciju malo bolje od njih? lol",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202076": {
      "poster": "blablajar",
      "content": "kako postaviti odredenu tezinu neuronke ako broj tezina ovisi o dimenzijama ulaza, broju neurona u skrivenom sloju i broju skrivenih slojeva?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202078": {
      "poster": "Bioxed",
      "content": "@Bioxed#202073 aha @Jaster111 je objasnio/la gore",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202079": {
      "poster": "Bioxed",
      "content": "Jel vi dirate biase?\n\nMislim jel ih križate ili mutirate?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202080": {
      "poster": "branimir1999",
      "content": "Meni jako sporo opada greska, cak i kada povecam elitism na 2 i K na 0.2\n\npseudo-kod mi je ovakav:\n\n> evaluiraj(mreze) // sortiraj ih tako da ona s najmanjim mean squared error je prva\n\n> iteriraj 10000 puta\n\n>--- nova_populacija = { }\n\n>--- dodaj prvih _elitism_ u nova_populacija // dakle najboljih nekoliko po mean squared error\n\n>--- dok populacija nije jednaka populaciji mreze\n\n>------ odaberi 2 random roditelja iz mreze\n\n>------ crossover roditelja tako da se napravi arit. sredina svake tezine svakog neurona\n\n>------ mutiraj tako da svaka tezina svakog neurona ima *p* sanse da se doda onaj gaussov sum od (0.0, k)\n\n>--- mreze = nova_populacija\n\n>--- evaluiraj(mreze)\n\nwtf radim krivo ako ista ovdje?",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202082": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@Bioxed#202079 slobodne tezine (biasi) i tezine izmedu veza neurona sve jednako tretiras sto se tice genetskog algoritma. Jedan genom = tezine izmedu neurona + biasi neurona",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202083": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@branimir1999#202080 \n\nJel koristis selekcijsku strategiju ili random biras nove roditelje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202085": {
      "poster": "branimir1999",
      "content": "@bodilyfluids#202083 random\n\nKako funkcionira ovaj selection strategy? Ako koristi uvijek ista dva najbolja roditelja, onda se razlikuju sva djeca samo po mutaciji, je li tako?\n\nTakoder, ne znam je li mi ovo dobro jer nista ne shvacam o cemu ovi pricaju u labosu. Ovo je moj izlaz neurona za svaki sloj (ukljucujuci i zadnji):\n\n> result = 0\n\n> for i in x.length\n\n> --- result += (weights[i] * x[i]);\n\n> result += bias\n\n> return sigmoid(result)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202086": {
      "poster": "Bioxed",
      "content": "Kak se ovaj test set podataka koristi? Jel se on nekako evaluira prema zadnjoj populaciji što imamo ili se sve ponovno radi kao i za train set?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202087": {
      "poster": "Bioxed",
      "content": "@branimir1999#202085 \n\nNisu uvijek dva ista roditelja jer ti generiras random broj izmedu 0 i 1 i onda će on pripast nekom random dijelu roulette wheela odnosno roditelju. Imaš tu https://www.youtube.com/watch?v=CrhAWDVJJlE",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202151": {
      "poster": "Fica (Prof)",
      "content": "Ana Batinović 10:00\n\nNišta preteško, prolazi se po kodu i objašnjavate što ste i kako radili, pita npr. kako ste računali funkciju dobrote, kako ste implementirali križanje i slično. Na kraju par teoretskih pitanja, kako možemo optimirati mrežu, a da nije genetski algoritam, čemu služi funkcija dobrote i zašto koristimo mutacije.",
      "votes": {
        "upvoters": [
          "Krisle",
          "Me1 (Me)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202181": {
      "poster": "Krisle",
      "content": "@Fica#202151 Kako optimirati mrežu a da nije genetski algoritam?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202184": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Krisle#202181 Imaš puno postupaka, evo nekih poznatijih\n\n- podržano učenje (reinforcement learning)\n- propagacija unatrag, obično gradijentnim spustom i srodnim postupcima (backpropagation)\n- heuristički algoritmi (npr. za neuronske mreže bi vjerojatno bilo dobro simulirano kaljenje)\n- bruteforce (uz potencijalno nasumičnu pretragu)\n- beam search\n\nObično se radi s ova prva dva jer su se pokazali efektivnima. A generalno je treniranje mreže optimizacijski problem, pa teoretski možete koristiti bilo koji optimizacijski algoritam, dok god možete nekako ostvariti cilj mreže njime. Kod genetskog algoritma maksimizirate dobrotu. Kod podržanog učenja maksimizirate nagradu. Kod propagacije unatrag minimizarate pogrešku. I tako dalje...",
      "votes": {
        "upvoters": [
          "Bioxed",
          "Krisle"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202307": {
      "poster": "Me1 (Me)",
      "content": "Zoran Medić\n\nSlično kao kolegi, detaljno se prođe kroz kod, neka od pitanja: opisati kako funkcionira neuronska mreža(od čega se sastoji i opisati jedan prolaz unaprijed), zašto koristimo prijenosne funckije i koje još postoje osim sigmoidalne, objasnit učenje perceptrona, kako bi implementirao mutaciju kod klasifikacijskog problema",
      "votes": {
        "upvoters": [
          "Bioxed",
          "Krisle"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202316": {
      "poster": "Me1 (Me)",
      "content": "@Me1#202307 ne kako bi mutaciju, nego kako bi križanje kod klasifikacijskog problema",
      "votes": {
        "upvoters": [
          "Krisle"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202517": {
      "poster": "Bioxed",
      "content": "@Me1#202316 \n\nŠto je odgovor ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202684": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "Kaj je na kraju s autograderom za ovu vjezbu? jel utjece ikako na bodovanje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202822": {
      "poster": "SwingWorker",
      "content": "@bodilyfluids#202684 Autograder postoji ali ne utjece bas na bodove. Ja sam slucajno hardkodirao broj iteracija pa je sve padalo ali sam nakon odgovaranja dobio skoro pa sve bodove",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202823": {
      "poster": "SwingWorker",
      "content": "Martin Tutek \n\nProc detaljno kroz kod i nekoliko pitanja za genetski algoritam. Tipa zasto postoji mutacija, kako biramo roditelje.\n\nI jos me pitao zasto je vazno uvesti nelinearnost pomocu sigmoidne funkcije.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202948": {
      "poster": "nnn (dinoo)",
      "content": "Je itko išao na labos, a da je napravio samo prvi dio sa neuronskim mrežama i da je dobio bodove neke?",
      "votes": {
        "upvoters": [
          "Artemis"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "202958": {
      "poster": "gladiator",
      "content": "Koja je procedura ako nisam predao labos (čak imam dovoljno bodova za prolaz predmeta)? Da se javim asistentu da me već sada izbaci iz grupa za odgovaranje labosa na teamsu ili da čekam svoj termin?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "203002": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@gladiator#202958 Pa samo nemoj doc na usmeni",
      "votes": {
        "upvoters": [
          "__builtin_popcount (std::popcount)",
          "gladiator"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "203281": {
      "poster": "Krisle",
      "content": "Ekipa, no struggle, dobit ćete bodove ak ste samo prvi dio. \n\nPreporuke ak će neko gledat iduće godine - riješite labos. \n\nNatjerat će vas malo naučit o neuronskim i genetskim, a prvi dio mi je u Pythonu imao 10 linija koda efektivnih (preporuka da probate ovaj lab u Pythonu ak možete).\n\nDrugi dio je gospon @benac#201619 lijep pseudokod napisao i samo po tom rokajte, funkcije mutacije, selekcije i križanja ćete skombinirati iz skripti najlakše. \n\nGg wp, ćao umjetna",
      "votes": {
        "upvoters": [
          "Ducky",
          "Retard00",
          "Wayk",
          "nnn (dinoo)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "203443": {
      "poster": "viliml",
      "content": "@Krisle#203281 Ja sam nikoji labos nisam niti razmatrao ikoji jezik osim Pythona čisto iz razloga što je on jedini koji ima parsiranje command line argumenata u standardnoj biblioteci. Nema tog boga da bih to ručno radio.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "203454": {
      "poster": "Fikalo",
      "content": "@viliml#203443 a mislim nes ti parsiranja, samo jedan switch case",
      "votes": {
        "upvoters": [
          "Gulbash",
          "__builtin_popcount (std::popcount)",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "203656": {
      "poster": "bega (brga)",
      "content": "jel itko imao situaciju da mu kod ispisuje (krivo), ima sve kaj treba imat ali to sve skupa ne radi baš? znam teoriju dosta dobro, ali mi treba 20 bodova da mogu proć labose.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "tuga": []
      }
    },
    "203666": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@bega#203656 To ti ovisi i o asistentu, ali na nekim labosima su bili opušteni oko toga. Sad, jel bi ti dali 20/24 za nefunkcionalan labos, eeeee, to je teže odgovoriti. Prije reworka labosa je 2. labos, s logikom, bio dosta zeznut. Nekim ljudima nije uopće ni radio, nekima jedva. Ja sam imao par slučajeva gdje je padao na retardirane načine koji su nasmijali asistenta, ali bio je generalno funkcionalan i nakon ispitivanja sam dobio sve bodove. Tak da moguće je, ali opet ovisi.",
      "votes": {
        "upvoters": [
          "bega (brga)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "203688": {
      "poster": "kix7 (Fish99)",
      "content": "zasto nekim ispitivacima treba po 13 min za dvije osobe i onda se po pola sata ne javljaju? Jel itko tu odgovaro vise od 20 min?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "203993": {
      "poster": "Jokke",
      "content": "@viliml#203443 ![](assets/2021-06-09/00033.jpeg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "iNavy (mornar Ica)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "204000": {
      "poster": "viliml",
      "content": "@Jokke#203993 Ako si sve napravio u C++, kul. I ja bih tako da mi je malo više volje i nadobudnosti preostalo.\n\nZnaš što je stvarno pathetic? Java.",
      "votes": {
        "upvoters": [
          "Jokke",
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Ducky",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "204004": {
      "poster": "Bioxed",
      "content": "@viliml#204000 \n\nhttps://www.youtube.com/watch?v=7xWnKPHp3co",
      "votes": {
        "upvoters": [
          "Jokke",
          "benac (caneb)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "204098": {
      "poster": "Gulbash",
      "content": "@viliml#204000 Nemoj da te Čupić čuje 😨",
      "votes": {
        "upvoters": [
          "Bioxed",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "blablajar"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "207794": {
      "poster": "[deleted]",
      "content": "ajde priznajte, tko je ovo predao 😀 \n\nhttps://twitter.com/mtutek/status/1403290550820814853",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Ardura (Maddy)",
          "DariolaVremenskiPutnik",
          "Ducky",
          "Fica (Prof)",
          "Gulbash",
          "HARAmara (decko_sa_balkana)",
          "Haki",
          "Jale (čakijale)",
          "Krisle",
          "Lusy (MGJ)",
          "Lyras",
          "Me1 (Me)",
          "Retard00",
          "Svarog (Veles)",
          "__builtin_popcount (std::popcount)",
          "gladiator",
          "ice",
          "in1",
          "kix7 (Fish99)",
          "lucylu",
          "member",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
          "mihamih",
          "nnn (dinoo)",
          "sheriffHorsey",
          "snowman",
          "viliml"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "224551": {
      "poster": "Ducky",
      "content": "![](assets/2021-07-22/00003.png)\n\nJel iko skužio zašto su ovolko velike greške?\n\nMoj postupak:\n\nx=3.469, y=-0.795, w[]={-0.01, 0.01}\n\npo formuli s=x* w+w0 ispada s=3.469* (-0.03988)+0.00204=-0.011792\n\nsigm(s)=1/(1+exp(-s))=0.49705\n\ni tak 5 puta, pa nastanu svi brojevi oko 0.5\n\ny'=x5* w5+x4* w4+x3* w3+x2* w2+x1*w1+w0=0.02134\n\nkada bi gledali samo taj primjer, err=(y-y')^2=0.66641\n\n0.66641 je daleko od 0.00291 jer je 0.02134 (y') daleko od -0.795 (y) i tako bude za svaku vrijednost, ali ne znam što točno radim krivo u postupku",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "224860": {
      "poster": "tomekbeli420",
      "content": "Zašto",
      "votes": {
        "upvoters": [
          "JoKing",
          "Krisle",
          "gladiator",
          "kix7 (Fish99)",
          "miss_anthropocene (neunist.iva)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "AK10 (endyyyy)",
          "JoKing",
          "TheNubKiller (Lumpy)",
          "gladiator",
          "iNavy (mornar Ica)",
          "kix7 (Fish99)",
          "miss_anthropocene (neunist.iva)",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "225133": {
      "poster": "Ducky",
      "content": "@tomekbeli420#224860 Nisam moro, pa sam hito vidit jel mogu\n\nSpojler: Ne mogu!",
      "votes": {
        "upvoters": [
          "nnn (dinoo)",
          "steker",
          "tomekbeli420"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "225166": {
      "poster": "steker",
      "content": "@Ducky#225133 cijenimo vas trud kolega",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "225170": {
      "poster": "tomekbeli420",
      "content": "@Ducky#225133 \n\nPohvala za hrabrost kolega",
      "votes": {
        "upvoters": [
          "Ducky",
          "Krisle",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}