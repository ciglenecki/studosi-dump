{
  "title": "[STRUCE1] Gradivo",
  "creator": "Stark",
  "slug": "struce1-gradivo",
  "tags": [
    "FER",
    "Strojno uƒçenje 1"
  ],
  "posts": {
    "59040": {
      "poster": "Stark",
      "content": "U nadi da nisam jedini koji ima ovo za polo≈æiti na jesenskim rokovima, i da ima ljudi koji imaju volje sudjelovati, otvaram ovu temu. Mislim da je zgodnije da imamo jednu temu za oba jesenska roka jer su meƒëusobno blizu, pa da se pitanja ne ponavljaju. \n\nMo≈æe pomoƒá s b) zadatkom?\n\n![](assets/2020-08-09/00001.jpeg)\n\nKoliko shvaƒáam, prostor inaƒçica su sve hipoteze koje ispravno rade klasifikaciju. To su sve one za koje vrijedi da je x>=w? I kako odrediti VS?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "59054": {
      "poster": "InCogNiTo124",
      "content": "> @Stark#59040 To su sve one za koje vrijedi da je x>=w?\n\nDa\n\n> @Stark#59040 kako odrediti VS?\n\nPomocu [ovoga](https://en.m.wikipedia.org/wiki/Version_space_learning) to je broj svih `w` koji dobro odjeljuju dataset, a to je interval <4, 6]",
      "votes": {
        "upvoters": [
          "ALovelace",
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "59278": {
      "poster": "Stark",
      "content": "Vektor optimalnih te≈æina je okomit na ovaj crte≈æ i prolazi ovom sredi≈°njom crvenom toƒçkom?![](assets/2020-08-10/00012.jpeg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "59394": {
      "poster": "InCogNiTo124",
      "content": "@Stark#59278 ne, vektor optimalnih tezina je vektor koji spaja ishodiste i upravo tu crvenu tocku te lezi u ravnini crteza",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "59462": {
      "poster": "Stark",
      "content": "Kako se izraƒçuna ovo pod c)? Nisam nigdje na≈°ao a nemam ideju kako.\n\n ![](assets/2020-08-11/00024.jpeg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "59503": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@Stark#59462 \n\n[math]\n\\begin{aligned}\n&\nsoftmax \\left(\n\\begin{bmatrix}\n1 & 1 & 1 & 1\n\\end{bmatrix}\n\n\\times\n\n\\begin{bmatrix}\n1 & 4 & -2 \\\\\n2 & 4 & -3 \\\\\n2 & 1 & 4 \\\\\n3 & 0 & 5\n\\end{bmatrix}\n\\right)\n\n= \\\\\\\\\n\n&\nsoftmax \\left(\n\\begin{bmatrix}\n8 & 9 & 4\n\\end{bmatrix}\n\\right)\n\n= \\\\\\\\\n\n&\n\\begin{bmatrix}\n0.268 & 0.727 & 0.005\n\\end{bmatrix}\n\n\n\\end{aligned}\n[/math]\n\nOvo se nalazi vi≈°e manje u 7. natuknicama s predavanja",
      "votes": {
        "upvoters": [
          "Red_Baron",
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "60952": {
      "poster": "Stark",
      "content": "Opƒáenito me dosta bune ovi zadaci kad treba nacrtati pogre≈°ku uƒçenja i ispitnu pogre≈°ku. Znam kako izgleda nazovimo to defaultni graf s prvog predavanja ali kad ulaze ovi hiperparametri nije mi jasno. Vidim da ima dosta takvih zadataka pa ako bi netko mogao objasniti bio bih zahvalan.\n\n![](assets/2020-08-17/00018.jpeg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "61826": {
      "poster": "Nabas",
      "content": "Kako se rje≈°avaju Bayesove mre≈æe? Ima negdje postupak, primjer? U google dokumentu od domaƒáe zadaƒáe i ishoda uƒçenja nema.\n\nTreƒái zadatak ZI 19/20, sliƒçan je i u ZIR 2020\n\n![](assets/2020-08-20/00009.png)",
      "votes": {
        "upvoters": [
          "ALovelace"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "62397": {
      "poster": "InCogNiTo124",
      "content": "# TUTORIAL\n## Uƒçenje Bayesove mre≈æe (PGM) iz dataseta\n\nZa potrebe ovog tutoriala izmislio sam svoj neki model i u numpyju generirao dataset. To radim da a) imate ovaj gore zadatak za vjezbu (jer je zadatke **izgleda nemoguƒáe za naci na internetu**) i b) ovaj moj je opƒáenitiji. Takoder, molio bih da sve sto sam napisao provjerite i da se moguce greske prijave ili meni ili administratoru ili pritiskom na objavu->prijavi pa da se popravi.\n\n### Problem:\nZajednicka distribucija raspisana je na sljedeci nacin:\n\n[imath]P(A,B,C,D) = P(A)P(B | A)P(C | A,B)P(D|C)[/imath] \n\nNauciti parametre pomocu sljedeceg dataseta:\n\n[math]\n\\begin{array}{ |c|c|c|c| }\nA & B & C & D \\\\\n\\hline\n0 & 3 & 1 & 1 \\\\\n1 & 3 & 1 & 0 \\\\\n1 & 1 & 0 & 1 \\\\\n1 & 2 & 1 & 0 \\\\\n1 & 1 & 1 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 3 & 1 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n1 & 2 & 1 & 1 \\\\\n1 & 3 & 0 & 0 \\\\\n0 & 2 & 1 & 1 \\\\\n0 & 2 & 0 & 0\n\\end {array}[/math]\n\n#### Zadatak 1\n[u]Nacrtati model[/u]\n>! ![](assets/2020-08-21/00032.svg)\n\n#### Zadatak 2\n[u] Nauciti distribucije varijabli pomocu dataseta. [/u]\n\nPrvo ponavljanje ViSa, sto je (diskretna) distribucija? To je u biti tablica s jednim retkom, gdje stupci odgovaraju vrijednostima, a u tablici se nalaze odgovarajuce vjerojatnosti stupaca. Suma svih vrijednosti u jednom retku mora biti, dakako, 1.\n\nZadatak se rjesava redom, od prvog cvora ka ostalima (haha streberi bi rekli topoloski sortiranim grafom). Tako se u ovom slucaju prvo odreduje distribucija od A. A moze poprimiti samo 2 vrijednosti, 0 ili 1, od toga 8 jedinica a 4 nule. Therefore\n\n[math]\nA \\sim\n\\begin{array}{ c|c }\n0 & 1 \\\\\n\\hline\n4 & 8\n\\end{array}\n[/math]\n\nPazljivi citatelj ce primjetiti \"cekaj malo pa suma u retku nije 1\" i to je istina. Razlog za to je osobni: ja uvijek prvo popisem brojnost svih vrijednosti pa onda na kraju kad sve provjerim, samo dodam `/12` ili koji vec broj. Drugi razlog je Laplaceovo zagladivanje - ali to necemo sad spominjat sve do samog kraja.\n\nOkej sad, kad imamo [imath]P(A)[/imath], iduca je po redu [imath]P(B)[/imath]. No, ovaj puta ona ne dolazi sama - ona je uvjetovana varijablom A. Kako se to odra≈æava na njenu tablicu distribucije? Pa jako puno u biti - vise nema samo jedan redak, vec je jedan redak _po mogucoj realizaciji uvjeta_. Da ponovim: tablica uvjetne distribucije neke varijable ima onoliko redova koliko njen uvjet ima razlicitih vrijednosti. To znaci da ce nam tablica [imath]P(B|A)[/imath] imati dva retka, a stupaca koliko ona ima razlicitih vrijednosti (tocno 3).\n\nPrvo uzmemo, recimo, kad je uvjet A=0 ispunjen (konkretno 1, 8, 11, 12 redak (ako retke indeksiramo od 1 \\:) )). Vidimo da se B realizirala jednom kao 3, triput kao 2 i nijednom kao 1. Pravimo tablicu:\n\n[math]\nB|A \\sim\n\\begin{array}{ c||c|c|c }\nA & 1 & 2 & 3 \\\\\n\\hline\n0 & 0 & 3 & 1\n\\end{array}\n[/math]\n\nA sad gledamo sve one retke di je uvjet A=1 ispunjen. Ovdje se pak B realizirala triput kao 1, dvaput kao 2 i triput kao 3. Dakle nadopunjujemo nasu tablicu:\n\n[math]\nB|A \\sim\n\\begin{array}{ c||c|c|c }\nA & 1 & 2 & 3 \\\\\n\\hline\n0 & 0 & 3 & 1\\\\\n1 & 3 & 2 & 3\n\\end{array}\n[/math]\n\nSanity check - suma svih vrijednosti je 12, sto je jednako svim broju primjera. All gucci. Prije iduce varijable, kratka neobavezna digresija:\n>! Ovo nekog mozda podsjeti na zajednicku distribuciju dvije varijable [imath]P(A, B)[/imath] i to i nije toliko daleko od istine jer su obje tablice, u biti, funkcija od dvije varijable (i zbog tog dvije dimenzije ([imath]P(A)[/imath] je imala samo jednu dimenziju \\:) ) Razlika je u tome sto u tablici zajednicke distribucije suma bas svih elemenata mora bit 1, dok je u uvjetnoj suma jednog retka 1. No, zasad ionako samo pisemo brojnosti\n\nMoving on. E sad problem moze biti sto ovaj put varijabla ima dva roditelja, stoga ponavljam recenicu:\n> @InCogNiTo124#62397  tablica uvjetne distribucije neke varijable ima onoliko redova koliko njen uvjet ima razlicitih vrijednosti\n\nKoliko razlicitih vrijednosti mogu imati A i B? Odgovor je velicina skupa koji je kartezijev produkt skupova domene slucajnih varijabli A i B. Fensi rjeƒçnik za reƒái [imath]2 \\cdot 3 = 6[/imath]. Dakle, plan rada je ic po svim kombinacijama A i B i pisat kakve se sve vrijednosti od C pojavljuju. Sad necu vise ici korak po korak, nego cu u spojler stavit rjesenje. Napominjem kako je ful bitno pokusati samostalno rijesiti.\n>! SAJK! fkt je bitno da solo probas rijesit. ako ti je samo do tocnog rjesnja, osudujem. Ako pak imas rjesenje, nadam se da sam stavio smjesak na tvoje lice i izvinjavam se zbog neugodnosti\n\n\n>! [math]\nC|A,B \\sim\n\\begin{array}{ c|c||c|c }\nA & B & 0 & 1  \\\\\n\\hline\n0 & 1 & 0 & 0\\\\\n0 & 2 & 2 & 1\\\\\n0 & 3 & 0 & 1\\\\\n1 & 1 & 2 & 1\\\\\n1 & 2 & 0 & 2\\\\\n1 & 3 & 1 & 2\\\\\n\\end{array}\n[/math]\n\n> Yet another sanity check, suma vrijednosti u desnom dijelu tablice je 12 kao sto bi i trebao biti\n\n> Also fun fact: s obzirom da imamo cak 2 uvjeta, ovo bi u teoriji trebao biti tenzor treceg reda (kao matrica samo kockica) no ovo je kakti ispeglani prikaz tog istog tenzora. All is still gucci.\n\nI sad zadnja tablica, D uvjetovan po C, ako ste prezivili proslu tablicu ova je komadiƒá torte. Ukratko, opet ista stvar, idemo po uvjetu, gledamo njegove vrijednosti i gledamo koliko se dogodilo kakvih realizacija nase ciljne varijable.\n\n[math]\nD|C \\sim\n\\begin{array}{ c||c|c }\nC & 0 & 1  \\\\\n\\hline\n0 & 4 & 1\\\\\n1 & 4 & 3\n\\end{array}\n[/math]\n\nI za kraj su nam ostale dvije stvari. Prva je to \"zloglasno\" Laplaceovo zagladivanje koje je u biti najlaksa stvar na svijetu - samo idete po svim brojevima u svim tablicama i dodate +1. Zasto se to radi? Najbolje je objasnit na primjeru uvjetne distribucije [imath]P(B|A)[/imath]. Naime u nasem datasetu se nikad nije pojavilo dogadaj [imath]A=0 \\land B=1[/imath]. Znaci li to da se to nikad _nikad **nikad**_ nece desit? pa ne bas - vise je vjerojatno da imamo sh\\*tan sampling. Zbog tog pretpostavimo da su se svi dogadaji bar jednom desili. To je nase vjerovanje - nasa pristranost, takoder pod nazivom prior probability. To je ono sto vjerujemo da je istina _bez da ista znamo o stvanom svijetu_. Onda taj nas prior napadnemo s nasim podacima, i dobimo nesto izmedu, tzv. posterior. Novi fun fact:\n>! Kakve veze Laplace ima s time? pa on je u biti takoreci izmislio cijelo podrucje vjerojatnosti i dokazao brdo teorema i svasta. Jedan dan su ga iz fore pitali \"ej cika pjer, a kolka je vjerojatnost da ce sutra svanut sunce?\" a on se tog ozbiljno uhvatio. Na kraju je rekao da problem nije moguce rjesiti bez nekih dodanih pretpostavki te je kao odgovor predlozio [imath]1 - \\frac1{n+1}[/imath] gdje je [imath]n[/imath] broj dana koji su prosli od pocetka svemira. Tako da, dosta su velike sanse da ce se ovaj ispit ipak pisat, ali opet nisu bas 100% üòõ\n\n\n\nI zadnja stvar koja nam je ostala je sad sve te tablice (s dodanim jedinicama!) pretvorit u [u]actual[/u] distribucije na nacin da dijelimo svaki redak sa sumom u tom retku. Rezultati se nalaze u spoileru:\n>! [math]\nA \\sim\n\\begin{array}{ c|c }\n0 & 1 \\\\\n\\hline\n\\frac{5}{14} & \\frac{9}{14}\n\\end{array}\n[/math]\n\n[math]\nB|A \\sim\n\\begin{array}{ c||c|c|c }\nA & 1 & 2 & 3 \\\\\n\\hline\n0 & \\frac17 & \\frac47 & \\frac27\\\\\n1 & \\frac4{11} & \\frac3{11} & \\frac4{11}\n\\end{array}\n[/math]\n\n[math]\nC|A,B \\sim\n\\begin{array}{ c|c||c|c }\nA & B & 0 & 1  \\\\\n\\hline\n0 & 1 & \\frac12 & \\frac12 \\\\\n0 & 2 & \\frac35 & \\frac25\\\\\n0 & 3 & \\frac13 & \\frac23\\\\\n1 & 1 & \\frac35 & \\frac25\\\\\n1 & 2 & \\frac14 & \\frac34\\\\\n1 & 3 & \\frac25 & \\frac35\\\\\n\\end{array}\n[/math]\n\n[math]\nD|C \\sim\n\\begin{array}{ c||c|c }\nC & 0 & 1  \\\\\n\\hline\n0 & \\frac57 & \\frac27\\\\\n1 & \\frac59 & \\frac49\n\\end{array}\n[/math]\n\nUmro sam dok sam sve ovo pretipko u [imath]\\LaTeX[/imath] üôÉ",
      "votes": {
        "upvoters": [
          "Bananaking",
          "Emma63194",
          "Franksta",
          "Nabas",
          "Red_Baron",
          "Stark",
          "basic919 (byk)",
          "data",
          "kix7 (Fish99)",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "62569": {
      "poster": "Nabas",
      "content": "@InCogNiTo124#62397 Hvala puno na tutorialu. Kad je pitanje procjenite MAP procjeniteljem npr. ovdje P(C|A,B) odgovor bi bio C=1 za A=1 i B=2 jer je vjerojatnost 0.75?",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "62591": {
      "poster": "InCogNiTo124",
      "content": "@Nabas#62569 da, tako je",
      "votes": {
        "upvoters": [
          "Nabas"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "67073": {
      "poster": "Stark",
      "content": "Za ovaj zadatak\n\n![](assets/2020-09-05/00011.jpeg)\n\nKako bi i≈°ao crte≈æ? Nekako ovako? Svi su linearni osim logistiƒçke?\n\n![](assets/2020-09-05/00012.jpeg)\n\nI onda kad se doda primjer (8,1) koji je duboko u podruƒçju crvenih, ≈°to se dogodi? \n\nEvo ako treba prazna slika za crtanje:\n\n![](assets/2020-09-05/00013.jpeg)",
      "votes": {
        "upvoters": [
          "andiamo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "67230": {
      "poster": "[deleted]",
      "content": "@Stark#67073 Buduƒái da prilikom kori≈°tenja linearne regresije kao klasifikatora primjeri koji su ispravno klasificirani isto tako budu ka≈ænjeni i to ≈°to su \"ispravnije\" klasificirani, to ƒáe biti vi≈°e ka≈ænjeni, funkcija linearne regresije ƒáe se pomaknuti prema tom primjeru kao bi se smanjilo kvadratno odstupanje. Svi ostali ƒáe ostati (vi≈°e-manje) isti.",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "67613": {
      "poster": "Red_Baron",
      "content": "@Stark#67073 Mislim da linearna regresija nije dobra na slici. Puno bi bolja bila funkcija y=2; ona dakle prolazi kroz skroz lijevu toƒçku, a kod ostalih minimizira udaljenost; time je ukupna pogre≈°ka 2 (ako me matematika ne vara), a po ovom tvojem je 4 (opet, ako me mentalna matematika ne vara).",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "80351": {
      "poster": "a_ko_si_ti",
      "content": "Di se nalazi kviz o kojem je profesor pricao?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "89869": {
      "poster": "[deleted]",
      "content": "![](assets/2020-11-08/00009.png)\n\nƒåini mi se da bi se ovisno o odabiru hipoteza na ovo pitanje moglo odgovoriti i sa c i sa d. Recimo ako prva hipoteza odvaja 3 pozitivna i 2 negativna + 1 pozitivan uljez, a druga margina odvaja jedan negativan i 4 pozitivna + 1 negativan uljez, tada bi odgovor bio pod c. Ako bi prva hipoteza odvajala isto kao druga, ali s drugim negativnim primjerom, tada bi toƒçan odgovor bio pod d. Je li to zaista tako?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "89912": {
      "poster": "Svarog (Veles)",
      "content": "@gentleman#89869 Neka me netko ispravi ako sam napravio negdje lapsus, ali evo mog obrazlo≈æenja za≈°to je d.\n\nPrvo, primijetimo da je skup primjera linearno neodvojiv, stoga prvi model nikada neƒáe moƒái toƒçno klasificirati sve primjere. S druge strane, ako bi mogli koristiti dvije hipoteze iz prvog modela, tj. ravnine, onda bi u potpunosti toƒçno klasificirali sve primjere koristeƒái presjek potprostora koje te dvije ravnine omeƒëuju. Presjek ta dva potprostora mo≈æemo, koristeƒái indikatorske funkcije, predstaviti s mno≈æenjem te dolazimo do ovog drugog modela koji je upravo to. Zbog toga ≈°to ƒáe postupak optimizacije egzaktno pronaƒái optimalnu hipotezu, zakljuƒçujemo da drugi model mo≈æe u potpunosti toƒçno klasificirati ovaj skup primjera i slijedno tomu klasificira strogo toƒçnije u odnosu na prvi model.",
      "votes": {
        "upvoters": [
          "Bananaking",
          "Cvija",
          "Emma63194",
          "Red_Baron",
          "[deleted]",
          "in1",
          "member",
          "mikimoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "89920": {
      "poster": "[deleted]",
      "content": "@Svarog#89912 \n\n> @Svarog#89912 Zbog toga ≈°to ƒáe postupak optimizacije egzaktno pronaƒái optimalnu hipotezu\n\nSmetnuo sam s uma da bi optimizacijski postupak prona≈°ao upravo taj sluƒçaj koji odgovara odgovoru d, hvala!",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "89922": {
      "poster": "Cvija",
      "content": "Evo moja pitanja i odgovori s prvog moodle kviza. Imamo li svi ista pitanja ili su se nekome pojavila i druga?\n\n![](assets/2020-11-08/00012.png)\n\n![](assets/2020-11-08/00013.png)\n\n![](assets/2020-11-08/00014.png)\n\n![](assets/2020-11-08/00015.png)\n\n![](assets/2020-11-08/00016.png)\n\n![](assets/2020-11-08/00017.png)\n\n![](assets/2020-11-08/00018.png)\n\n![](assets/2020-11-08/00019.png)\n\n![](assets/2020-11-08/00020.png)\n\n![](assets/2020-11-08/00021.png)\n\n![](assets/2020-11-08/00022.png)\n\n![](assets/2020-11-08/00023.png)\n\n![](assets/2020-11-08/00024.png)\n\n![](assets/2020-11-08/00025.png)\n\n![](assets/2020-11-08/00026.png)",
      "votes": {
        "upvoters": [
          "Cubii",
          "Emma63194",
          "Noggenfogger (dammitimmad)",
          "Red_Baron",
          "Simpy",
          "neja_negoti",
          "setuid0"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90169": {
      "poster": "Emma63194",
      "content": "@Cvija#89922 Svi imamo ista pitanja.",
      "votes": {
        "upvoters": [
          "Cvija"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90273": {
      "poster": "Yeltneb",
      "content": "Za≈°to ovdje d) nije isto toƒçno? \n\n![](assets/2020-11-09/00013.png)",
      "votes": {
        "upvoters": [
          "Cubii",
          "rockymus (Daniel Plainview)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90310": {
      "poster": "InCogNiTo124",
      "content": "@Yeltneb#90273 ja mislim da ne mozes znat hoce li generalizrati bolje jer je sum u podacima velik, a ovo je vrlo jaka regularizacija",
      "votes": {
        "upvoters": [
          "Yeltneb"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90519": {
      "poster": "tito",
      "content": "kako se najbolje pripremiti za ispit, imajuƒái na umu da je na zaokru≈æivanje",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90540": {
      "poster": "Emma63194",
      "content": "Zna mo≈æda netko objasniti ovak zadatak?\n\nNisam sigurna kako su do≈°li do tih te≈æina, niti kako opƒáe pristupiti zadatku. \n\n![](assets/2020-11-10/00011.png)",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90565": {
      "poster": "InCogNiTo124",
      "content": "@\"Emma63194\"#p90540 ma taj je lagani kjut zadatak haha\n\nPrvo krenimo od dataseta koji je generiran onom Gaussovom razdiobom, onaj izraz ti je pravac kojeg bi kao trebala dobit da ti je loss funkcija dobra, to je stvarni pravac\n\nNo, nemas dobru loss funkciju.\n\nDoduse, fear not, jer ako se samo malo algebarski poigras, (y + h(x))^2 = (y - (-h(x))^2, odnosno, efektivno ucis nad podacima koji su flipani oko x osi.\n\n(Alternativno, loss ti moze biti i (h(x) - (-y))^2 gdje se bolje vidi da y mjenja predznak. Razmisli zasto)\n\nE sad ostavljam tebi za vjezbu da nades jednazbu pravca koji nastane flipanjem ovog zadanog u Gaussovoj oko x osi\n\nEdit: nisam objasnio odakle tezine, pliz napravi korespondenciju izmedu tog kak ti izgleda hipoteza i kak ti izgleda pravac, i trebala bi moci matchat iz tog sta ti je w0 a sta w1",
      "votes": {
        "upvoters": [
          "Emma63194",
          "Fran_- (random_trooper)",
          "Noggenfogger (dammitimmad)",
          "Stark",
          "[deleted]",
          "in1"
        ],
        "downvoters": [
          "Juren"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90810": {
      "poster": "rockymus (Daniel Plainview)",
      "content": "@InCogNiTo124#90310 pa ba≈° zato ≈°to je ≈°um velik bi d) trebao biti toƒçan",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90818": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@rockymus#90810 Ne, jer ≈°um ti onemoguƒáava generalizaciju. Zapamti, ti na ≈°umu uƒçi≈°. Ako je ≈°um velik, uopƒáe ne mora≈° toƒçno uƒçiti. A s obzirom na to da ima≈° istu dimenzionalnost, isto se prenauƒçe, ovaj reguliziraniji se manje prenauƒçi (iako s tim faktorom se vjv ni ni≈°ta ne nauƒçi), ali za generalizaciju nema≈° pojma.",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "90843": {
      "poster": "InCogNiTo124",
      "content": "@rockymus#90810 da, samo zato sto je regularizacija velika ne znaci da model magicno dobro generalizira, veliki sum ti ubije sve",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91150": {
      "poster": "FICHEKK",
      "content": "Koja je zadnja lekcija koja ulazi u ispit?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "[deleted]"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91431": {
      "poster": "Cvija",
      "content": "https://www.mentimeter.com/s/df70e13555085506b871dc515e4f44cb/ce9e776fe49b\n\nhttps://www.mentimeter.com/s/38c974c6640c7520ad54fc83dd1f468b/e4860d794295\n\nhttps://www.mentimeter.com/s/4b3a322d9a5f54d7fd253a02518ac220/e77cdb7938c2\n\nhttps://www.mentimeter.com/s/f902613407ba3a6ab9778bde7b7d50e4/8262859a3f35\n\nhttps://www.mentimeter.com/s/781be9192b1e81635b6f73c40854512e/df1436b7dddf\n\nhttps://www.mentimeter.com/s/63d94575856c4b46e47284cd7f9eb3e3/9e974b9d4432\n\nhttps://www.mentimeter.com/s/4e525c01d764d0b3eada097d627d86c9/1e95be59ccaa\n\nhttps://www.mentimeter.com/s/c49df11f9b48e73acc50d814ef92148a/297af9dfbcf7\n\nhttps://www.mentimeter.com/s/a2ed2615daff6262eb076b0e6004dd38/d886773799f1\n\nhttps://www.mentimeter.com/s/5de36dbb4fb97f6dca1328d8b661d055/bacaa22dd274\n\nEvo tu su svi kvizovi",
      "votes": {
        "upvoters": [
          "Amali (Amajli)",
          "Amon",
          "Cubii",
          "Daorson",
          "Emma63194",
          "FICHEKK",
          "Fran_- (random_trooper)",
          "InCogNiTo124",
          "Joji",
          "Juren",
          "Longclaw",
          "Louverture (≈Ωuti Ki≈°obran)",
          "Njet",
          "Noggenfogger (dammitimmad)",
          "PrisonMike (≈†tevo)",
          "PudingIzMenze",
          "Stark",
          "Svarog (Veles)",
          "Vrba",
          "[deleted]",
          "chuuya (temari)",
          "in1",
          "johndoe12 (enaiks)",
          "koBASA (hackerman)",
          "member",
          "setuid0",
          "tito",
          "toni98",
          "tre_besty (luk)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91447": {
      "poster": "Bananaking",
      "content": "![](assets/2020-11-12/00004.png)\n\nMo≈æe mi netko pojasniti ovaj zadatak? Za≈°to alfa2 nije overfitan?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91461": {
      "poster": "[deleted]",
      "content": "@Bananaking#91447 ![](assets/2020-11-12/00008.png)\n\nMoguƒáe je da se u danoj situaciji nalazimo sa lijeve strane od optimalnog modela, oba su podnauƒçena. Jedino ≈°to znamo iz ovoga je da je razlika izmeƒëu gre≈°ke u uƒçenju i ispitivanju veƒáa kod hiperparametra [imath]\\alpha_2[/imath] nego kod [imath]\\alpha_1[/imath]",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91577": {
      "poster": "Hus",
      "content": "![](assets/2020-11-12/00020.png)\n\n![](assets/2020-11-12/00021.png)\n\n![](assets/2020-11-12/00022.png)\n\n![](assets/2020-11-12/00023.png)\n\nAko netko ima vremena objasniti ova 4 zadatka. Meni uopce nije jasno zas≈°to su ovo toƒçni odgovori.",
      "votes": {
        "upvoters": [
          "Cubii",
          "hi_doggy"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "hi_doggy"
        ]
      }
    },
    "91627": {
      "poster": "InCogNiTo124",
      "content": "@Hus#91577\n\nPrvi zadatak:\n\nAko si skiciras problem, vidit ces da je najbolji pravac koji dijeli ove dvije tocke zapravo pravac `y=x` odnosno u implicitnom obliku `-ax+ay=0` gdje je a neka konstanta, jer je implicitni oblik pravca invarijantnan na mnozenje skalarom (ekvivalent toga su homogene koordinate iz IRG-a ako se sjecas; ako ne jebiga).\n\nDruga informacija koju bi trebao znati je naci udaljenost od pravca do tocke: jedna lijepa slatka formula `d=h(x) / |w|`, gdje je `h(x)` izlaz hipoteze, a `|w|` norma vektora tezina. Udaljenost tocke od pravca znamo (ja znam da je `sqrt(2) / 2` a od tebe zahtjevam da ako ne znas napamet da izvedes iz geometrije) i lijepo u jednadzbu gore uvrstis neku tocku, recimo (0, 1): `sqrt(2) / 2 = (-a*0+a*1) / (sqrt((-a)**2 + (a**2))` i malo se poigras algebarski da dobis a. To ce ti bit jednako `w2`.\n\nNaravno ista stvar bi trebala doc kao rezultat i ako stavis drugu tocku, to je zato jer (a) matematika tako funkcionira (b) maksimizacija udaljenosti hiperravnine eksplicitno enkodira u nas problem da ce granica prepolavljat udaljenost te dve tocke, odnosno s lijeve i desne strane pravca ce bit ista udaljenost.\n>! ![](https://i.kym-cdn.com/photos/images/original/001/561/446/27d.jpg)\n\nDrugi zadatak:\n\nNadam se da si rjesavao drugi labos koji se ticao logisticke regresije, gdje si uzeo `wTx` i omotao to oko sigmoide. E sad, sigmoida je poprilicno nelinearna, ali granica koju si (trebao) dobiti je linearna. Zasto je tome tako? Zato jer su ti podaci unutar sigmoide linearni. Dakle, ako ti je funkcija PHI linearna, dobit ces linearnu granicu. Ako je nelinerna, i granica ce bit (perhaps surprisingly) nelinearna. Also, ako ti je PHI nelinearna, a aktivacija f linearna, ponovo granica nije linearna. Podaci su kljuc!\n\nTreci:\n\nVrlo mehanicki i brainless zadatak. Pomnozis W sa x i dobijes Wx ciji izlaz nazivamo \"logiti\" (nebitno). Od tih logita racuna se softmax tako da izracunas `exp()` za svaki element vektora, i onda skupa podijelis sa sumom. Softmax bi ti trebo ispast, ako nisam nesto sjebo, `(0.999, 1.026e-10, 1.67e-5)`. I sad treba samo uzet nas softmax vektor i vektor koji trebamo dobit i s njim u multiclass logistic loss ciju formulu imas u skriptama, labosima ili internetu. Jedino je eto problem sto ja dobijem broj 23 kao rjesenje koji nije ponuden tako da ne znam kj se desilo no postupak je okej haha\n\nCetvrti zadatak:\n\nadaptivne bazne funkcije == neuronska mreza s jednim skrivenim slojem. ulazni parametri imaju 10 varijabli, svaka adaptivna bazna funkcij ima dakle 10 tezina + 1 bias. Takvih adaptvnih baznih funkcija ima 4, dakle sve skupa 4(10+1) = 44. Zavrsili smo prvi sloj, ai time smo samo iz podataka izvadili znacajke, sto znaci da tek sad idemo u softmax. Znaci sad se pravimo da su ovih 4 \"pravi podaci\", dakle trebat ce nam jos 4 tezine i 1 bias. Sve skupa 44+5=49. Puno je lakse ako gledas slikicu i pratis sta se dogada nego ovak napamet rjesavat",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)",
          "Amon",
          "Anonimity (BoJack)",
          "Broono (Buruƒáuh)",
          "Daorson",
          "Emma63194",
          "FICHEKK",
          "Fran_- (random_trooper)",
          "Hus",
          "Juren",
          "Stark",
          "WhiteMamba",
          "[deleted]",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91649": {
      "poster": "Amali (Amajli)",
      "content": "@Cvija#91431 https://docs.google.com/document/d/1pCK4LPwiY9AZON6lZWK7vFXNB6UogtXnDSOYEmg1w0U/edit?usp=sharing prepisani tocni odgovori, bar koji su oznaceni tocno tam il se sjecam da je bio issue s pitanjem, al ne sjecam se bas svih koji su bili sporni",
      "votes": {
        "upvoters": [
          "Cvija",
          "Daorson",
          "InCogNiTo124",
          "Stark",
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91666": {
      "poster": "sphera",
      "content": "@InCogNiTo124#91627 kako onda na slici za softmax pi≈°e da je w indeksiran s j,k ≈°ta ne bi onda trebao w biti drugaƒçiji za razliƒçite klase, i za≈°to ako j ide od 0 mi svejedno na to dodamo bias, jel nije bias ukljuƒçen kao w0 kad je j=0",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91684": {
      "poster": "InCogNiTo124",
      "content": "@sphera#91666 prvo pitanje, svaki stupac u matrici W ti je jedan model za jednu klasu. Onda se oni svi skupe i pretvore softmaxom u distribuciju po klasama\n\nDrugo pitanje, to su sad vec detalji koji nisu nikad nigdje konzistentni, konkretno u ovom slucaju cini mi se da nema biasa pa da je prvi element od 0 indeksiran",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91728": {
      "poster": "Amali (Amajli)",
      "content": "> @InCogNiTo124#91627 Vrlo mehanicki i brainless zadatak. Pomnozis W sa x i dobijes Wx ciji izlaz nazivamo ‚Äúlogiti‚Äù (nebitno). Od tih logita racuna se softmax tako da izracunas exp() za svaki element vektora, i onda skupa podijelis sa sumom. Softmax bi ti trebo ispast, ako nisam nesto sjebo, `(0.999, 1.026e-10, 1.67e-5)`. I sad treba samo uzet nas softmax vektor i vektor koji trebamo dobit i s njim u multiclass logistic loss ciju formulu imas u skriptama, labosima ili internetu. Jedino je eto problem sto ja dobijem broj 23 kao rjesenje koji nije ponuden tako da ne znam kj se desilo no postupak je okej haha\n\nmeni isto ovo nije jasno, i ja dobijem \\~23 generickim softmax postupkom\n\njel itko to skuzio? jel mozda, slucajno, snajder sjebo?",
      "votes": {
        "upvoters": [
          "khm19 (ajmemeni5)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91730": {
      "poster": "InCogNiTo124",
      "content": "@Amali#91728 1.55 je najblizi 23 tak da je zato xD",
      "votes": {
        "upvoters": [
          "Amon",
          "Fran_- (random_trooper)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91733": {
      "poster": "Hus",
      "content": "@InCogNiTo124#91627 To je to! Hvala! (meni je isto ispadao u treƒáem 23 pa sam mislio da sam nesto tesko profulao oko gubitka i modela multinomijalne regresije, no izgleda da nisam jedini pa barem ne≈°to)",
      "votes": {
        "upvoters": [
          "Amali (Amajli)",
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91736": {
      "poster": "cotfuse",
      "content": "@Hus#91577\n\n4) Ovo prakticki opisuje neuronsku mrezu sa ulaznom dimenzijom 10, skrivenim slojem dimenzije 3 i izlaznim slojem dimenzije 4. Svaki od slojeva ima svoje biase, pa racunica ispada: [imath] (10+1)*3 + (3+1)*4 = 49 [/imath]\n\nOsim toga, ovaj zadatak koji je 3. kod husa, tocan odgovor je 23 i u medjuvremenu su promijenili odgovore tako da je sada i 23 ponudjeno.",
      "votes": {
        "upvoters": [
          "Vrba",
          "in1",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91741": {
      "poster": "Amali (Amajli)",
      "content": "@Amali#91728 sad sam drugi put pokrenula kviz i druga su rjesenja pod tim zadatkom, netko prijavio il oni skuzili I guess",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91742": {
      "poster": "member",
      "content": "![](assets/2020-11-12/00036.png)\n\nJa sam preko formule za gubitak mislila dobit h(x) ako uvrstim y=1/0, al naravno dobila bi dvije razliƒçite vrijednosti. A h(x) se ne mijenja pa bi onda y promijenila i dobila gubitak, al fali mi tu ne≈°to. Ne znam kako bi to do kraja haha",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91744": {
      "poster": "Amali (Amajli)",
      "content": "@member#91742 dobijes h(x) tak, ispast ce ti simetricni, i sam ih uvrsit u formulu koji god sa suprotnom oznakom od one za koju je dobiven (tipa za y = 1 dobijes jedan broj i taj iskoristis u loss funkciji u clanu za klasu 0. Koju god kombu uzmes dobit ces isto svakako)",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91854": {
      "poster": "tito",
      "content": "za≈°to funkcija pogre≈°ke ne konvergira kod linearne regresije kada su znaƒçajke linearno zavisne?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "91857": {
      "poster": "InCogNiTo124",
      "content": "@tito#91854 u tom slucaju ti matrica dizanja nema puni rang i pseudoinverz ne postoji",
      "votes": {
        "upvoters": [
          "Fran_- (random_trooper)",
          "tito"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92146": {
      "poster": "Bananaking",
      "content": "≈†to je onaj VS(H,D) ?",
      "votes": {
        "upvoters": [
          "MsBrightside"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92150": {
      "poster": "InCogNiTo124",
      "content": "@Bananaking#92146 version space, prostor inacica, je skup hipoteza koje na datasetu D imaju empirijsku pogresku 0. Takvih moze biti beskonacno.\n\nPrimjer ti je [tu na slici](url), ako su ti hipoteze pravokutnici, onda ti je zelena povrsina VS na example datasetu",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92224": {
      "poster": "Stark",
      "content": "Mo≈æe obja≈°njenje ovog? \n\n![](assets/2020-11-13/00040.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92229": {
      "poster": "Amon",
      "content": "@Stark#92224 Gore je kolega objasnio @Svarog#89912",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92263": {
      "poster": "Stark",
      "content": "@Amon#92229 Hvala, nisam uopƒáe sku≈æio da je veƒá bilo pitanje üòÖ",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92292": {
      "poster": "YenOfVen",
      "content": "Sto zadnje ulazi u ispit?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92308": {
      "poster": "Bananaking",
      "content": "@YenOfVen#92292 11 - Neparametarske metode",
      "votes": {
        "upvoters": [
          "YenOfVen"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92433": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "Je li mi mo≈æe netko molim vas objasniti kako se ovo rje≈°ava?\n\n14.\tKoristimo regresiju za predviƒëanje uspjeha studija na temelju prosjeka ocjena u ƒçetiri razreda srednje ≈°kole te uspjeha iz matematike i fizike na dr≈æavnoj maturi (ukupno 6 znaƒçajki). Za preslikavanje u prostor znaƒçajki koristimo polinom drugog stupnja s interakcijskim parovima znaƒçajki (samo parovi!). Pretpostavite da nema multikolinearnosti. Koliko minimalno primjera za uƒçenje trebamo imati, a da bi rje≈°enje bilo stabilno i bez regularizacije?",
      "votes": {
        "upvoters": [
          "Juren",
          "Stark",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92434": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@-Ivan-#92433 (znam da je odgovor 28, ali ne znam za≈°to)",
      "votes": {
        "upvoters": [
          "Juren",
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92453": {
      "poster": "InCogNiTo124",
      "content": "@-Ivan-#92433 mislim da je do tog da, kad uzmes n varijabli i preslikas ih polinomom drugog stupnja, dobijes n znacajki jednakih originalnim, n(n-1)/2 parova i n kvadrata, za n=6 to je 6+15+6=27 i jos bias za sve skupa 28 znacajki\n\nMinimalno toliko i primjera ti onda treba da ti matrica ima puni rang i da postoji (pseudo)inverz",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)",
          "doki",
          "happysun",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92468": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@InCogNiTo124#92453 Hvala lijepa üòÅ",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92507": {
      "poster": "Emma63194",
      "content": "> @InCogNiTo124#91627 Drugi zadatak:\n\n> Nadam se da si rjesavao drugi labos koji se ticao logisticke regresije, gdje si uzeo wTx i omotao to oko sigmoide. E sad, sigmoida je poprilicno nelinearna, ali granica koju si (trebao) dobiti je linearna. Zasto je tome tako? Zato jer su ti podaci unutar sigmoide linearni. Dakle, ako ti je funkcija PHI linearna, dobit ces linearnu granicu. Ako je nelinerna, i granica ce bit (perhaps surprisingly) nelinearna. Also, ako ti je PHI nelinearna, a PHI linearna, ponovo granice nije linearna. Podaci su kljuc!\n\nProƒçitala sam ovo nekoliko puta i razmislila o tome, ali zaista mi ne sjeda. \n\nNije mi jasno, ako imamo sigmoidu ili ako je npr. f neka jako divlja nelinearna funkcija (≈°ta ja znam, sinusi, kosinus, apsolutne vrijednosti, ≈°ta se veƒá sve da skombinirati u jednu funkciju), kako unatoƒç tome funkcija uspije dati neku linearnu granicu samo zbog toga ≈°to su podaci linearni?",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92601": {
      "poster": "TentationeM",
      "content": "≈†to mislite odgovaraju li ovi moodle kvizovi te≈æini pitanja na MI?",
      "votes": {
        "upvoters": [
          "Stark",
          "narval13068 (Dima)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92604": {
      "poster": "InCogNiTo124",
      "content": "@Emma63194#92507 ovo je u biti dobro pitanje, nadao sam se da cete ili uzet to as is, ili ce nekom neka matematicka intucija pomoc, al zaista nije u redu od mene da to ne objasnim.\n\nKratak odgovor: nelinearnost je u ortogonalnoj dimenziji pa se \"ne broji\". Dugi odgovor slijedi u nekoliko skrinova ispod:\n\nOvo je sigmoida od linearne kombinacije:\n>! ![](assets/2020-11-14/00017.png)\n\n ovdje su mi a i b neke \"tezine\", a f je sigmoida, nebitno. Bitno je da bi sad klasifikacijska granica bila f(x)=0.5, odnosno presjekli bi ovu plohu sa ravninom z=0.5. Tebi prepustam da si zamislis sto bi dobila: odgovor je lijepi ravni pravac. Razlog tome je sto je funkcija nelinearna kad se gleda po z dimenziji, dok je linearna kad se gleda u x-y dimenzijama.\n\n\nNovi primjer:\n>! ![](assets/2020-11-14/00018.png)\n\nOvdje ako obratis pozornost na ulaz u sigmoidu, vidit ces da sam promjenio tako da sam dodao \"interakcijsku znacajku\" - fensi rijec za nelinearnost. Radimo opet istu stvar, presjeces povrsinu sa ravninom z=0.5 i kj dobis ovaj put? ERMAGERD pa crta koju dobis vise nije linearna!! Upravo zbog podataka haha\n\nZadnji primjer:\n>! ![](assets/2020-11-14/00019.png)\n\nSad sam dodao kvadrate i vidi sta se dobi, slatki mali bulge ^^ naravno kad bi ovo cudo sad presjekla sa z=0.5 dobila bi neku kruznicu. Y iz that? opet nelinearno, samo zato jer su znacajke nelinearne.\n\n\nTLDR linearna kombinacija znacajki daje linearnu granicu (nakon sto plohu presjecemo ravninom) cak i uz nelinearnu aktivaciju. Ako je kombinacija znacajki nelinearna, granica ce bit nelinearna.",
      "votes": {
        "upvoters": [
          "Cvija",
          "Emma63194",
          "Stark",
          "WhiteMamba",
          "[deleted]",
          "in1",
          "member",
          "neja_negoti",
          "saitama"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92743": {
      "poster": "Yasuke (Bono)",
      "content": "Ako mo≈æe neko pls objasnit koji je toƒçan odgovor ovdje? \n\n![](assets/2020-11-14/00032.png)\n\nI ovaj takoƒëer\n\n![](assets/2020-11-14/00033.png)",
      "votes": {
        "upvoters": [
          "Emma63194",
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92772": {
      "poster": "koBASA (hackerman)",
      "content": "![](assets/2020-11-14/00038.png)\n\nMo≈æda ovaj netko?",
      "votes": {
        "upvoters": [
          "Stark",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92785": {
      "poster": "Yasuke (Bono)",
      "content": "@koBASA#92772 Ja sam tu tra≈æio koji su primjeri potporni vektori tako da sam pomno≈æio w sa svakim primjerom iz X i onda ako kao izlaz doƒëe -1 ili 1 ili ne≈°to jako blizu, ja sam za prvi i treƒái primjer dobio 0.99 i -0.99, onda su to potporni vektori ≈°to znaƒçi da je za ostale primjere alfa=0 i kako je ponuƒëeno samo jedno rje≈°enje koje na 2. i 4. mjestu ima 0 onda je to to.",
      "votes": {
        "upvoters": [
          "Broono (Buruƒáuh)",
          "Cvija",
          "Emma63194",
          "Fran_- (random_trooper)",
          "[deleted]",
          "koBASA (hackerman)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92802": {
      "poster": "koBASA (hackerman)",
      "content": "@Yasuke#92743 \n\nJa sam sebi nacrtao, u prvom slucaju je udaljenost od tocke 3,3 do 3,4 jednaka 1 pa je sirina margine 0.5, a u drugom slucaju vidis da je udaljenost tocke 3,4 od ovog pravca koji prolazi kroz dvije tocke jednak 3 korijena iz 2, sirina je pola toga, dakle sirina margine je 3 korijena iz 2 puta veca od ove prve, ne znam jel postoji bolji naƒçin, al eto.\n\n![](assets/2020-11-14/00043.png)",
      "votes": {
        "upvoters": [
          "Yasuke (Bono)",
          "[deleted]",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92817": {
      "poster": "narval13068 (Dima)",
      "content": "@Yasuke#92743 ![](assets/2020-11-14/00044.heic)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92824": {
      "poster": "narval13068 (Dima)",
      "content": "@Yasuke#92743 ![](assets/2020-11-14/00045.png)",
      "votes": {
        "upvoters": [
          "Yasuke (Bono)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92829": {
      "poster": "narval13068 (Dima)",
      "content": "![](assets/2020-11-14/00047.png)\n\nJel zna netko zasto se w0 prije izracuna rezultata mora ovdje dobiti preko prvog zadanog primjera, a ne preko drugog (preko prvog sam dobia da je on -1283.56 pa onaj dio s alfama za novi primjer mi je -265.35 pa daje rjesenje ponudjeno, ali ako idem preko drugog dobit w0 ispadne -57.73, zasto nije isti ka preko prvog :/ )",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92857": {
      "poster": "narval13068 (Dima)",
      "content": "@narval13068#92829 Uspio sam pronaci da postoji neka nestabilnost pa da se nece moc dobiti iz svakog nego iz jednog od njih pa izgleda da treba izracunat iz oba i vidit koje je ponudjeno rjesenje u zdk jer to je ono sta se trazi",
      "votes": {
        "upvoters": [
          "Broono (Buruƒáuh)",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [
          "Amali (Amajli)",
          "Broono (Buruƒáuh)",
          "InCogNiTo124",
          "neja_negoti"
        ],
        "tuga": [
          "Fran_- (random_trooper)",
          "sphera",
          "stateboli"
        ]
      }
    },
    "92861": {
      "poster": "MJ3",
      "content": "@narval13068#92829 jel mo≈æe≈° stavit postupak? meni ispadne jako mala vrijednost w0 pa onda ni jedan od ponuƒëenih odgovora",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92866": {
      "poster": "narval13068 (Dima)",
      "content": "@MJ3#92861 \n\n![](assets/2020-11-14/00052.png)\n\n![](assets/2020-11-14/00053.png)\n\nTamo desno pise jos +w0 u prvoj slici u ove dvije donje jednajdbe kad se izracunava samo je ispalo iz slike",
      "votes": {
        "upvoters": [
          "WhiteMamba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92884": {
      "poster": "johndoe12 (enaiks)",
      "content": "iz cega ucite za ovaj ispit? samo moodle blicevi, bez starih ispita (uz skriptu i video predavanja naravno)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92890": {
      "poster": "MJ3",
      "content": "@narval13068#92866 hvala :D",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92908": {
      "poster": "Stark",
      "content": "Da li bi netko znao objasniti za≈°to je u ovom zadatku d) toƒçan?\n\n![](assets/2020-11-14/00058.png)",
      "votes": {
        "upvoters": [
          "logitech"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92917": {
      "poster": "Vrba",
      "content": "![](assets/2020-11-14/00062.png)\n\njel moze netko ovaj objasnit?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92921": {
      "poster": "am22",
      "content": "@Vrba#92917 Trebas sve modele kojima je C >= 1 (veci C daje slozeniji model) i [imath]\\gamma[/imath] <= 1 (manja preciznost isto daje slozeniji model). Takvih je 36, i onda oduzmes 1 jer C = 1 i [imath]\\gamma[/imath] = 1 su oni vec napisali, tako da je odgovor 35.",
      "votes": {
        "upvoters": [
          "Vrba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92932": {
      "poster": "Stark",
      "content": "Ovdje mi ispada 0.70, pa oƒçito krivo radim. Mo≈æe obja≈°njenje?\n\n![](assets/2020-11-14/00063.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92945": {
      "poster": "RogerRoger",
      "content": "@Stark#92932 \n\nFormula za gubitak binarne logistiƒçke regresije je [imath]-y * ln(h(x)) - (1-y) * ln((1-h(x))[/imath].\n\nAko raƒçuna≈° da je npr. y = 1 i izjednaƒçi≈° s 1.20, onda ti se drugi ƒçlan poni≈°tava jer je pomno≈æen s (1 - y), ≈°to je 0. Uglavnom, ima≈° [imath]-ln(h(x)) = 1.20[/imath], tj. [imath]h(x) = exp(-1.20)[/imath] i ponovi≈° izraƒçun samo uz pretpostavku da je y = 0 (jer je oznaka promijenjena).\n\nDalje samo izraƒçuna≈° [imath]- ln(1 - h(x)) = -ln(1 - exp(-1.20)) = 0.36[/imath].",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "92985": {
      "poster": "Noggenfogger (dammitimmad)",
      "content": "molim nekog za objasnjenje, na koji nacin razmisljati redom \n\n ![](assets/2020-11-14/00067.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93149": {
      "poster": "Ziher",
      "content": "Moze li netko objasniti ovaj? Prvo sam dobio 33.935, ovo sam pogodio\n\n![](assets/2020-11-15/00005.png)",
      "votes": {
        "upvoters": [
          "neja_negoti"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93178": {
      "poster": "Lujonlu (Gannicus)",
      "content": "@Ziher#93149 ne regulariziras w0, tako da racunas |w| bez w0",
      "votes": {
        "upvoters": [
          "Amali (Amajli)",
          "cajaznun",
          "neja_negoti"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93186": {
      "poster": "Lujonlu (Gannicus)",
      "content": "@am22#92921 veca preciznost daje slozeniji model. iz skriptice:\n\nNpr.,  ako odaberemo visoku vrijednost za Œ≥,  dobit  ƒáemo slo≈æeniji model,  pa  ƒáe  trebati  pojaƒçati  regularizaciju  odabirom  manje  vrijednosti  za C.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93190": {
      "poster": "khm19 (ajmemeni5)",
      "content": "@Vrba#92917 Veci gama daje slozeniji model jer je gama=1/2sigma^2, a sto je varijanca manja to je Gaussovo zvono uze pa bi primjeri trebali biti sto blize kako bi bili slicni, a to daje slozeniji model. C takoder s povecanjem daje vecu slozenost jer je c=1/lambda, a sto je lambda manji to je regularizacija manja pa imamo slozeniji model. U zadatku ima 6 C i 6 gama ukljucujuci i C=1 i gama=1, kombinacija je 6^2=36 i oduzmemo ponuƒëenu za C=1 i gama=1 i to su preostali prenauƒçeni modeli.",
      "votes": {
        "upvoters": [
          "Vrba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93200": {
      "poster": "saitama",
      "content": "@cotfuse#91736  zasto je skriveni sloj dimenzije 3,a ne 4 ?",
      "votes": {
        "upvoters": [
          "ImJustAKid (lumity)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93209": {
      "poster": "korisnickoime",
      "content": "@Ziher#93149 \n\n@Lujonlu#93178 ima neko mozda postupak za ovaj?",
      "votes": {
        "upvoters": [
          "RogerRoger"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93226": {
      "poster": "johndoe12 (enaiks)",
      "content": "![](assets/2020-11-15/00010.png)\n\n![](assets/2020-11-15/00011.png)\n\n![](assets/2020-11-15/00012.png)\n\nZna li netko tocne odgovore na ova pitanja i objasnjenje?",
      "votes": {
        "upvoters": [
          "blast"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93231": {
      "poster": "RogerRoger",
      "content": "@johndoe12#93226 \n\nZa prvo pitanje, svaka znaƒçajka ti je jedan klasifikator. OVO ima K povrh 2 klasifikatora, OVR ima K, gdje je K broj klasa. To znaƒçi da u ovom primjeru OVO ima 10 znaƒçajki, a OVR 5. Meƒëutim, linearni modeli imaju problem kad su klase neuravnote≈æene, tj. kad jedna klasa ima puno vi≈°e primjera od druge, i ƒçesto ga rje≈°avaju tako da klasificiraju sve ispitne primjere u klasu s vi≈°e primjera za uƒçenje jer tako minimiziraju empirijsku pogre≈°ku (na ≈°tetu manje klase). Za 5 klasa i OVR, omjer primjera za svaki klasifikator je 1:4 i rezultira pogre≈°nom klasifikacijom primjera \"znanosti\" (koja je ionako 5x manja od \"politike\". Zato je toƒçan odgovor drugi ponuƒëeni.\n\nZa drugo pitanje pogledaj onaj graf slo≈æenosti modela naspram empirijske pogre≈°ke uƒçenja i ispitivanja (iz skriptice Osnovni koncepti). Pogre≈°ka uƒçenja asimptotski te≈æi nuli, ali ispitna pogre≈°ka pati od prevelike slo≈æenosti. Regularizacija smanjuje slo≈æenost modela ovisno o magnitudi parametara w, ≈°to kao rezultat ima bolju generalizaciju, ali lo≈°iju prilagoƒëenost primjerima za uƒçenje. Za regularizirani model pogre≈°ka uƒçenja se smanjuje do odreƒëene toƒçke, ali zatim stagnira jer joj regularizacija ne da da te≈æi nuli. Zato je toƒçan odgovor drugi ponuƒëeni.\n\nNewtonov postupak koristi Hesseovu matricu za ƒçiji je izraƒçun potrebna cijela matrica preslikavanja i zato je neiskoristiv za online uƒçenje. Mora imati sve primjere za uƒçenje odjednom i ne mo≈æe primati jedan po jedan primjer i pode≈°avati te≈æine, ≈°to je moguƒáe stohastiƒçkim gradijentnim spustom. Newtonov je postupak dodu≈°e optimizacija drugog reda i uzima u obzir drugu derivaciju funkcije, tj. zakrivljenost plohe ƒçime sprjeƒçava krivudanje i zato mo≈æe br≈æe konvergirati. Opet je toƒçan odgovor drugi ponuƒëeni.",
      "votes": {
        "upvoters": [
          "Bananaking",
          "[deleted]",
          "in1",
          "johndoe12 (enaiks)",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93244": {
      "poster": "cotfuse",
      "content": "@saitama#93200 Suma koja se direktno vidi u zadatku ide od 0 do 3, a s obzirom da imas bias w0, ostanu ti 3 weighta, sto povlaci da je sirina skrivenog sloja 3",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93247": {
      "poster": "koBASA (hackerman)",
      "content": "@korisnickoime#93209 \n\n![](assets/2020-11-15/00015.png)",
      "votes": {
        "upvoters": [
          "in1",
          "korisnickoime"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93251": {
      "poster": "MJ3",
      "content": "![](assets/2020-11-15/00018.png)\n\nkako izgleda ulaz x nakon preslikavanja polinomom 2.stupnja?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93259": {
      "poster": "[deleted]",
      "content": "@MJ3#93251 [imath]1 + x_1 + x_2 + x_1x_2 + x_1^2 + x_2^2[/imath] \n\nhttps://fer.studosi.net/d/1348-struce-pitanja-i-odgovori/73",
      "votes": {
        "upvoters": [
          "MJ3",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93261": {
      "poster": "johndoe12 (enaiks)",
      "content": "gdje se moze naci objasnjene o induckijskoj pristranosti, u skripti na webu ne vidim..",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93270": {
      "poster": "InCogNiTo124",
      "content": "@johndoe12#93261 [strana 10 poglavlje 2.3](https://www.fer.unizg.hr/_download/repository/StrojnoUcenje.pdf)",
      "votes": {
        "upvoters": [
          "johndoe12 (enaiks)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93287": {
      "poster": "stateboli",
      "content": "@InCogNiTo124#91627 Treci zadatak, 23 je rje≈°enje promijenili su zadatak![](assets/2020-11-15/00026.png)",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93333": {
      "poster": "Yeltneb",
      "content": "@Stark#92908 \n\nNije nitko odgovorio pa ponavljam, jel zna netko ovo objasniti?",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93337": {
      "poster": "cotfuse",
      "content": "@Stark#92908 @Yeltneb#93333 \n\nako skup podataka nije linearno odvojiv to znaci da kakav god pravac (pravac odluke modela perceptrona) provuces kroz te podatke, barem jedan primjer ce biti s krive strane pravca. Ti primjeri s krive strane pravca ce uzrokovati da model",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93340": {
      "poster": "cotfuse",
      "content": "@Yeltneb#93333 @Stark#92908 \n\nako skup podataka nije linearno odvojiv to znaci da kakav god pravac (pravac odluke modela perceptrona) provuces kroz te podatke, barem jedan primjer ce biti s krive strane pravca. Ti primjeri s krive strane pravca ce uzrokovati da je gradijent gubtka veci od 0 i zbog toga ce se pravac stalno micati kako bi pokusao uhvatiti te preostale primjere, odnosno model nece konvergirati.",
      "votes": {
        "upvoters": [
          "Red_Baron",
          "Stark",
          "Yeltneb",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93359": {
      "poster": "Atem",
      "content": "@cotfuse#93340 Na temelju ƒçega si zakljuƒçio da ƒáe gradijent u svakom primjeru biti veƒái od nule? Zato ≈°to svaki par (x,y) ima barem jednu nulu u sebi?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93375": {
      "poster": "hi_doggy",
      "content": "![](assets/2020-11-15/00042.jpeg)\n\n![](assets/2020-11-15/00043.jpeg)\n\nMo≈æe netko objasnit? Hvala",
      "votes": {
        "upvoters": [
          "Cubii"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Cubii"
        ]
      }
    },
    "93390": {
      "poster": "cotfuse",
      "content": "@Atem#93359 ne znam sto znaci da svaki par x,y ima barem jednu nulu u sebi\n\nMeni je to najlakse onak intuitivno poznavajuci onaj graf prostora funkcije gubtka perceptrona koji mozes naci na dnu stranice 15 skriptice o linearnim diskriminativnim modelima. Tamo mozes vidjeti da je nagib grafa konstantan na segmentima. Svaki taj segment predstavlja prostor parametara gdje model jednak broj primjera netocno klasificira. Gdje vise grijesimo, taj je segment strmiji. Ti svi segmenti gradijentnim spustom vode u jedan segment koji je ravan, gdje je gradijent 0. To je prostor gdje model perceptrona sve primjere dobro klasificira. Sad, kad znamo da prostor nije linearno odvojiv, kako nam se mijenja taj graf? Pa znamo da ne mozemo sve primjere tocno klasificirati pa ce taj graf uvijek imati neki nagib, aka gradijent ce uvijek biti veci od 0. Nas postupak optimizacije ce zapravo stalno plesati oko nekog sjecista dva segmenta.",
      "votes": {
        "upvoters": [
          "Atem",
          "Bananaking",
          "in1",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93392": {
      "poster": "Stark",
      "content": "@koBASA#93247 Mo≈æe≈° objasniti kako znamo da je w2 = 0, tj druga te≈æina, ako je prvi ƒçlan u vektoru alfa 0, a ne drugi?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93405": {
      "poster": "koBASA (hackerman)",
      "content": "@Stark#93392 \n\nw2 bi ti bilo [imath]-1*0*3 + (-1)*0.01*4 + 1*0.01*4[/imath] pa je to nula, nema to veze s tim da je prvi ƒçlan vektora alfa 0, to ti samo znaƒçi da ne gleda≈° vektor koji nije potporni jer ga 0 poni≈°ti.",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93412": {
      "poster": "Ziher",
      "content": "@hi_doggy#93375 Znaci imamo 2 slucaja: alpha je 0 (promatrani vektor nije potporni) i alpha >0 (promatrani vektor je potporni), sto znaci da izraz u drugoj zagradi mora biti jednak 0 da bi jednakost vrijedila. Taj drugi izraz znaci da se promatrani vektor nalazi na margini (ksi je 0) ili unutar nje (ksi je veci od 0). S obzirom kako ksi ne moze biti < 0, potporni vektori nikad nece izaci izvan margine s prave strane granice.\n\nSto se tice drugog pitanja, zapises si tu razliku u odnosu na rijec \"straja\" i onda gledas koji su ti primjeri najblizi (konkretno, 3 clana za koji imas najmanji L) i onda ih prebrojis i napravis glasanje (2 jedinice + 1 nula =  klasa 1). Onda, samo sto trebas je uvrstiti to sto si dobio u ovu jezgru i gledas najvece brojeve koje si dobio (jer je slicnost veca) i opet dobijes 1. Znaci h1=h2=1",
      "votes": {
        "upvoters": [
          "Broono (Buruƒáuh)",
          "Cubii",
          "Stark",
          "hi_doggy"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93436": {
      "poster": "Stark",
      "content": "@narval13068#92866 Za ovaj primjer gdje je vrijednost -1 (na prvoj slici na kraju) mi ispada w0 = -59.73. ≈†to radim krivo? Ne bi se smjelo dogoditi da w0 ima dvije razliƒçite vrijednosti, zar ne?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93440": {
      "poster": "Bananaking",
      "content": "Ovo se ƒçini kao relativno jednostavan zadatak ali sam lo≈° i ne ku≈æim ba≈° to preslikavanje pa jel bi mogao netko ≈°erati svoj postupak?\n\nPretpostavljam da se treba samo raƒçunati empirijska gre≈°ka po formuli iz skripte kao sumu od i do N funkcije max(0, -w^T preslikano(x^i) y^i \n\n![](assets/2020-11-15/00052.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93456": {
      "poster": "Stark",
      "content": "Mo≈æe obja≈°njenje?\n\n![](assets/2020-11-15/00053.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93459": {
      "poster": "Atem",
      "content": "![](assets/2020-11-15/00054.png)\n\n![](assets/2020-11-15/00055.png)\n\n![](assets/2020-11-15/00056.png)\n\nAko bi netko mogao objasniti ova tri ili barem reƒái koje je toƒçno",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93461": {
      "poster": "cotfuse",
      "content": "@Stark#93456 taj jedan hiperparametar je [imath]\\sigma[/imath], koji je dijeljen izmedju svih kernela, 1001 parametar su parametri odabira znacajki u rijetkom jezgrenom stroju, 2829 parametara su 28*100 sto oznacava znacajke odabranih prototipa, + 28 znacajki znacajnosti tih prototipa, to je znaci 28 od ovih 1001 koje optimiziras, znaci koliko svaki od njih pridonosi konacnom rezultatu i jedan je bias",
      "votes": {
        "upvoters": [
          "Emma63194",
          "Stark",
          "chuuya (temari)",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93465": {
      "poster": "ImJustAKid (lumity)",
      "content": "@Bananaking#93440 ![](assets/2020-11-15/00057.jpeg)",
      "votes": {
        "upvoters": [
          "Murin",
          "in1"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93474": {
      "poster": "sphera",
      "content": "ima netko ovaj postupak\n\n![](assets/2020-11-15/00058.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93502": {
      "poster": "Amali (Amajli)",
      "content": "@Atem#93459 \n- 1. ENm\n    - E za svaku epohu. U svakoj epohi prodjes po svakom primjeru da bi azurirao tezine, dakle *N. Za svaki primjer prodjes po svakoj znacajki , dakle *m.</LI>\n- 2. fi(x) = (1, x)\n    - granica nam treba biti linearna u ulaznom prostoru. Narav funkcije f nam nije bitna za izgled granice, bitne su samo znacajke, dakle preslikavanje mora biti linearno, jer ako je preslikavanje nelinearno imas linearnu granicu u tom visem prostoru, a kad se vratis u ulazni dobijes nelinearnu granicu.</LI>\n- 3. funkciju gubitka i optimizacijski postupak\n    - kada promijenis funkciju gubitka s ovog sto je, moras i promijeniti optimizacijski postupak da pase za tu funkciju gubitka koju si odabrao, postupak najmanjih kvadrata je sam za kvadratni gubitak</LI>",
      "votes": {
        "upvoters": [
          "Atem",
          "Bananaking",
          "InCogNiTo124",
          "Noggenfogger (dammitimmad)",
          "Stark",
          "in1",
          "tito"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93515": {
      "poster": "Amali (Amajli)",
      "content": "@sphera#93474 \n\nPrvo izracunas tezine jer ti ionak trebaju za regulariziranu gresku. To mozes napravit matricno - vektor alpha, svaki alpha pomnozen oznakom y pripadnog vektora, puta matrica dizajna (jedan redak jedan primjer). To su ti tezine\n\n![](assets/2020-11-15/00059.png)\n\nOnda imas funkciju pogreske koja je suma gubitaka + regularizacijski faktor, a to je 1/2C * norma tezina na kvadrat (C je 1/lambda). Ovdje pazis da ne ukljucujes tezinu w0 u normu tezina jer se ona ne regularizira, dakle sam ono kaj daje matricno mnozenje ubacis u formulu za normu vektora i kvadriras (ili ni ne korjenujes in the first place, suma kvadrata elemenata, skalarni produkt)\n\n![](assets/2020-11-15/00060.png)\n\nZa gubitak u pogresci (ovo u sumi) ti treba h(x) za svaki vektor, i to mozes izracunat na primarni il dualni nacin sam po formulama i uvrstis u pogresku.\n\n![](assets/2020-11-15/00061.png)",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "in1",
          "sphera",
          "tito"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93533": {
      "poster": "carrieb",
      "content": "@Stark#93436 u skripti pise da bi se ovo trebalo napraviti, makar je i meni cudno da je toliko velika razlika ako uzmemo jedan ili drugi primjer... sa srednjom vrijednosti w0 ne dolazi dobro rjesenje na pitanju\n\n![](assets/2020-11-15/00063.png)",
      "votes": {
        "upvoters": [
          "Amali (Amajli)",
          "Stark",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93538": {
      "poster": "johndoe12 (enaiks)",
      "content": "@Amali#93515 \n\ntezine su mi w1=-0.09, w2=-0.08, w3=0.05\n\nh(x1) i h(x2) su mi -1, znaci njihov loss je 0, dakle u empirijskoj pogeski imam samo x3\n\nh(x3) dobijem -0.87\n\n(1-h(x3)) = 1.87\n\ni kad sve to uvrstim u E, dobijem gresku 2.72.\n\nGdje grijesim?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93554": {
      "poster": "Amali (Amajli)",
      "content": "@johndoe12#93538 ja tezine dobijem 0.02, 0, -0.03, tak da tu nesto. Mnozenje s oznakom y (alpha bude [0, -0.01, 0.01] s tim y ukljucenim) mislim da je, iako bi w1 bio -0.06 tako, a i msm da bi w2 bio pozitivan\n\nbuduci da je prvi 0, mozes i smanjit izracun, pa imas alpha*y onda = [-0.01, 0.01], a matrica s kojom mnozis je [[-4, 4, 4],[-2, 4, 1]]",
      "votes": {
        "upvoters": [
          "johndoe12 (enaiks)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93556": {
      "poster": "Amon",
      "content": "@johndoe12#93538 \n\n@Amali#93554 \n\nKolega je gore rije≈°io taj zadatak\n\nhttps://fer.studosi.net/d/1348-struce-pitanja-i-odgovori/95",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "johndoe12 (enaiks)",
          "koBASA (hackerman)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93560": {
      "poster": "Bananaking",
      "content": "Ovaj jo≈° nisam vidio ako se ne varam, mo≈æe netko opisati rje≈°avanje?\n\n![](assets/2020-11-15/00066.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93561": {
      "poster": "johndoe12 (enaiks)",
      "content": "@Noggenfogger#92985 Je li netko zna ovaj? Meni se cini da je a, al nisam garant..",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93562": {
      "poster": "Amali (Amajli)",
      "content": "@Bananaking#93560 ima par rasprava o ovom ako se ne varam",
      "votes": {
        "upvoters": [
          "Amon",
          "Bananaking",
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93563": {
      "poster": "Amon",
      "content": "@Bananaking#93560 Cetvrti zadatak:\n\nadaptivne bazne funkcije == neuronska mreza s jednim skrivenim slojem. ulazni parametri imaju 10 varijabli, svaka adaptivna bazna funkcij ima dakle 10 tezina + 1 bias. Takvih adaptvnih baznih funkcija ima 4, dakle sve skupa 4(10+1) = 44. Zavrsili smo prvi sloj, ai time smo samo iz podataka izvadili znacajke, sto znaci da tek sad idemo u softmax. Znaci sad se pravimo da su ovih 4 ‚Äúpravi podaci‚Äù, dakle trebat ce nam jos 4 tezine i 1 bias. Sve skupa 44+5=49. Puno je lakse ako gledas slikicu i pratis sta se dogada nego ovak napamet rjesavat\n\ncopy-pasted from @InCogNiTo124",
      "votes": {
        "upvoters": [
          "Bananaking",
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93564": {
      "poster": "Amali (Amajli)",
      "content": "@Noggenfogger#92985 \n\n@johndoe12#93561 \n\nodg je c\n\nhttps://docs.google.com/document/d/1pCK4LPwiY9AZON6lZWK7vFXNB6UogtXnDSOYEmg1w0U/edit",
      "votes": {
        "upvoters": [
          "johndoe12 (enaiks)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93576": {
      "poster": "Yeltneb",
      "content": "Jel ima netko rje≈°enja MI 2019/2020?\n\n![](assets/2020-11-15/00067.jpeg)\n\n![](assets/2020-11-15/00068.jpeg)\n\n![](assets/2020-11-15/00069.jpeg)",
      "votes": {
        "upvoters": [
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93579": {
      "poster": "Amali (Amajli)",
      "content": "> @cotfuse#91736 4) Ovo prakticki opisuje neuronsku mrezu sa ulaznom dimenzijom 10, skrivenim slojem dimenzije 3 i izlaznim slojem dimenzije 4. Svaki od slojeva ima svoje biase, pa racunica ispada: \n\n>                     [imath] (10+1)*3 + (3+1)*4 = 49 [/imath]\n\njel ovo gleda da je fi~0 dummy pa se ne broji kao dio sloja unutra, a izlaz je 4-dim tj za svaku klasu jedan?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93601": {
      "poster": "johndoe12 (enaiks)",
      "content": "![](assets/2020-11-15/00070.png)\n\nima netko postupak za ovaj",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93604": {
      "poster": "Amon",
      "content": "@johndoe12#93601 \n\nIsto je gore kolega napisao\n\n@Yasuke#92785 \n\nDajte ƒçitajte thread ljudi, nema razloga da se neka pitanja 3 puta ponavljaju",
      "votes": {
        "upvoters": [
          "in1",
          "megi7 (someone7)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Amali (Amajli)"
        ],
        "wtf": [],
        "tuga": [
          "InCogNiTo124",
          "PiqueBlinders (zisku)"
        ]
      }
    },
    "93606": {
      "poster": "InCogNiTo124",
      "content": "@Amon#93604 nema‚ùå se vremena ‚è±Ô∏è",
      "votes": {
        "upvoters": [
          "PiqueBlinders (zisku)",
          "Zogen",
          "toni98"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Amali (Amajli)",
          "Amon"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "93634": {
      "poster": "in1",
      "content": "> @InCogNiTo124#91627 Dakle, ako ti je funkcija PHI linearna, dobit ces linearnu granicu. Ako je nelinerna, i granica ce bit (perhaps surprisingly) nelinearna. Also, ako ti je PHI nelinearna, a PHI linearna, ponovo granice nije linearna. \n\nMislim da si neku rijeƒç falio, mo≈æe≈° srediti to? :)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93643": {
      "poster": "InCogNiTo124",
      "content": "@in1#93634 tehnologija foruma ne dopusta izmjenu objava nakon isteka 10 minuta od postanja",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "in1"
        ]
      }
    },
    "93657": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@InCogNiTo124#93643 Ali dobrostivi diktator ovog pakla nudi moguƒánost edita ako mu po≈°alje≈° link posta i tekst supstitut",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93679": {
      "poster": "PrisonMike (≈†tevo)",
      "content": "Jel ovo toƒçno? Ako je, kako broj parametara ovisi o druga dva odgovora?\n\n![](assets/2020-11-15/00079.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93684": {
      "poster": "sunceko",
      "content": "@johndoe12#93601 @koBASA#92772 \n\n ![](assets/2020-11-15/00080.jpeg)\n\nNemam pojma jel postupak dobar. Brojke nisu skroz toƒçne, ali su za mene dovoljno blizu.",
      "votes": {
        "upvoters": [
          "Noggenfogger (dammitimmad)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93697": {
      "poster": "Amali (Amajli)",
      "content": "@PrisonMike#93679 mogu ti sam rec da je tocno. Msm da je broj znacajki objasnjeno u predavanju al ne sjecam se, mogu bubnut da tezine ovise o znacajkama, a iz tezina se mogu dobit alphe koje su parametri dualne pa indirektno ovise?, a broj klasa... not sure, msm da je sam reko da nismo radili viseklasni SVM al da je to tocno isto u biti\n\n@sunceko#93684 \n\n@johndoe12#93601 \n\nja bih sam tu probala dobit tezine koje su zadali iz ponudjenih alphi i podataka\n\nnpr vektor alpha se pomnozi s vektorom prvih elemenata (preskoci se dummy!) primjera i trebala bi se dobit prva (ne w~0 vec w~1!) tezina i onda je dobro, tak sam i rijesila zadatak. Nisam gledala koji bi vektori trebali biti potporni da ista eliminiram üòÖ",
      "votes": {
        "upvoters": [
          "PrisonMike (≈†tevo)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93704": {
      "poster": "PrisonMike (≈†tevo)",
      "content": "> @Amali#93697 mogu ti sam rec da je tocno. Msm da je broj znacajki objasnjeno u predavanju al ne sjecam se, mogu bubnut da tezine ovise o znacajkama, a iz tezina se mogu dobit alphe koje su parametri dualne pa indirektno ovise?, a broj klasa‚Ä¶ not sure, msm da je sam reko da nismo radili viseklasni SVM al da je to tocno isto u biti\n\nHvala, evo i≈°ao sam pogledat snimku predavanja. Uglavnom ovo kaj ka≈æe≈°, broj klasa zbog vi≈°eklasnog SVM, a kao broj znaƒçajki zato jer ako ovisi o broju potpornih vektora, a potporni vektor ovisi o broju znaƒçajki, onda i broj parametara ovisi o broju znaƒçajki.",
      "votes": {
        "upvoters": [
          "Amali (Amajli)",
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93926": {
      "poster": "johndoe12 (enaiks)",
      "content": "![](assets/2020-11-16/00019.png)\n\nKako je ovdje odg a) ? ne bi li trebalo biti c",
      "votes": {
        "upvoters": [
          "Bato (Morski Pas)",
          "Murin",
          "Yasuke (Bono)",
          "Zabe",
          "korisnickoime",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "93957": {
      "poster": "PiqueBlinders (zisku)",
      "content": "@johndoe12#93926 ja sam a) dobio, al ko ce ga znat vise s obzirom kakav je ispit bio",
      "votes": {
        "upvoters": [
          "Ellie",
          "Vrba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [
          "johndoe12 (enaiks)"
        ],
        "tuga": []
      }
    },
    "94003": {
      "poster": "megi7 (someone7)",
      "content": "Ono pitanje s NR i L2R s blica na moodlu je doslo u ispitu, jedan odgovor tocan na moodlu, drugi na ispitu....\n\nJe li to ja ne vidim razliku u pitanju ili su zeznuli?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "94009": {
      "poster": "Vrba",
      "content": "@megi7#94003 U ispitu _empirijska pogre≈°ka uƒçenja ne konvergira_, a na moodleu se _zaustavio s rje≈°enjem_",
      "votes": {
        "upvoters": [
          "Amali (Amajli)",
          "Erinon",
          "Fran_- (random_trooper)",
          "korisnickoime"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Bananaking",
          "Stark",
          "johndoe12 (enaiks)",
          "khm19 (ajmemeni5)",
          "megi7 (someone7)",
          "moji_prsti_prsti_klize_po_njoj",
          "sane_insane"
        ]
      }
    },
    "94380": {
      "poster": "Ellie",
      "content": "Rjesavala sam ga na probnom slican zadatak kad nije bilo interakcije parova i rjesenje je bilo tocno. \n\nMoja logika je bila ovakva:\n\n [imath]7 \\ linearnih\\  znacajki\\ + {7\\choose 2} \\ interakcije \\ parova+ {7\\choose 3}\\ interakcije\\ trojki+ 7\\ kvadratnih \\ znacajki\\ = \\ 70[/imath]\n \n Ocito je kriva. Moze li mi netko objasniti kako se dolazi do 48?\n\n![](assets/2020-11-17/00002.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "94389": {
      "poster": "FICHEKK",
      "content": "@Ellie#94380 Treba primijetiti da je jedna znaƒçajka nepotrebna, a to je prosjek ocjena 4 razreda jer je to zapravo linearna kombinacija znaƒçajki 1-4. Dakle, nju ƒáemo izbaciti ako ≈æelimo stabilno rje≈°enje. Preostaje 6 znaƒçajki te za njih radimo raƒçunamo: 6 linearnih + 6 kvadratnih + 6C2 parova + 6C3 trojki + 1 dummy = 48.",
      "votes": {
        "upvoters": [
          "Ellie",
          "member",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
          "setuid0"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "94390": {
      "poster": "Cubii",
      "content": "@Ellie#94380 Pretpostavljam da je ovdje trik da ne moras iskoristit sve znacajke, pa izbacimo prosjek ocjena jer je ista stvar ko i ocjene od prvog do cetvrtog (a ne zelimo multi kolinearnost).\n\nPa onda po istoj formuli dobijes 47. Nisam siguran od kud jos +1, ali mislim da je to to.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "94450": {
      "poster": "Dekan",
      "content": "@Ellie#94380 Takoƒëer, problem u tom zadatku je ≈°to s polinomom 2. stupnja ne mo≈æemo dobiti trojke znaƒçajki, za trojke nam treba barem polinom treƒáeg stupnja. Kada sam pitao prof na ispitu kako mo≈æemo dobiti trojke iz polinoma drugog stupnja, odgovor je bio \"ma nema veze, samo uzmite trojke\" ili tako ne≈°to, ne sjeƒáam se vi≈°e toƒçno.",
      "votes": {
        "upvoters": [
          "Ellie"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "96659": {
      "poster": "login",
      "content": "Jel se bodovi dobiveni na moodleu sumiraju pod kontinuirano svima il samo za visu ocjenu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "96667": {
      "poster": "Amali (Amajli)",
      "content": "@login#96659 zar nije da je to bonus svima? Mislim da pise negdje u uvodnoj prezi o predmetu, il organizacija predmeta ili stovec ima gdje",
      "votes": {
        "upvoters": [
          "Emma63194"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "96670": {
      "poster": "login",
      "content": "@Amali#96667 \n\nEvo skicnuo sam i pise ovako. Znaci, svi dobivamo.\n\n![](assets/2020-11-21/00027.png)",
      "votes": {
        "upvoters": [
          "Amali (Amajli)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "97175": {
      "poster": "moji_prsti_prsti_klize_po_njoj",
      "content": "Jel postoji netko kome jo≈° nije upisana druga lab vje≈æba? Treban li se zabrinuti? (ispitivaƒç Domagoj Alagiƒá)",
      "votes": {
        "upvoters": [
          "Stark",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "97205": {
      "poster": "Stark",
      "content": "@moji_prsti_prsti_klize_po_njoj#97175 Meni je upisana ali su mi krivo skalirani bodovi",
      "votes": {
        "upvoters": [
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "moji_prsti_prsti_klize_po_njoj"
        ]
      }
    },
    "97232": {
      "poster": "logitech",
      "content": "Zna netko koja je logika za ovaj zadatak?\n\n![](assets/2020-11-22/00042.png)\n\nJa sam gledao ovako. Ukupno imamo N=6 primjera. Max gre≈°ka ƒáe biti kada svih ≈°est krivo klasificiramo. Dva primjera mogu biti umjesto 0 oznaƒçeni kao 1 tj. imamo dva primjera koji mogu biti false positive. ƒåetiri primjera mogu biti umjesto 1 oznaƒçeni kao 0 tj. imamo ƒçetiri primjera koji mogu biti false negative. I onda imamo generalno E(h|D) = 1/6 * (4 * 1 + 2 * 1/2) = 5/6. Min pogre≈°ka je 0 kada su svi toƒçno oznaƒçeni.",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "97235": {
      "poster": "Emma63194",
      "content": "@logitech#97232 Je li model koji se tu koristi linearan? Jer, ako je, ƒçini mi se da nije moguƒáe da ima≈° gre≈°ku nula, ali isto tako i nije moguƒáe uzeti hipotezu koja sve krivo klasificira.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "97255": {
      "poster": "Murin",
      "content": "@logitech#97232 \n\n![](assets/2020-11-22/00049.png)\n\n\nOvo ti je u isto vrijeme i najgori i najbolji slucaj, ako je s gornje strane granice sve klasificirano ko 1 onda imas gresku lazni pozitivni*1=0.5,  a ako je klasificirano ko 0 onda imas 4*lazni negativni+1*lazni pozitivni=4.5",
      "votes": {
        "upvoters": [
          "Dekan",
          "InCogNiTo124",
          "logitech"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "100625": {
      "poster": "AromaticConfusion (VrloZbunjen)",
      "content": "Ne ku≈æim iz obavijesti \n\n> Popravili smo vrednovanje zadatka s dva toƒçna ponuƒëena odgovora (zadatak 10 u grupi A)\n\nKoji su onda toƒçni odgovori na kraju za taj zadatak?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "100626": {
      "poster": "Vrba",
      "content": "@AromaticConfusion#100625 Vjerojatno b) i c) s obzirom da su to isti brojevi",
      "votes": {
        "upvoters": [
          "AromaticConfusion (VrloZbunjen)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "100628": {
      "poster": "AromaticConfusion (VrloZbunjen)",
      "content": "@Vrba#100626 Eh, da sad sam sku≈æio haha, hvala",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "103625": {
      "poster": "johndoe12 (enaiks)",
      "content": "Je li ima netko iskustva sa zamjenom termina labosa? Jel moram imati neki konkretan razlog ili? Kome se javljam?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "103714": {
      "poster": "Antuunn",
      "content": "@johndoe12#103625 ja sam se javio asistentu i rekao je da zamjena dolazi u obzir ako nademo drugog studenta koji bi se isto zamijenio",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "103969": {
      "poster": "johndoe12 (enaiks)",
      "content": "Ima li netko da bi mjenjao termin cetvrtak u 14h?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "103974": {
      "poster": "Antuunn",
      "content": "@johndoe12#103969 ja bi",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "104126": {
      "poster": "johndoe12 (enaiks)",
      "content": "@Antuunn#103974 nazalost, vec se netko javio",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "104543": {
      "poster": "doakes",
      "content": "Ima li netko da bi se mjenjao, moj termin je u petak u 8?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124",
          "Watson (112)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "104910": {
      "poster": "doakes",
      "content": "@doakes#104543  Na≈°ao.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "105313": {
      "poster": "Ziher",
      "content": "Zeli li se netko mijenjati za termin LV? Moj je u petak u 13",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "105321": {
      "poster": "Red_Baron",
      "content": "@Ziher#105313 Prodano! ƒåekiraj poruke",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "105529": {
      "poster": "Ziher",
      "content": "@Ziher#105313 prodano",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "106071": {
      "poster": "a_ko_si_ti",
      "content": "Zeli li se itko mijenjat za termin 3. labosa? moj je u petak u 15",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "106491": {
      "poster": "member",
      "content": "@a_ko_si_ti#106071 mogu ja",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "108017": {
      "poster": "a_ko_si_ti",
      "content": "@Ziher @doakes @johndoe12 \n\nJel potvrdi asistent zamjenu na mail. Trazio sam jucer i jos uvik ne odgovara",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "108139": {
      "poster": "Ziher",
      "content": "@a_ko_si_ti#108017 Ne potvrdi, samo te smjesti u tu grupu na teamsu, meni je i na kalendaru zapisano zapravo",
      "votes": {
        "upvoters": [
          "a_ko_si_ti"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "120891": {
      "poster": "Atem",
      "content": "Jesmo li obradili temu \"Probabilistiƒçki grafiƒçki modeli 2\"? (Hoƒáe li doƒái u ispitu)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "121160": {
      "poster": "Koalalica (zaba)",
      "content": "@Atem#120891 Jesmo. Trebala bi. Nema video za nju, ali ima skriptica.",
      "votes": {
        "upvoters": [
          "Atem"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "121781": {
      "poster": "pepelko",
      "content": "Jel zna netko kad ce prof otvoriti Moodle kvizove za Probabilisticke modele, grupiranje itd? i oce li ih uopce bit?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "121782": {
      "poster": "Stark",
      "content": "@pepelko#121781 Danas bi trebali otvoriti prvi",
      "votes": {
        "upvoters": [
          "Ellie",
          "johndoe12 (enaiks)",
          "pepelko"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "122399": {
      "poster": "tre_besty (luk)",
      "content": "Zna li itko objasnit kako dobiju ove vrijednosti za P(w=1), P(s=1|w=1) i P(r=1|w=1), nisu mi jasne ove sume, koje se vjerojatnosti mnoze/zbrajaju:\n\nhttps://i.ibb.co/m9ZdTm6/Screenshot-from-2021-01-16-17-16-57.png\n\nOvo je graf iz kojeg iscitavaju vjerojatnosti:\n\nhttps://i.ibb.co/SXGzPhm/Screenshot-from-2021-01-16-17-17-26.png",
      "votes": {
        "upvoters": [
          "Cvija",
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "122907": {
      "poster": "logitech",
      "content": "Bi li netko tko ima termin labosa u ƒçetvrtak ili petak se mijenjao za utorak u 15:00h?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "122931": {
      "poster": "saitama",
      "content": "Kako se bodovi iz moodle kvizova racunaju u ukupan zbroj bodova?",
      "votes": {
        "upvoters": [
          "Anonimity (BoJack)",
          "ajkula",
          "ls_123 (KimuraKong)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "123162": {
      "poster": "tre_besty (luk)",
      "content": "Kako otvorit menti kvizove, na≈°ao sam ih u chatu na teamsu al mi pise \"The quiz is not open. Please wait for the presenter to activate it.\" npr evo link za jedan: https://www.menti.com/b8prshw5y7",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "123761": {
      "poster": "johndoe12 (enaiks)",
      "content": "vidim da na yt nema predavanja o Grupiranju, zna li netko postoji li negdje drugdje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "123815": {
      "poster": "Cvija",
      "content": "@tre_besty#123162 To su linkovi za pristup kvizu, evo ovdje su linkovi svih kvizova nakon meƒëuispita.. ostaje jo≈° jedan koji ƒáe biti u ƒçetvrtak\n\nhttps://www.mentimeter.com/s/88dfe4c3cff8607d81059196167adb67/2cfc18f6cee2\n\nhttps://www.mentimeter.com/s/d94ee63c4f80a568bc87e7feca6e0e54/c61654fee0f6\n\nhttps://www.mentimeter.com/s/e0565a4b75ec793bf8b024ed0dd6511f/61caee0ec16a\n\nhttps://www.mentimeter.com/s/ad638f1eaaaa77d27b8e6e7030923562/a7d6c9d3b6e5\n\nhttps://www.mentimeter.com/s/0d503045b881b974d907ff41986263e0/96b59b258557\n\nhttps://www.mentimeter.com/s/c6a5036e236e8cd492d0d4d5f82bed49/8d120c78b32c\n\nhttps://www.mentimeter.com/s/4b43f1e3a183b39f28c1886e22686e29/e6b3351bf0f6\n\nNadam se da ne fali nijedan",
      "votes": {
        "upvoters": [
          "Cubii",
          "Daorson",
          "Emma63194",
          "johndoe12 (enaiks)",
          "tre_besty (luk)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "125422": {
      "poster": "Cvija",
      "content": "@Cvija#123815 Evo i posljednji kviz\n\nhttps://www.mentimeter.com/s/35c0c5d434d650baf5f39c714bc71a80/a379ac60f264",
      "votes": {
        "upvoters": [
          "Conrad",
          "Daorson",
          "Emma63194",
          "Stark",
          "johndoe12 (enaiks)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "126429": {
      "poster": "svemia (bearyn)",
      "content": "![](assets/2021-01-22/00040.png)\n\n![](assets/2021-01-22/00041.png)\n\nJel zna netko kako se ova dva zadatka rjesavaju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "127670": {
      "poster": "Emma63194",
      "content": "Kako izraƒçunati ove parametre pod b)? \n\nNije mi ba≈° sjelo kako se to radi.\n\nAlso, mo≈æe mo≈æda neki hint za c) dio zadatka?\n\n>!![](assets/2021-01-23/00069.jpeg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "127891": {
      "poster": "johndoe12 (enaiks)",
      "content": "@Emma63194#127670 \n\n![](assets/2021-01-24/00006.jpeg)\n\n![](assets/2021-01-24/00007.jpeg)\n\n![](assets/2021-01-24/00008.jpeg)\n\nBroj parametara: (br.vrijednosti koje var moze imati -1) * vrijednosti koje moze imati 1 roditelj * vrijednosti koje moze imati 2.roditelj*... \n\nnpr. uzmimo var x3 koja je binarna, dakle imamo 2-1, i ona ima 2 roditelja, x1 i x2, a oni su isto binarni pa mnozis sa 2 * 2. \n\nc) tu uvjetnu vjerojatnost prvo raspises po pravilu uvjetne vjv pa ces u brojniku imati zajednicku vjv, a u nazivniku P(x1=T, x4=3) (taj dio meni preskocen na papiru). Onda i brojnik i nazivnik raspises kao sumu i u yagradi stavis sve varijable koje imas, i onda moras iyracunati vjv za sve moguce kombinacije.",
      "votes": {
        "upvoters": [
          "Emma63194",
          "[deleted]",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "128006": {
      "poster": "johndoe",
      "content": "Ima li netko odgovore za Kviz 6 Vrednovanje modela?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "128029": {
      "poster": "johndoe",
      "content": "@johndoe#128006 ugh, uvijek zaboravim na onaj shared dokument",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124",
          "Stark"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "138675": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Poz imam pitanje sa zadatkom s mi-ja (7.)\n\n![](assets/2021-02-06/00022.png)\n\novdje je moj pokusaj rijesavanja. Ako mi moze netko pomoc. Hvala\n\n![](assets/2021-02-06/00023.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138799": {
      "poster": "a_ko_si_ti",
      "content": "@vidraKida#138675 Tocno si rjesio, al u zadnjem redu si krivo zbrojio sumu u zagradama. Trebas dobiti 2.1846 + |w|/2, i onda ti to da 2.69.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138804": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@a_ko_si_ti#138799 kak dobijem ovaj |w|, jer u najboljem slucaju mi ispadne 0.56 a treba ispast po ovome 0.51",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138805": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Jel moze pomoc oko ovog iz MI-ja (8.)\n\n![](assets/2021-02-06/00031.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138807": {
      "poster": "a_ko_si_ti",
      "content": "Jel itko moze objasniti 10., 17. i 24. iz ovogodi≈°njeg MI-a kako se rade.\n\n10.\n\n![](assets/2021-02-06/00032.png)\n\nTocno je 50/32 i 25/16. Ja stalno dobivam 50/21. Za OVR uzmem N klasifikatora (4) i svaki se trenira sa 1000 primjera, sto daje za svaki Grammovu matricu od 1 000 000 elemenata, i tako puta 4 puta (4 000 000). Za OVR imam K povrh 2 (6) klasifikatora, i imaju razlicito elemenata, ovisno o broju primjera(400+400, 400+100 * 4, i 100+100). U sumi dobijem 1 680 000 elemenata u Grammovoj matrici i iz toga omjer 50:21\n\n17.\n\n![](assets/2021-02-06/00033.png)\n\nToƒçan je A. Ovdje sam izraƒçunao h(x) za svaki x, po tome odredio koji je y, i onda to ubacio u formulu za ovisnost **w** i **alpha** [5. stranica ovdje](https://www.fer.unizg.hr/_download/repository/SU-2020-08-StrojPotpornihVektora.pdf). Time sam dobio sistem od 4 jednad≈æbe sa 4 nepoznanice (alphe) i od toga uvijek dobio da nema rje≈°enja. Jel to toƒçan naƒçin za radit pa ja krivo rje≈°avam sistem jednad≈æbi ili ima neki drugi naƒçin?\n\n24.\n\n![](assets/2021-02-06/00034.png)\n\n    Ovdje je toƒçno pod D. Mogu navuƒá brojke al mi nije ba≈° 100% jasno. 501 parametar optimazacije mi je jasno jer imamo 500 jezgrenih funkcija (za svaki primjer jednu) u jezgrenom stroju, plus œÜ1=1. Al kako su do≈°li do 3079 parametara? Sta ne bi bilo da za svaki od 38 prototipa imamo samo po jedan skalar _w_?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138810": {
      "poster": "a_ko_si_ti",
      "content": "@vidraKida#138804 Po≈°to se  radi o L1 regularizaciji, |w| je apsolutna suma svih elemenata od w (osim w0 jer njega ne skaliramo). To ti daje 0.94+0.08=1.02, i onda iz formule o gubitku vidis da se ubaci |w|/2=0.56.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138834": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Moze pomoc oko (15.) u MI-ju? \n\n![](assets/2021-02-07/00001.png)\n\nracunao sam ali dobijem da moram skalar pomozit dalje s vektorom fi(x) a ne znam dal radim nesto krivo ili?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138837": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@vidraKida#138834 ![](assets/2021-02-07/00002.png)\n\n1.28 je rj.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138838": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Moze pomoc oko (16.) iz MI-ja\n\n![](assets/2021-02-07/00003.png)\n\n![](assets/2021-02-07/00004.png)\n\ndobio sam da je w2 = 5 a u rj. je -5",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138852": {
      "poster": "a_ko_si_ti",
      "content": "@vidraKida#138838 Ja sam to grafiƒçki rje≈°io. Jednom kad nacrtas tocke, lako se vidi koja je hiperravnina, a onda i njena normala (w). \n\nAl analitiƒçki gledano: Odkud ti da je skalarni umno≈æak 0? Ta dva vektora nisu okomita, nego paralelna.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138877": {
      "poster": "TentationeM",
      "content": "Zna li netko objasniti kod linearne regresije za≈°to je sustav nekonzistentan ako vrijedi `rang(X) < rang(X|y)`, gdje je X matrica dizajna, a y vektor oznaka?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138906": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@a_ko_si_ti#138852 ima u formulama negdje navedeno  al moguce da sam ja sjebo \n\n![](assets/2021-02-07/00006.png)\n\n@a_ko_si_ti#138852 daj kad se vec samo ti i ja dopamo ovdje jel mo mozes pomoc oko ostalih zadataka ili ako imas postupak MI-ja da sherash tu ili nekaj",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "138912": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@a_ko_si_ti#138852 btw rijesio sam, krivo sam napisao krate se w0 i w0 i dobijes iz toga jednadzbu da je -w2 = w1",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "139010": {
      "poster": "InCogNiTo124",
      "content": "@TentationeM#138877 jedan od super primjera di znanje linearne dobro dode\n\npromatramo sljedeci slucaj: broj redaka je veci od broja stupaca (dakle imamo vise primjera nego znacajki). rang matrice je min(broj redaka, broj stupaca), dakle u ovom slucaju rang == broj stupaca. dodavanjem jednog stupca povecali smo rang za jedan.\n\ngdje tu u cijelu pricu ulazi konzistentnost? ako imamo vise redaka od stupaca, u jeziku linearne algebre to znaci kao da imas vise jednadzbi od nepoznanica (dakle mozes imat x1 .. x5, ali 20 jednadzbi) za takav sustav jednadzbi kazemo da je preodreden odnosno inkonzistentan.\n\njos jednom ukratko, ako se rang matrice poveca kad dodas stupac, znaci da ima manje stupaca od redaka, sto znaci da imas vise jednadzbi od varijabli, sto znaci da ti je sustav inkonzistentan\n\nskroz druga prica se dogada u drugom slucaju, ako je broj redaka manji od broja stupaca (imas manje primjera nego znacajki). Tada je rang matrice == broju primjera (a ne znacajki, kao gore). stoga, dodavanjem novog stupca ne mjenja se rang. u tom slucaju (ako na takvu matricu gledas kao sustav jednadzbi) sustav vise nije inkonzistentan, vec je pododreƒëen (razmisli - ako imas 3 jednadzbe s 4 nepoznanice, ne mozes ih rjesit sve 4 nikako; zato pododreden. za takav sustav mozes nac x4 za svaki od x1..x3 koji zadovoljava sustav jednadzbi)\n\nprocitaj polako i po potrebi nacrtaj si o cem pricam, jednom kad skuzis ima savrseno smisla, makar zvuci komplicirano",
      "votes": {
        "upvoters": [
          "TentationeM"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "140218": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Nisu stavili ispit za zira u repo. Ja sam uspio par racunskih zadatka pretezito iz 1. ciklusa prepisat s ponudenim odg. Mogli bi napravit neki kolektivni dokument ili tu skupa probat rijesit te zadatke i mi i zi pa da ostane narastajima poslje nas. #djecaSUBuducnost, slikam ove zadatke pa ih naknadno tu objavim",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "140225": {
      "poster": "a_ko_si_ti",
      "content": "@vidraKida#140218 https://www.fer.unizg.hr/_download/repository/SU-2020-1IR.pdf\n\nTu je ispit",
      "votes": {
        "upvoters": [
          "Stark"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231102": {
      "poster": "Bananaking",
      "content": "U ulaznom prostoru X = {0, 1}^3 definiramo klasif model: h(**x**; **w**) = **1**(w0 + w1*x1 + w2*x2 + w3*x3 >= 0)\n\nKoja je dimenzija prostora parametara te koliko razlicitih hipoteza postoji u ovom modelu? \n\nOdg: Dim prostora parametara je 4 (jer ih je 4), hipoteza ima manje od 256. Kako dobijem broj hipoteza? Na primjeru je rije≈°en onaj primjer sa 2 dimenzijskim ulaznim prostorom pa je donekle jasno za≈°to ih je 14 a ne 16 (2 xora ne mogu pravcem klasificirati), ali kako je to matematiƒçki za vi≈°e dimenzionalan ulazni prostor?",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231279": {
      "poster": "Bananaking",
      "content": "@Ellie#94380 Mo≈æe netko ovo primjeniti na zadatak s roka?\n\nPo meni bi i≈°lo 1 (dummy) + 6 (linearnih) + 6 (kvadratnih) + 6C2 (parovi) * 2^2 (kombinacije kvadrata nad njima npr x1x2, x1^2 x2, x1x2^2, x1^2 x2^2) + 6C3 (trojke) * 2^3 (kombinacije kvadrata) = 233 = oƒçito krivo, treba biti A) 79.\n\nPretpostavljam da od 7 znaƒçajki jednu trebamo izbaciti jer su iz x5 x6 i x7 mo≈æemo jednu dobiti pomoƒáu druge dvije. Takoƒëer pretpostavka da ≈°tednja u kunama i devizna ≈°tednja u eurima nije isto ofc nego 2 raƒçuna.\n\n![](assets/2021-08-20/00004.png)",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231499": {
      "poster": "Bananaking",
      "content": "![](assets/2021-08-21/00011.png)\n\nZadnji poku≈°aj prije nego prestanem postati jer nitko ovo ne uƒçi za jesen ili ne prati temu: zna netko objasniti ovaj zadatak? Odgovor je pod D), pretpostavljam da ide funkcija preslikavanja 1 jer ima kvadratne ƒçlanove a podaci iz D nisu linearno odvojivi. Ali za≈°to Perceptron? Zato ≈°to perceptron \"ka≈ænjava samo netoƒçno klasificirane primjere (za razliku od regresije)\" ?\n\nTakoƒëer: ako netko ima rije≈°ene moodle zadatke ili koji ispit bilo bi super to uploadati, bar dok su ispiti ovako vi≈°e raƒçunski na zaokru≈æivanje mo≈æda se i da ne≈°to nauƒçiti po primjerima a ne doktoriranjem teorije prije prelaska na zadatke.",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231526": {
      "poster": "nd49261 (SimpleRick)",
      "content": "@Bananaking#231499 \n\nOdgovor bi trebao biti D (perceptron i preslikavanje PHI 1 ).\n\nMoje obja≈°njenje je da perceptron i logistiƒçka regresija moraju imati linearno odvojive podatke kako bi uƒçenje konvergiralo (kada podaci nisu linearno odvojivi radi se preslikavanje u prostor di su linearno odvojivi) .\n\nprvo preslikavanje ne radi ni≈°ta, samo dodaje dummy znaƒçajku i to je obiƒçna matrica dizajna.\n\nTreƒçe preslikavanje je u prostor s 3 dimenzije (interakcijska znaƒçajka je x1x2 je uvijek nula zato ≈°to je ili x1 ili x2 u svakom primjeru nula). podaci su i dalje linearno neodvojivi.\n\nDrugo preslikavanje rje≈°ava problem linearnosti ( pretpostavljam zbog kvadratnih baznih funckija ) i onda uƒçenje perceptrona mo≈æe konvergirati.",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231528": {
      "poster": "Bananaking",
      "content": "@nd49261#231526 Ok ali za≈°to ne bi bilo LR i phi1 preslikavanje?",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231531": {
      "poster": "nd49261 (SimpleRick)",
      "content": "@Bananaking#231528 \n\nNisam dobro pogledao odgovore, ne znam za≈°to nije LR",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231538": {
      "poster": "nd49261 (SimpleRick)",
      "content": "Ovo je iz jednog prija≈°njeg odgovora, mislim da je to odgovor na na≈°e pitanje:\n\n\"Drugi zadatak:\n\nNadam se da si rjesavao drugi labos koji se ticao logisticke regresije, gdje si uzeo wTx i omotao to oko sigmoide. E sad, sigmoida je poprilicno nelinearna, ali granica koju si (trebao) dobiti je linearna. Zasto je tome tako? Zato jer su ti podaci unutar sigmoide linearni. Dakle, ako ti je funkcija PHI linearna, dobit ces linearnu granicu. Ako je nelinerna, i granica ce bit (perhaps surprisingly) nelinearna. Also, ako ti je PHI nelinearna, a aktivacija f linearna, ponovo granica nije linearna. Podaci su kljuc!\"\n\nZakljuƒçak: nelinearna aktivacijska funkcija(sigmoida) i nelinearni PHI daju nelinearnu granicu i zbog toga LR ne mo≈æe konvergirati?",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231562": {
      "poster": "nd49261 (SimpleRick)",
      "content": "@Bananaking#231102 \n\nPeta bilje≈°ka na kraju skripte Osnovni koncepti:\n\n\"Razlicite hipoteze imat ce razlicite vektore parametara Œ∏. Medutim, razliciti vektori parametara Œ∏ ne\n\nmoraju nuzno davati razlicite hipoteze. Na primjer, ako je ulazni prostor diskretan (npr. X = N\n\nn), onda mozemo imati pravce koji su malo razliciti (dakle parametri Œ∏ im se razlikuju), ali ipak daju\n\nidenticnu klasifikaciju primjera u dvije klase, tj. funkcija h je identicna (kako je uobicajeno, jednakost\n\nfunkcije ovdje definiramo ekstenzionalno: dvije funkcije su jednake ako jednako preslikavaju elemente\n\niz domene u kodomenu. To znaci da razliciti Œ∏ mogu dati identicne funkcije\"\n\nDimenzija prostora parameta je 4, ulazni prostor je diskretan (ima 8 razliƒçitih ulaza) i bitno je samo jel h(x) veƒái ili manji od 0(sve hipoteze koje za tih 8 ulaznih primjera daju iste klasifikacije su zapravo jedna hipoteza) \n\nU principu je pitanje na koliko naƒçina mo≈æe≈° klasificirati tih 8 ulaza u dvije klase i to mo≈æe≈° napraviti na 2^8 naƒçina (256)\n\nod klasifikacije 0,0,0,0,0,0,0,0 do klasifikacije 1,1,1,1,1,1,1,1  i sve izmeƒëu.\n\nJa sam si ovako protumaƒçio zadatak, ne znam jel toƒçno moje razmisljanje.",
      "votes": {
        "upvoters": [
          "vidraKida (Œñ Œµ œç œÇ)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231682": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@nd49261#231562 \n\n@Bananaking#231499 \n\nja radim za jesen, ako ste za imam neki online dokument pa mozemo tamo komentirat i radit",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231683": {
      "poster": "Bananaking",
      "content": "@vidraKida#231682 Mo≈æe naravno, ne znam koliko ƒáu biti od koristi ali 3 glave bolje od jedne",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231686": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@Bananaking#231683 https://docs.google.com/document/d/1D-WwT4eT4aakrNXwPqBoB6vshss4pHdXspTbfrpZqLM/edit",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231687": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Planiram rjesavat moodle i ispite i onda probat zadace",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231690": {
      "poster": "Ellie",
      "content": "@Bananaking#231279 Sorry, ne sjecam se vise kako su se rjesavali takvi zadatci. Your guess is as good as mine :/",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231772": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@Bananaking#231279 kombinacije parova i trojki gledas ovako n!/((n-2)!x2! I za trojke n!/((n-3)!x3!",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "231782": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@Bananaking#231279 pokusavao sam ga rijesit ali uvijek dobijem tipa 71 ili tako nesto blizu... ugl kak sam radio makno sam 2 znacajke za stednju i za preostala dugovanja. Dobio sam 5 + 5 + 1 ona klasika i 60 u kombinacijama ovakvim... sad ako ti to ista pomaze da skuzis nkj jebeno bi bilo da mi objasnis haha",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "233005": {
      "poster": "DocHoc",
      "content": "zna itko kako se rje≈°avaju 3. i 9. zadatak iz MI-a?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "233452": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Jel mi moze netko pomoc oko 1., 4., 11. Zadatka iz zira? 11. Sam rjesavao kao i ostale tog tipa ali nikako ne mogu dobit dobre vrijednosti",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "235919": {
      "poster": "Bananaking",
      "content": "@vidraKida#231686 jel bilo ≈°ta od ovoga na kraju? jo≈° uvijek mi je access denied",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "236455": {
      "poster": "Bananaking",
      "content": "@nd49261#231562 \n\n@Bananaking#231102 \n\nPitao sam ovdje sliƒçan primjer ali moram priznati da mi nije jasno kako rje≈°avati opƒáeniti sluƒçaj ovakvog zadatka. Evo primjer iz ovogodi≈°njeg meƒëuispita. Poku≈°ao sam razmi≈°ljati \"na koliko naƒçina mo≈æemo klasificirati ulazne primjere\", kako je X = {0,1}^3 njih ima 2^3 = 8, mislio sam mo≈æda za prvu zagradu x1 mo≈æe biti manji od fi 1,1, izmeƒëu ili veƒái, isto za drugu i treƒáu zagradu pa ne≈°to tipa 3C1 + 3C1 + 3C1 = 9 + ?\n\n![](assets/2021-09-12/00026.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "241723": {
      "poster": "lovro (l123)",
      "content": "Jel rje≈°io neko 5. iz zadataka za uƒçenje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "241737": {
      "poster": "lincthesinc17",
      "content": "mo≈æe neko stavit postupke kak je rje≈°io?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "241821": {
      "poster": "tomekbeli420",
      "content": "@\"l123\"#p241723 \n\nove zadatke za uƒçenje su starije kolege rije≈°ile\n\nhttps://fer.studosi.net/d/2200-struce-o-predmetu/3\n\njedino ≈°to se tiƒçe njihovog 5a sam napisao\n\nPogre≈°ka hipoteze je oƒçekivanje funkcije gubitka nad distribucijom primjera [imath]\\mathbf{x}[/imath] iz prostora primjera [imath]\\mathcal{X}[/imath] (dakle ne samo iz skupa primjera [imath]\\mathcal{D}[/imath] koji je statistiƒçki gledano samo uzorak iz distribucije). U praksi je problem ≈°to ta distribucija najƒçe≈°ƒáe nije poznata.\n\n@\"lincthesinc17\"#p241737 \n\nKoji toƒçno te zanima? One sve za vje≈æbu ima≈° na onom google docu.",
      "votes": {
        "upvoters": [
          "lovro (l123)",
          "pingvinka"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242040": {
      "poster": "rolotex (brr)",
      "content": "![](assets/2021-10-08/00009.png)\n\nSto znaci ova tocka pokraj X",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242424": {
      "poster": "Bananaking",
      "content": "![](assets/2021-10-10/00005.png)\n\nKoja je razlika izmeƒëu A) i B)? Znaƒçi li to da za neke parametre theta ne postoje funkcije h?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242436": {
      "poster": "InCogNiTo124",
      "content": "@\"tomekbeli420\"#p241821 sta se tice google doca, slobodno pisite u njega svoja rjesenja i pitanja, to je dobro mozda pomognete kasnije nekom ko bide imo ista pitanja",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242443": {
      "poster": "Joji",
      "content": "@\"Bananaking\"#p242424 Mislim da je stvar u tome da je moguƒáe za razliƒçite vrijednosti parametara ponekad dobiti iste hipoteze. Npr ako ima≈° model [imath]h(\\textbf x; \\boldsymbol \\theta) = |\\boldsymbol\\theta^\\top\\textbf x|[/imath], dobiva≈° istu hipotezu za [imath]\\boldsymbol\\theta[/imath] i [imath]\\boldsymbol-\\boldsymbol\\theta[/imath]. S druge strane, kad ima≈° razliƒçite hipoteze onda sigurno ima≈° razliƒçite parametre jer s istim parametrima mora≈° dobit istu hipotezu.",
      "votes": {
        "upvoters": [
          "bodNaUvidima",
          "nikace (AeIoU)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242460": {
      "poster": "[deleted]",
      "content": "![](assets/2021-10-10/00008.png)\n\nmo≈æe netko objasnit ≈°to znaƒçe ove definicije? konkretno imam problema sa shvaƒáanjem desnog dijela svake (u zagradama)",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242569": {
      "poster": "Rene",
      "content": "@\"Todd Chavez\"#p242460 \n\nZa hipotezu s vrijedi da je konzistentna, i da je svaka druga konzistentna hipoteza od koje je ona opƒáenitija ili jednaka ujedno opƒáenitija ili jednaka od s -  one su jednake. Dakle, s su najspecifiƒçnije hipoteze. Analogno su G najopƒáenitije. Nekakva \"analogija\" koja bi ti mo≈æda mogla pomoƒá:  Neka je H multiskup (skup s dozvoljenim duplikatima), npr. H = {1, 2, 7, 5, 1, 7}.  s su oni brojevi za koje vrijedi da ako je s >= h, onda je i h >=s. Dakle to su najmanji element (ili vi≈°e jednakih): S = {1, 1}. Sliƒçno bi u G zavr≈°ili brojevi za koje vrijedi ako je h >= g, onda je i g >= h, tj. H = {7, 7}",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "242879": {
      "poster": "rolotex (brr)",
      "content": "Jel netko rjesavao sve zadatke iz Regresije?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "243919": {
      "poster": "Bananaking",
      "content": "Ne znam jel zadan za zadaƒáu ili ne (moodle trenutno ne radi) ali mo≈æe li netko staviti rje≈°enje 3. zadatka iz zadataka za uƒçenje iz vje≈æbe Regresija 1 ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "243994": {
      "poster": "tomekbeli420",
      "content": "@\"Bananaking\"#p243919 Ima≈° u skripti za to gradivo, (P03 - Regresija) na stranici 12, ova 3 matematiƒçka izraza + obja≈°njenje ispod zadnjeg izraza.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244030": {
      "poster": "BillIK",
      "content": "_Je li pristranost koja\n\nproizlazi iz odabira modela dovoljna za jednoznaƒçnu klasifikaciju primjera iz D?_\n\n≈°to bi znaƒçila jednoznaƒçna klasifikacija?",
      "votes": {
        "upvoters": [
          "yabk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244053": {
      "poster": "tomekbeli420",
      "content": "@\"BillIK\"#p244030 to pitanje je i meni bilo malo sumnjivo, jer primjeri iz [imath]\\mathcal{D}[/imath] su veƒá klasificirani.\n\nJa mislim da se pita mo≈æe li se odrediti jedinstvena hipoteza koja **ispravno** klasificira sve primjera iz [imath]\\mathcal{D}[/imath], dakle da je konzistentna i da uz to ne postoji vi≈°e od jedne moguƒánosti kako klasificirati neviƒëene primjere (primjere iz skupa [imath]\\mathcal{X} \\setminus \\mathcal{D}[/imath]).\n\nOdnosno, je li skup [imath]VS_{\\mathcal{H},\\mathcal{D}}[/imath] ima jedan ili vi≈°e elemenata",
      "votes": {
        "upvoters": [
          "steker",
          "yabk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244162": {
      "poster": "yabk",
      "content": "Moze li netko pls objasniti 3. d) iz zadataka za ucenje (Osnovni koncepti)?\n\nGledam u ovaj doc rijesenih domacih zadaca, ali mi nije jasno kakvog smisla ima linearan model nad X = {0,1}^3 i kako dodemo do te dvije konkretne klasifikacije koje se spominju",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244195": {
      "poster": "nikace (AeIoU)",
      "content": "@\"bruuum\"#p242040 ne znam je li netko veƒá odgovorio.. ali je na predavanju toƒçka proƒçitana kao izraz \"za koju vrijedi\" konkretnije \"x iz X za kojeg vrijedi...\"\n\nnadam se da nisam u krivu :)",
      "votes": {
        "upvoters": [
          "rolotex (brr)",
          "yabk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244285": {
      "poster": "Sulejman",
      "content": "@\"yabk\"#p244162 Nije ni meni bilo na prvu jasno pa sam si [geometrijski ](https://www.geogebra.org/3d/kwvvjjdc) nacrtao. Poanta je da (0, 0, 1) mo≈æe pripadati bilo kojoj od dvije klase, jer postoje dvije ravnine (≈°to su hipoteze) koje tu toƒçku mogu smjestiti u jednu ili u drugu klasu. \n\nZnaƒçi sve toƒçke koje su s jedne stane ravnine pripadaju prvoj klasi, a ove s druge strane ravnine pripadaju drugoj.",
      "votes": {
        "upvoters": [
          "yabk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244310": {
      "poster": "421blazeitfgt",
      "content": "Moze netko objasniti ovaj?\n\n![](assets/2021-10-16/00014.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244362": {
      "poster": "tomekbeli420",
      "content": "@\"421blazeitfgt\"#p244310 \n\nu zadacima kod kojih je prostor primjera konaƒçan, ≈°to je kod nas sluƒçaj jer [imath]\\mathcal{X} = \\left\\{0, 1\\right\\}^3[/imath] je skup svih ureƒëenih trojki nula ili jedinica i ima ih 8, korisno je vizualizirati kako izgledaju svi moguƒái primjeri u prostoru primjera.\n\nZbog toga ≈°to se radi o ureƒëenim trojkama, jasno je da svaki primjer [imath]\\mathbf{x}[/imath] iz prostora primjera ima tri znaƒçajke: [imath]\\mathbf{x} = \\left(x_1, x_2, x_3\\right)[/imath]. Svih 8 moguƒáih primjera iz prostora primjera [imath]\\mathcal{X}[/imath] se tada mogu prikazati na ovakvoj kocki:\n\n![](https://i.imgur.com/EsP0S2e.png)\n\nE sad na sliƒçni naƒçin treba vizualizirati zadani model. Vidimo da se radi o binarnoj klasifikaciji, jer se koristi funkcija [imath]\\mathbf{1} \\{...\\}[/imath] sa nekim predikatom unutar vitiƒçastih zagrada. E sad vidimo da taj predikat\n\n gleda svaku znaƒçajku posebno, i za svaku znaƒçajku testira nalazi li se unutar nekog intervala zadanih sa parametrima, i onda sve to pove≈æe sa logiƒçkim I (znak [imath]\\wedge[/imath]).\n\nAlso mali komentar, nije mi jasno za≈°to su stavili da je prostor parametara [imath]\\boldsymbol{\\theta} = \\mathbb{R}^6[/imath] a pojedine jednodimenzijske parametre oznaƒçili sa dvama indeksima npr [imath]\\theta_{1,2}[/imath], no dobro... Bitno je samo da postoji 6 parametara, i svake dvije su za granice intervala jedne znaƒçajke.\n\nPretpostavimo da su parametri takvi da je interval \"ispravan\" pod navodnicima (da donje granice nisu veƒáe od gornjih, npr da se ne desi situacija da je [imath]\\theta_{1,1} = 1.5[/imath] i [imath]\\theta_{1,2} = 0.5[/imath]), jer u suprotnom ƒáe onda takav predikat uvijek dati la≈æ (jer evo za ove dvije thete bi se u predikat na≈°ao [imath]1.5 < x_1 < 0.5[/imath], ≈°to je naravno uvijek la≈æ jer ne postoji nijedan realan broj koji je veƒái od 1.5 i manji od 0.5) i takva hipoteza onda sve primjere klasificira kao negativne (dakle sa nulama).\n\nE onda u sluƒçaju da su parametri dobri, mo≈æemo vizualizirati model na ulaznom prostoru.\n\nPa ako malo bolje razmisli≈°, primijetit ƒáe≈° da se radi o kvadru koji ima sve bridove i plohe paralelne sa ovom kockom koju sam nacrtao gore na slici.\n\nEvo primjera vizualizacije jedne od hipoteza, nisam ba≈° najvje≈°tiji u crtanju 3D oblika:\n\n![](https://i.imgur.com/EN4zDRK.png)\n\nOvo bi odgovaralo situaciji npr da su parametri ovakvi (otprilike):\n\n[math]\\theta_{1,1} = 0.8 \\quad \\theta_{1,2} = 1.5 \\quad \\theta_{2,1} = -0.5 \\quad \\theta_{2,2} = 1.8 \\quad \\theta_{3,1} = -0.2 \\quad \\theta_{3,3} = 0.25[/math]\n\nI onda se pozitivno klasificira sve ≈°to je unutar takvog kvadra. Ovakva hipoteza koju sam naveo kao primjer bi onda pozitivno klasificirala [imath](1, 0, 0)[/imath] i [imath](1, 1, 0)[/imath]. Strane i bridovi tog kvadra su paralelne sa onima iz kocke jer se testira svaka znaƒçajka pojedinaƒçno. Jako bitno je za primijetiti da iako postoji neprebrojivo beskonaƒçno mnogo parametara iz [imath]\\mathbb{R}^6[/imath], hipoteza postoji konaƒçno mnogo (ƒçak i bez ovakvog modela) jer puno razliƒçitih realnih brojeva daju efektivno iste hipoteze. Npr, ova hipoteza koju sam naveo bi bila ista kao i ona sa parametrima:\n\n[math]\\theta_{1,1} = 0.81 \\quad \\theta_{1,2} = 1.51 \\quad \\theta_{2,1} = -0.51 \\quad \\theta_{2,2} = 1.81 \\quad \\theta_{3,1} = -0.21 \\quad \\theta_{3,3} = 0.26[/math]\n\n≈†to je mrvicu pomaknuti kvadar u odnosu na pro≈°li primjer.\n\nZa≈°to je ista? Hipoteza je u matematiƒçkom smislu funkcija, i ona za svaki [imath]\\mathbf{x}[/imath] iz prostora primjera [imath]\\mathcal{X}[/imath] pljuje oznaku. Pa ako dvije hipoteze za svaki [imath]\\mathbf{x}[/imath] daju istu oznaku, onda su te dvije hipoteze iste i onda ih ne brojimo dvaput kod prebrojavanja hipoteza. Razlog tomu je ƒçinjenica da je prostor primjera [imath]\\mathcal{X}[/imath] konaƒçan, pa onda postoji konaƒçno mnogo klasifikacijskih funkcija (hipoteza) i bez modela, a model ih jo≈° ograniƒçi s obzirom da nije moguƒáe postiƒái sve moguƒáe hipoteze.\n\nDobro vizualizirali smo model (odnosno hipoteze iz tog modela) i sad treba prebrojiti koliko razliƒçitih klasifikacija postoji za takav model, odnosno koliko razliƒçitih funkcija (Booleovih funkcija u ovom sluƒçaju jer imamo binarnu klasifikaciju) se mo≈æe dobiti ovakvim modelom.\n\nE sad vizualizacija je dobra jer mo≈æemo problem svesti na sljedeƒái ekvivalentan problem:\n\nKoliko ima razliƒçitih \"konfiguracija\" preklapanja kocke i kvadra, gdje se naravno vrhovi kocke (primjeri iz [imath]\\mathcal{X}[/imath]) razlikuju?\n\nA ovo prebrojiti je relativno lagano jer znamo da kvadar ima bridove i plohe paralelne sa onima od kocke.\n\nPrva dva sluƒçaja su kad se svi primjeri klasificiraju isto. Ako kvadar skroz \"fula\" kocku (ili su parametri \"neispravni\" kako smo spomenuli ranije), onda ƒáe svi primjeri biti klasificirani kao 0, a ako se kocka nalazi potpuno unutar kvadra, onda se svi primjeri klasificiraju kao 1. To su 2 hipoteze.\n\nOnda uzmimo sluƒçaj kako kvadar u svojoj unutra≈°njosti obuhvaƒáa samo jedan vrh. Sad ovisno o tome koji vrh obuhvati, taj primjer ƒáe klasificirati sa 1, a ostale sa 0. Takvih moguƒánosti imamo 8 jer ima 8 razliƒçitih vrhova, dakle to je dodatnih 8 hipoteza.\n\nOnda uzmimo sluƒçaj kako kvadar u svojoj unutra≈°njosti obuhvaƒáa jedan brid. Pokazni primjer je jedan od takvih hipoteza. Taj brid koji obuhvaƒáa ta 2 vrha/ulaznih primjera ƒáe klasificirati sa 1, ostale sa 0. Bridova ima 12, dakle takvih moguƒánosti ima dodatnih 12, dakle dodatnih 12 hipoteza.\n\nDalje pretpostavljam ku≈æi≈° kako.\n\nOnda uzmimo sluƒçaj kako kvadar u svojoj unutra≈°nosti obuhvaƒáa cijelu jednu stranu. Strana ima 6, dakle 6 dodatnih hipoteza.\n\nPozbrojimo sve to,\n\n1+1+8+12+6 = 28.",
      "votes": {
        "upvoters": [
          "123 (FERella)",
          "Arya",
          "Daho_Cro",
          "Dootz",
          "Fica (Prof)",
          "Gulbash",
          "Heklijo (Geralt of Rivia)",
          "JoKing",
          "Lyras",
          "Me1 (Me)",
          "PaleAle",
          "Pleomax",
          "Sulejman",
          "SuperSaiyano",
          "SuperSjajan3",
          "TheCrimsonChin",
          "Vonj",
          "ZekoHop",
          "boogie_woogie (nika_1999)",
          "cajaznun",
          "fooFighter",
          "gladiator",
          "indythedog",
          "jobi (azex)",
          "luka6 (ugrijaniRadijator)",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
          "sheriffHorsey",
          "spampers (majmunska boginja)",
          "steker",
          "yabk",
          "zastozato (studo≈°)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244410": {
      "poster": "lincthesinc17",
      "content": "@\"tomekbeli420\"#p241821 na kojem google docu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244429": {
      "poster": "tomekbeli420",
      "content": "@\"lincthesinc17\"#p244410 https://docs.google.com/document/d/1POm4KkLzv3M_R1Lf7m3nnvp-2MJ-JYHRMKRJNCprJwU/edit#heading=h.jwsd30gipi6",
      "votes": {
        "upvoters": [
          "Gulbash",
          "lincthesinc17"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244586": {
      "poster": "rolotex (brr)",
      "content": "Je li netko rj 3. zad - zad s ispita iz 03 Regresija?",
      "votes": {
        "upvoters": [
          "Ollie",
          "[deleted]",
          "cajaznun"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244758": {
      "poster": "[deleted]",
      "content": "≈°to je toƒçno rang matrice i kako ga odrediti? jel prijevod toga na engleskome `span` ? jel to samo broj razlicitih stupaca üòì",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244763": {
      "poster": "Bananaking",
      "content": "@\"Todd Chavez\"#p244758 Skripta \"3: Regresija\", Bilje≈°ke, bilje≈°ka broj 9, stranica 14. tl;dr rang matrice je broj linearno nezavisnih stupaca matrice. Ali proƒçitaj ≈°to pi≈°e, ima≈° i primjere.",
      "votes": {
        "upvoters": [
          "[deleted]",
          "[deleted]",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "244797": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"Todd Chavez\"#p244758 ~~Na engleskom se zove \"range\" ili \"column space\"~~\n\nEDIT: Na engleskom se zove \"rank\". Vezano je uz \"range\" ali nije ista stvar, pardon.",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "Sulejman"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245619": {
      "poster": "[deleted]",
      "content": "![](assets/2021-10-21/00015.png)\n\nmoze netko objasniti ovaj?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245623": {
      "poster": "Emma63194",
      "content": "@\"Todd Chavez\"#p245619 \n\n@\"InCogNiTo124\"#p90565",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245630": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p245619 Ja sam ovako shvatio.\n\n≈†um nije relevantan za zadatak jer pi≈°e da ga je malo. ≈Ωeli≈° minimizirat funkciju pogre≈°ke koja se raƒçuna\n\n(y+h(x))^2. E sad, tvoje oznake veƒá pribli≈æno le≈æe na pravcu (jer je ≈°um malen), pa je pitanje mo≈æe≈° li smislit drugi pravac koji daje vrijednosti koje ƒáe minimizirat fju pogre≈°ke? E to ƒáe biti pravac koji simetriƒçan s orginalnim pravcem (tj oznakama) u odnosu na x os.\n\ntj (h(x) + y) = 1-2x -1+2x = 0\n\n>!  ![](assets/2021-10-21/00016.jpg)",
      "votes": {
        "upvoters": [
          "[deleted]",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245718": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@\"Todd Chavez\"#p245619 ![](assets/2021-10-22/00003.jpg)",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245860": {
      "poster": "steker",
      "content": "![](assets/2021-10-22/00013.jpg)\n\nMi u ovom zadatku ne mozemo zakljucit nis o tome koji model bi bolje generaliziro od kojeg zbog velikog suma? Ako sam dobro skuzila",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245872": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"steker\"#p245860 Ja bih prije rekao da ti ≈°um govori da ƒáe model s veƒáim kapacitetom imati manju pogre≈°ku, a da mogu jednako lo≈°e generalizirati zato ≈°to su neodgovarajuƒáe aproksimacije (2 je premalo, 5 je previ≈°e). Ovisno o uzorcima mo≈æe ti se underfittati na [imath]H_{2,0}[/imath] i overfittati na [imath]H_{5,0}[/imath], ali bez uvida u uzorke ne mo≈æe≈° reƒái koji ƒáe otiƒái dalje od odgovarajuƒáe stupnja 3. Nije nu≈æno stupanj 5 jer je za 2 udaljen od stupnja 3, dok je stupanj 2 udaljen za 1 od stupnja 3. Nit mo≈æe≈° predviƒëati da ƒáe ≈°um bit takav da ƒáe to srediti ekstra 2 stupnja polinoma stupnja 5 bolje nego regularizacija koju pru≈æa polinom stupnja 2.",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "245923": {
      "poster": "steker",
      "content": "@\"BDSMiƒáo\"#p245872 k tenks",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "246121": {
      "poster": "[deleted]",
      "content": "@\"Precious Bodily Fluids\"#p245630 mo≈æe≈° li jo≈° pojasniti za≈°to nam to toƒçno treba biti = 0 kad zelimo minimizirati? po≈°to to ipak nije derivacija",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "246123": {
      "poster": "angello2",
      "content": "@\"Todd Chavez\"#p246121 zelis minimizirat pogresku, pogreska ne moze bit negativna tako da je najmanje sta moze bit = 0",
      "votes": {
        "upvoters": [
          "[deleted]",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "246826": {
      "poster": "InCogNiTo124",
      "content": "> @\"angello2\"#p246123 pogreska ne moze bit negativna tako da je najmanje sta moze bit = 0\n\nPazi samo, pogreska opcenito moze biti manja od 0.\n\nevo recimo jedan cest primjer: ucis vector embedding recimo slike, i zelis da ti model vrati slicne vektore za slicne slike, a razlicite vektore za razlicite slike. Slicnost vektora mjeris cosinusnom slicnoscu tako da MAKSIMIZIRAS cosine_similarity(model(x), y), odnosno MINIMIZIRAS -cosine_similarity(model(x), y). Ugl dogodit ce ti se da je minimum jednak -1.\n\nVecina loseva u strojnom, poput square loss iz labosa ali i l1, hinge, logistic i Mnogi Drugi imaju minimum u 0, al to nije nuzno, pa treba pazit",
      "votes": {
        "upvoters": [
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247132": {
      "poster": "Artemis",
      "content": "Rije≈°io netko 1.zad s ispita (linearni diskriminativni modeli)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247135": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"Loki\"#p247132 Kojeg",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247142": {
      "poster": "Artemis",
      "content": "@\"BDSMiƒáo\"#p247135 \n\n![](assets/2021-10-27/00019.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247146": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"Loki\"#p247142 Koji je to ispit mislim",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247148": {
      "poster": "[deleted]",
      "content": "@\"BDSMiƒáo\"#p247146 to su skupljeni zadaci s intraneta, sekcija se zove ‚Äòzadaci s ispita‚Äô",
      "votes": {
        "upvoters": [
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247267": {
      "poster": "Sulejman",
      "content": "Za≈°to koristimo preslikavanje iz skupa primjera u skup oznaka?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247325": {
      "poster": "steker",
      "content": "@\"Loki\"#p247142 jel tu w0 =0, w1=5, w2=-5",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247328": {
      "poster": "Artemis",
      "content": "@\"steker\"#p247325 \n\nNe znam za w0 i w1, ali w2=-5 ≈°to je i toƒçno rje≈°enje zadatka.\n\nKako doƒái do toga?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247346": {
      "poster": "tomekbeli420",
      "content": "@\"Sulejman\"#p247267 da bi podaci koji nisu bili linearni (odnosno nisu bili linearno odvojivi kod klasifikacije) u originalnom ulaznom prostoru postali linearni u tom preslikanom prostoru. Na taj naƒçin ne moramo mijenjati linearan model (model je i dalje linearan u te≈æinama [imath]\\mathbf{w}[/imath]), nego potencijalnu nelinearnost mo≈æemo postiƒái sa nelinearnim preslikavanjem [imath]\\boldsymbol{\\phi}[/imath].\n\nSkripta Regresija II, paragraf 1.2\n\n@\"Loki\"#p247142 \n\nZnamo da su te≈æine takve da je maksimizirana udaljenost. Za predznaƒçenu udaljenost primjera od hiperravnine granice modela znamo da se raƒçuna prema izrazu [imath]d = \\frac{h \\left(\\mathbf{x}\\right)}{\\left\\| \\mathbf{w} \\right\\|}[/imath] gdje je [imath]\\mathbf{w}[/imath] vektor te≈æina ali sa iskljuƒçenim [imath]w_0[/imath], dakle u na≈°em sluƒçaju [imath]\\mathbf{w} = \\left(w_1, w_2\\right)[/imath]. E ali kod nas je induktivna pristranost takva da se maksimizira udaljenost ali da se ne gleda predznak, dakle onda moramo gledati apsolutnu vrijednost: [imath]d = \\left| \\frac{h \\left(\\mathbf{x}\\right)}{\\left\\| \\mathbf{w} \\right\\|} \\right|[/imath]\n\ndakle potrebno je maksimizirati izraz (oznaƒçio sam ga sa [imath]D[/imath] reda radi)\n\n[math]D = \\sum_{i=1}^{N} \\left| \\frac{h \\left(\\mathbf{x}^{(i)}\\right)}{\\left\\| \\mathbf{w} \\right\\|} \\right|[/math]\n\nE sad mi znamo da za oba primjera vrijedi [imath]y \\cdot h \\left(\\mathbf{x}\\right) = 5[/imath], pa prema tome odmah mo≈æemo saznati koliko iznose vrijednosti hipoteze (linearnog modela prije nego se uplete klasifikacija) za svaki primjer ako uvrstimo vrijednosti njihovih oznaka [imath]y[/imath] (mo≈æemo uvrstiti i vrijednosti njihovih znaƒçajki):\n\n[math]h \\left(\\mathbf{x}^{(1)}\\right) = w_1 x_1^{(1)} + w_2 x_2^{(1)} + w_0 = w_1 \\cdot 1 + w_2 \\cdot 0 + w_0 = w_1 + w_0 = 5 \\\\\nh \\left(\\mathbf{x}^{(2)}\\right) = w_1 x_1^{(2)} + w_2 x_2^{(2)} + w_0 = w_1 \\cdot 0 + w_2 \\cdot 1 + w_0 = w_2 + w_0 = -5[/math]\n\nSamo iz dobivenih linearnih jednad≈æbi sa nepoznanicama [imath]w_0, w_1, w_2[/imath] ne mo≈æemo odrediti jedinstveno rje≈°enje, no moramo iskoristiti ƒçinjenicu da rje≈°enje maksimizira udaljenosti (izraz [imath]D[/imath]) hiperravnine od primjera. E sad uvrstimo podatke (iznose hipoteza za svaka 2 primjera) u izraz [imath]D[/imath]:\n\n[math]D = \\frac{5}{\\left\\| \\mathbf{w} \\right\\|} + \\frac{5}{\\left\\| \\mathbf{w} \\right\\|} = \\frac{10}{\\sqrt{{w_1}^2 + {w_2}^2}}[/math]\n\nI to je potrebno maksimizirati uz uvjete da vrijede one 2 linearne jednad≈æbe gore. Pa jasno je da maksimizacija [imath]D[/imath] se svodi na minimizaciju zbroja kvadrata dvaju te≈æina (minimizacija jer se zbroj kvadrata nalazi u nazivniku, a minimizacija korijena se svodi na minimizaciju onog unutar korijena pod uvjetom da je to unutar korijena pozitivno, ≈°to naravno jest sluƒçaj jer se radi o zbroju kvadrata).\n\nInaƒçe bismo morali minimizirati funkciju dviju varijabli [imath]w_1[/imath] i [imath]w_2[/imath], ali one linearno ovise o [imath]w_0[/imath] (iz onih linearnih jednad≈æbi) pa ih mo≈æemo tako zapisati. Dakle onda se zadatak svodi na minimiziranje izraza [imath]\\left(5 - w_0\\right)^2 + \\left(-5 - w_0\\right)^2[/imath] ≈°to je dost trivijalno\n\nIzraz se svede na (kad se kvadriraju zagrade) [imath]2 {w_0}^2 + 50[/imath] ≈°to je parabola sa tjemenom u [imath]w_0 = 0[/imath]. Dakle onda je rje≈°enje [imath]w_2 = -5 - w_0 = -5 - 0 = -5[/imath].",
      "votes": {
        "upvoters": [
          "Ardura (Maddy)",
          "Artemis",
          "Ollie",
          "SuperSaiyano",
          "Valentino",
          "WickyWinslow",
          "bodNaUvidima",
          "indythedog",
          "nnn (dinoo)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247350": {
      "poster": "steker",
      "content": "@\"tomekbeli420\"#p247346 jel se moze w0=0 zakljucit iz toga da bi mozda(?) ravnina trebala prolaziti kroz ishodiste kako bi se ostvario taj maksimum udaljenosti jednog i drugog primjera",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "247353": {
      "poster": "tomekbeli420",
      "content": "@\"steker\"#p247350 Ne. Recimo da zadatak nije specificirao da mora za oba primjera vrijediti [imath]y \\cdot h \\left(\\mathbf{x}\\right) = 5[/imath] (odnosno da ne znamo da to vrijedi). Maksimum udaljenosti se onda mo≈æe postiƒái neovisno o tome koliki je [imath]w_0[/imath]. Za≈°to?\n\nPa ako raspi≈°e≈° opet onaj izraz za [imath]D[/imath] uzimajuƒái u obzir da je jedan primjer pozitivan drugi negativan, dobije≈°\n\n[math]D = \\frac{h \\left(\\mathbf{x}^{(1)}\\right) - h \\left(\\mathbf{x}^{(2)}\\right)}{\\| \\mathbf{w} \\|} = \\frac{w_1 + w_0 - \\left(w_2 + w_0\\right)}{\\sqrt{{w_1}^2 + {w_2}^2}} = \\frac{w_1 - w_2}{\\sqrt{{w_1}^2 + {w_2}^2}}[/math]\n\n≈†to ne ovisi o [imath]w_0[/imath] (jasno, ne smije se dogoditi da su te≈æine takve da se netoƒçno klasificiraju primjeri). Maksimizatora ovog izraza ima beskonaƒçno, konkretno rje≈°enje su sve te≈æine za koje vrijedi [imath]w_2 = -w_1[/imath], ≈°to ima smisla i geometrijski ako nacrta≈° primjere u prostoru primjera, pa onda da bi se maksimizirale udaljenosti, pravac granice mora biti okomit na spojnicu izmeƒëu dva primjera iz skupa primjera. E sad kroz koji dio spojnice prolazi je nebitno, maksimizirana udaljenost (zbroj) ƒáe biti [imath]\\sqrt{2}[/imath], pa je stoga nebitno koliki je [imath]w_0[/imath]. No ako uz to ukljuƒçi≈° informaciju da mora vrijediti [imath]y \\cdot h \\left(\\mathbf{x}\\right) = 5[/imath], tek onda mo≈æe≈° sa sigurno≈°ƒáu reƒái da je [imath]w_0 = 0[/imath].",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248429": {
      "poster": "lucylu",
      "content": "@\"tomekbeli420\"#p247346 \n\nza≈°to se gleda suma d-ova kod maksimizacije?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248432": {
      "poster": "tomekbeli420",
      "content": "@\"lucylu\"#p248429 jer zadatak ka≈æe da model ima induktivnu pristranost tako da maksimizira udaljenost primjera od hiperravnine. Jedino ≈°to malo nije skroz jasno jest ≈°to toƒçno se maksimizira izmeƒëu udaljenosti, nije eksplicitno reƒçeno da je zbroj.",
      "votes": {
        "upvoters": [
          "lucylu"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248472": {
      "poster": "Bananaking",
      "content": "Linearni Diskriminativni Modeli, zadaƒáa, 4. zadatak, \"Pozivajuƒái se na skicu, odgovorite za koje ƒáe modele oƒçekivanje gubitka biti veƒáe od udjela pogre≈°nih klasifikacija\". Ne razumijem ba≈° pitanje, jel odgovor isto ≈°to me pita zadnja 3 podzadatka kv gubitak jer ka≈ænjava i toƒçne?",
      "votes": {
        "upvoters": [
          "Sulejman",
          "WickyWinslow",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248570": {
      "poster": "viliml",
      "content": "@\"tomekbeli420\"#p247346 @\"tomekbeli420\"#p247353 Ovo ≈°to raƒçuna≈° nije udaljenost primjera od hiperravnine, nego udaljenost izmeƒëu projekcija dva primjera na pravac okomit na hiperravninu.\n\nOno ≈°to se treba maksimizirati je minimalna udaljenost od bilo kojeg primjera do hiperravnine, dakle u na≈°em sluƒçaju pravac mora biti simetrala na≈°a dva primjera.\n\nTo nam odmah daje [imath]w_0=0, w_1+w_2=0[/imath], i onda dalje lako.\n\nEDIT: ok, shvatio sam ≈°to ti je bila ideja. Ti si shvatio da se maksimizira *suma* udaljenosti primjera od hiperravnine. Ali zadatak nije tako zadan. Definicija udaljenosti izmeƒëu dva skupa toƒçaka je minimum udaljenosti izmeƒëu bilo koje toƒçke u prvom i bilo koje toƒçke u drugom skupu.\n\nBespotrebno si si zakomplicirao ≈æivot, ali ipak si dobio isto rje≈°enje pa bravo.",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248614": {
      "poster": "tomekbeli420",
      "content": "@\"viliml\"#p248570 aha vidi stvarno, a bilo bi super kad bi u zadatku eksplicitno rekli da je minimum",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248799": {
      "poster": "boogie_woogie (nika_1999)",
      "content": "Zna netko ovaj?\n\n![](assets/2021-11-01/00037.png)\n\nPretpostavljam da se a i b mogu eliminirati jer primjeri nisu linearno odvojivi, ali za≈°to je ba≈° d, a ne c?",
      "votes": {
        "upvoters": [
          "blast"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "248950": {
      "poster": "viliml",
      "content": "@\"boogie_woogie\"#p248799 To se meni ƒçini kao gre≈°ka u zadatku, osim ako je neka kvaka s time da empirijska pogre≈°ka konvergira na neku veliku vrijednost dok jo≈° uvijek krivo klasificira.\n\nOvaj mi se isto ƒçini kao gre≈°ka. Topologija mre≈æe je 10x4x3, Parametara je 40+12=52.\n\n![](assets/2021-11-02/00007.png)",
      "votes": {
        "upvoters": [
          "Lyras"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249637": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-04/00000.png)\n\nmo≈æe li netko dodatno pojasniti ovaj dio? ni nakon njihovog obja≈°njenja mi nije jasno za≈°to se ovo dogaƒëa *samo* za linearno odvojive probleme",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249649": {
      "poster": "Rene",
      "content": "@\"Todd Chavez\"#p249637 Ako su primjeri linearno odvojivi, onda ƒáe se sigmoida stezati i praktiƒçki te≈æiti prema obliku step funkcije jer mo≈æe≈° samo biti jako blizu nule za jednu klasu, a jako blizu jedinice za drugu klasu i strmi prelazak izmeƒëu njih (slika lijevo).\n\nAko nisu linearno odvojivi onda ne taj strmi prijelaz nije dobar jer ƒáe gre≈°ka biti veƒáa, pa sigmoida postaje \"bla≈æeg\" prijelaza (slika desno)\n\n![](assets/2021-11-04/00002.png)\n\nMo≈æda se nisam najbolje izrazio, ali mislim da je o tome ≈†najder govorio na predavanju Logistiƒçka regresija 2 pred kraj.",
      "votes": {
        "upvoters": [
          "[deleted]",
          "blast"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249659": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p249637 \n\nEvo wall of text struje svijesti, nadam se da pomogne.\n\nPrije svega, va≈æno je shvatiti ≈°to se dogaƒëa sa sigmoidom ako mno≈æi≈° njen ulaz sa faktorom alpha. ≈†to vi≈°e raste faktor alpha, to sigmoida postaje strmija ( 6. cjeline, str 2).\n\nSljedeƒáe, potrebno je razumjeti da kada koristi≈° sigmoidu u logistiƒçkoj regresiji\n\n[math]\\sigma(w^Tx)[/math]\n\n w^T je ista stvar kao faktor alpha. Kako je on veƒái, to je sigmoida strmija.\n\nDalje je potrebno razumjeti gubitak unakrsne entropije. On ka≈ænjava i ispravno i neispravno klasificirane primjere i  raste proporcionalno s razlikom izlaza modela i stvarne oznake primjera, tj. |[imath]y -  h \\left(\\mathbf{x}\\right)[/imath]|\n\n(vidi cjelinu 6, str 7.)\n\nAjmo sada pogledati ≈°to se dogaƒëa s modelom koji veƒá ispravno klasificira sve primjere. Dakle, primjeri su linearno odvojivi. Za≈°to on u daljnjoj optimizaciji nastavlja za neki faktor poveƒáavati te≈æine? Zato jer time ne mjenja granicu klasifikacije, a sigmoida postaje strmija. A kad sigmoida postane strmija, izlaz modela za sve pozitivne primjere pomakne se bli≈æe 1, a za negativne bli≈æe 0. Time se smanjuje gubitak, odnosno pogre≈°ka, a to je upravo ono ≈°to algoritam i ≈æeli.\n\nE sad, ako primjeri nisu linearno odvojivi, logiƒçka regresija neke primjere neƒáe moƒái ispravno klasificirati. I sad zamisli da krene≈° poveƒáavati te≈æine isto kao i gore. Opet bi sigmoida postala strma i davala vrijednosti blizu ili 0 ili 1. I sad recimo da postoji pozitivno oznaƒçen primjer na pogre≈°noj strani klasifikacijske granice. Za njega bi model dao [imath]h \\left(\\mathbf{x}\\right) \\approx 0[/imath] , ≈°to je potpuno krivo klasificirano i gubitak je velik, odnosno gubitak netoƒçno klasificiranih primjera raste ≈°to je sigmoida strmija. U drugu ruku, pogre≈°ka za sve ispravno klasificirane primjere bi padala. Dakle kako mjenja≈° strminu sigmoide, ispravno klasificiranim primjerima gubitak se smanjuje, a neispravnim se poveƒáava.\n\nPoanta cijele priƒçe je da kod linearno odvojih primjera funkciju pogre≈°ke uvijek mo≈æe≈° natjerati da te≈æi u nula, a to posti≈æe≈° jako strmom sigmoidom. Kod primjera koji nisu linearno odvojivi to ne mo≈æe≈° jer minimum funkcije pogre≈°ke nije 0 i te≈æine nikad neƒáe rasti nekontrolirano.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "Rene",
          "[deleted]",
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249661": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p249637 Zapravo, mislim da ƒáe ti biti najjasnije ako proba≈° debuggat algoritam za najjednostavniji moguƒái linearno odvojiv i neodvojiv primjer, pa pogleda≈° kako se stvari a≈æuriraju.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250504": {
      "poster": "viliml",
      "content": "@\"boogie_woogie\"#p248799 @\"viliml\"#p248950 \n\nMo≈æe drugo mi≈°ljenje?\n\nDa netko ili potvrditi da su zadatci krivo zadani ili objasni slu≈æbeno rje≈°enje?\n\nUskoro ƒáe rok za predaju.",
      "votes": {
        "upvoters": [
          "boogie_woogie (nika_1999)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250510": {
      "poster": "Rene",
      "content": "@\"viliml\"#p250504 Ne bih rekao da je gre≈°ka.\n\nA i B neƒáe konvergirati jer primjeri nisu linearno odvojivi a koristi se perceptron.\n\nC ne konvergira jer logistiƒçka regresija (neregularizirana) ne konvergira za linearno odvojive primjere. Detaljnije obja≈°njenje:\n\nhttps://stats.stackexchange.com/questions/224863/understanding-complete-separation-for-logistic-regression\n\nD konvergira jer su primjeri linearno neodvovjivi.\n\nOvaj drugi zadatak ne dobijam ni tvoje ni njihovo rje≈°enje, pa nisam siguran",
      "votes": {
        "upvoters": [
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250527": {
      "poster": "Rene",
      "content": "@\"Rene\"#p250510 Evo, mislim da sam uspio i taj.\n\nIz modela vidimo da postoje 4 bazne funkcije [imath]\\phi_j[/imath] s tim da je [imath]\\phi_0(\\vec{x})=1 [/imath] pa ona nema parametara.\n\nOstale 3 su definirane kao [imath]\\phi_j(\\vec{x})=w_{j0} + w_{j1} x_1 + ... + w_{j10}x_{10} [/imath] dakle svaka ima 11 parametara.\n\nSvaka od 3 klase jo≈° ima svoj vektor [imath] \\vec{w_k} = (w_{k0}, w_{k1}, w_{k2}, w_{k3}) [/imath].\n\nUkupno je to onda 3 * 11 + 3 * 4 = 45 parametara.",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ollie",
          "angello2",
          "matt (Matt)",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250611": {
      "poster": "viliml",
      "content": "> @\"Rene\"#p250510 C ne konvergira jer logistiƒçka regresija (neregularizirana) ne konvergira za linearno odvojive primjere.\n\nTe≈æine ne konvergiraju (te≈æe beskonaƒçnosti), ali empirijska pogre≈°ka i dalje konvergira prema nuli.\n\nAli istina da D takoƒëer konvergira.\n\n@\"Rene\"#p250527 \n\nU zadatku pi≈°e da su bazne funkcije definirane kao \"skalarni produkt vektora znaƒçajki i vektora primjera\". Ako ignoriramo to ≈°to su vjerojatno htjeli reƒái \"vektora znaƒçajki i vektora *te≈æina*\", to nala≈æe da imaju 10 parametara. Nije pisalo \"afina funkcija\". Ali ne bi me ƒçudilo da je to isto njihova gre≈°ka.\n\nTakoƒëer nigdje nije reƒçeno da je nulta bazna funkcija konstanta, ali ok, recimo da je to zdravi razum kojeg ja nemam.",
      "votes": {
        "upvoters": [
          "Rene",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250616": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"viliml\"#p250611 E ali uzmi u obzir da ƒáe ti se tih 10 znaƒçajki potencijalno pro≈°iriti dummy znaƒçajkom, takva je i praksa na predmetu. Trebalo bi urediti zadatak da ne pi≈°e ovo \"kao i na predavanju\", nego da pi≈°e konkretno o ƒçemu se radi.",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250732": {
      "poster": "BillIK",
      "content": "Kako odabiremo najbolju stopu uƒçenja? Ima ƒçitava ona priƒça u skripti, ali postoji li neki kraƒái odgovor bez toliko teoretiziranja tipa. ona za koju ƒáe pogre≈°ka bit min/max?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250740": {
      "poster": "Jale (ƒçakijale)",
      "content": "Jel imao netko problema s Pycharmom i prikazivanjem grafova? Uopce mi se ne prikaze graf u Pycharmu nego se otvori novi smrznuti prozor (Not responding). Kad isti kod pokrecem u browseru, najnormalnije se prikazuje. Nisam uspio nista korisno naci na internetu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250766": {
      "poster": "rolotex (brr)",
      "content": "![](assets/2021-11-07/00009.png)\n\nZna netko ovaj",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250844": {
      "poster": "jazzMassive",
      "content": "@\"Jale\"#p250740 zakomentiraj onaj red u prvoj celiji inline pylab, al nemoj zaboraviti vratiti kada pokazujes asistentu",
      "votes": {
        "upvoters": [
          "Jale (ƒçakijale)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250851": {
      "poster": "bodNaUvidima",
      "content": "@\"Rene\"#p250527 Gdje pi≈°e da se uzima da je nulta bazna funkcija konstantno preslikavanje znaƒçajki u 1? Ne mogu naƒái to u literaturi na intranetu niti se sjeƒáam da je to nagla≈°eno u videopredavanju.",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250866": {
      "poster": "BillIK",
      "content": "@\"BillIK\"#p250732  anyone?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250870": {
      "poster": "bodNaUvidima",
      "content": "@\"BillIK\"#p250866 Idealna stopa uƒçenja bi bila ona s kojom mo≈æe≈° izaƒái iz svakog lokalnog minimuma i uvijek zavr≈°iti u globalnom, a to znati unaprijed je koliko znam nemoguƒáe.",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250872": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"BillIK\"#p250866 a nema bas neki definitan odgovor. Velike stope ucenja su u pravilu brze, ali ne nuzno jer ovisi kakve gradijente pogadas. Dodatno ako je stopa prevelika onda raste sansa da ti algoritam divergira. Uglavnom, trazis omjer brzine i tocnosti, koliko sam shvatio.",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250882": {
      "poster": "Rene",
      "content": "@\"bodNaUvidima\"#p250851 nije nu≈æno ali na ptedavanju je snajder rekao da je uobicajeno\n\nBar ja tako imam u biljeskama",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250965": {
      "poster": "viliml",
      "content": "@\"bruuum\"#p250766 \n\n[math]-\\log(1-\\sigma(0.15+\\mathbf{w}^\\intercal\\mathbf{x}))=0.274 \\\\\n-\\log\\sigma(0.15+\\mathbf{w}^\\intercal(2\\mathbf{x})) =\\space?[/math]\n\n[math]1-\\sigma(0.15+\\mathbf{w}^\\intercal\\mathbf{x})=e^{-0.274} \\\\\n\\sigma(0.15+\\mathbf{w}^\\intercal\\mathbf{x})=1-e^{-0.274} \\\\\n\\mathbf{w}^\\intercal\\mathbf{x}=\\log(-\\frac{1-e^{-0.274}}{1-e^{-0.274}-1})-0.15 \\\\\n=\\log(\\frac{1-e^{-0.274}}{e^{-0.274}})-0.15 \\\\\n=\\log(e^{0.274}-1)-0.15[/math]\n\n[math]-\\log\\sigma(0.15+\\mathbf{w}^\\intercal(2\\mathbf{x})) = -\\log\\sigma(0.15+2\\mathbf{w}^\\intercal\\mathbf{x}) \\\\\n=-\\log\\sigma(0.15+2(\\log(e^{0.274}-1)-0.15)) \\\\\n=-\\log\\sigma(0.15+2(\\log(e^{0.274}-1)-0.15)) \\\\\n=-\\log\\sigma(2\\log(e^{0.274}-1)-0.15) \\\\\n\\approx 2.54[/math]",
      "votes": {
        "upvoters": [
          "Ollie",
          "cajaznun",
          "jobi (azex)",
          "matt (Matt)",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
          "rolotex (brr)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251026": {
      "poster": "[deleted]",
      "content": "@\"Rene\"#p250510 mo≈æda sam ja oma≈°io ceo fudbal, al za≈°to primjeri nisu linearno odvojivi? jel ih ne bi mogla odvojiti ploha y=0 npr.?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251033": {
      "poster": "Rene",
      "content": "@\"Todd Chavez\"#p251026 ne znam ≈°to misli≈° pod \"y\" ali s obzirom da je x2 = 0 onda mo≈æe≈° skicirat ove primjere s ovim preslikavanjima:![](assets/2021-11-07/00025.png)\n\n[imath]\\phi_0[/imath] i [imath]\\phi_2[/imath]  izgledaju kao lijeva slika (ƒçlan x1x2 zanemaruje≈° jer je uvijek 0), a [imath]\\phi_1[/imath]  izgleda kao desna slika (zanemaruje≈° x2 i x2^2)",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251035": {
      "poster": "[deleted]",
      "content": "@\"Rene\"#p251033 aa hvala ja sam gledao y kao vrijednosti i onda sam zapravo crtao (x, y) graf pa mi nije bilo jasno jer na njemu su odvojivi. tako nesto bi bilo ok za regresiju ili ni tada?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251044": {
      "poster": "Rene",
      "content": "@\"Todd Chavez\"#p251035 linearna odvojivost primjera == moguƒánost da ih odvoji≈° u klase hiperravninom, nema veze s regresijom",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251074": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "> @\"BillIK\"#p250732 ali postoji li neki kraƒái odgovor bez toliko teoretiziranja tipa. ona za koju ƒáe pogre≈°ka bit min/max?\n\nNe\n\nTo se, uostalom, rje≈°ava i drukƒçijim algoritmima, a ne samo drukƒçijom vrijednosti i otvoreni je (potencijalno nerje≈°ivi) problem.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "252230": {
      "poster": "nnn (dinoo)",
      "content": "Zna netko 4 i 6 iz dz08/v08?\n\n![](assets/2021-11-10/00009.png)![](assets/2021-11-10/00010.png)",
      "votes": {
        "upvoters": [
          "Sulejman",
          "angello2",
          "cajaznun",
          "cloudies",
          "netko_tamo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "253724": {
      "poster": "angello2",
      "content": "moze bar neko objasnjenje za 6. zad iz ispita? probo sam svasta i nikad mi ne ispadne ovo njihovo rjesenje",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "253805": {
      "poster": "viliml",
      "content": "@\"dino\"#p252230 @\"angello2\"#p253724 \n\nKao prvo, u SVM-u se [imath]w_0[/imath] tretira posve zasebno od svega ostaloga. Dakle treba izbrisati prvi stupac matrice dizajna i prvu vrijednost u vektoru [imath]\\mathbf{w}[/imath].\n\nZatim treba pronaƒái oznake primjera i odrediti koji od njih su potporni. To se lako vidi iz vrijednosti hipoteze [imath]\\mathbf{w}^\\intercal\\mathbf{x}^{(i)}+w_0[/imath].\n\nSada samo treba primijeniti ekvivalentnost primarnog i dualnog modela [imath]\\mathbf{w}=\\sum_{i=1}^N{\\alpha_iy^{(i)}\\mathbf{x}^{(i)}}[/imath] da se naƒëu vrijednosti dualnih parametara.\n\nNedostatak preciznosti u zadanim vrijednostima mo≈æe malo zakomplicirati stvar jer neƒáe biti toƒçne jednakosti, aproksimacija se mo≈æe uƒçiniti robustnijom tako da se iskoristi ograniƒçenje [imath]\\sum_{i=1}^N{\\alpha_iy^{(i)}=0}[/imath] i tako smanji broj varijabli za 1.",
      "votes": {
        "upvoters": [
          "angello2",
          "fraki"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Kasperinac",
          "netko_tamo",
          "pvmnt (ostaje.mi.to.sto.se.volimo)"
        ]
      }
    },
    "253878": {
      "poster": "netko_tamo",
      "content": "@\"viliml\"#p253805 ja i dalje ne dobivam njhovo rje≈°enje, ƒçak ni ne dobivam da mi predikcija za neke primjere daje 1 pa nemam ni potporne vektore...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "253896": {
      "poster": "viliml",
      "content": "@\"netko_tamo\"#p253878\n\n[math]\\left(\n\\begin{array}{ccccc}\n 1 & 3 & 16 & -8 & -11 \\\\\n 1 & -5 & 4 & -8 & -7 \\\\\n 1 & 7 & -4 & 11 & 9 \\\\\n 1 & 15 & -20 & 25 & 25 \\\\\n\\end{array}\n\\right) \\left(\n\\begin{array}{c}\n 0.137 \\\\\n -0.029 \\\\\n 0.0194 \\\\\n -0.0461 \\\\\n -0.0388 \\\\\n\\end{array}\n\\right)=\\left(\n\\begin{array}{c}\n 1.16 \\\\\n 1. \\\\\n -1. \\\\\n -2.81 \\\\\n\\end{array}\n\\right)[/math]",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "253944": {
      "poster": "Rene",
      "content": "@\"dino\"#p252230 Jel iko rjesio 4.? Meni se cini da je rjesenje pod B tocno?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "253971": {
      "poster": "pvmnt (ostaje.mi.to.sto.se.volimo)",
      "content": "@\"Rene\"#p253944 povuci pravac izmedu dvije najblize tocke s lijeve strane i okomica na taj pravac s primjerom 3,3 ce ti bit u 0,0 pa ce ti 3,3 bit udaljeno od tog pravca korijen iz 3*3+3*3 sta je korijen iz 18, margina je korijen iz 18/2, sve podijeljeno s 1/2 sto je margina od prvog treniranja dobijes da je omjer korijen iz 18, sto je 3 puta korijen iz 2. pozdrav!",
      "votes": {
        "upvoters": [
          "Rene"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "253975": {
      "poster": "pvmnt (ostaje.mi.to.sto.se.volimo)",
      "content": "@\"legend649\"#p253971 ma nabijem na kurac ovaj forum ove nakosene 33 je 3 puta 3. neuk sam i nepismen. pozdrav!",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Bucc (Olive Oil)",
          "Kasperinac",
          "Lyras",
          "Tone",
          "kix7 (Fish99)",
          "pingvinka",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "254030": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"legend649\"#p253975 Preporuƒçam kori≈°tenje latexa za jednad≈æbe, ili escape znaka `\\`",
      "votes": {
        "upvoters": [
          "matt (Matt)"
        ],
        "downvoters": [
          "Dootz",
          "Kasperinac"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254047": {
      "poster": "steker",
      "content": "Postoje neki sluzbeni materijali za neparametarske metode osim natuknica?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254218": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "Koje je gradivo zadnje za meduispit(koja preza) (ukljuƒçeno) ?",
      "votes": {
        "upvoters": [
          "Han"
        ],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254220": {
      "poster": "[deleted]",
      "content": "@\"Tompa007\"#p254218 https://www.fer.unizg.hr/predmet/struce1/obavijesti?@=2ur9b#news_142309",
      "votes": {
        "upvoters": [
          "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254543": {
      "poster": "boogie_woogie (nika_1999)",
      "content": "Zna netko ovaj?\n\n![](assets/2021-11-16/00008.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254642": {
      "poster": "viliml",
      "content": "@\"boogie_woogie\"#p254543 \n\nSamo izraƒçuna≈° vrijednosti hipoteze i to uvrsti≈° u formulu za gubitak zglobnice uz [imath]\\lambda=1/C[/imath].",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254646": {
      "poster": "tomekbeli420",
      "content": "@\"boogie_woogie\"#p254543 najprije treba≈° izraƒçunati vektor te≈æina [imath]\\mathbf{w}[/imath] kako bi mogao raƒçunati gubitke zglobnice. Taj vektor te≈æina mo≈æe≈° iz vektora [imath]\\boldsymbol{\\alpha} = \\left(\\alpha_1 , \\alpha_2 , \\alpha_3\\right) = \\left(0, 0.01, 0.01\\right)[/imath] raƒçunati preko one poveznice kad se prelazilo iz primarnog problema meke margine u dualni:\n\n[math]\\mathbf{w} = \\sum_{i=1}^{N} \\alpha_i y^{(i)} \\mathbf{x}^{(i)}[/math]\n\nSve te podatke ima≈°, kad se uvrsti dobije≈° [imath]\\mathbf{w} = \\left(0.02, 0, 0.03\\right)[/imath]\n\nEmpirijska pogre≈°ka SVM-a na skupu [imath]\\mathcal{D}[/imath] se raƒçuna kao:\n\n[math]E_{R} \\left(\\mathbf{w}, w_0 \\vert \\mathcal{D} \\right) = \\sum_{i=1}^{N} \\max{\\left(0, 1 - y^{(i)} h \\left(\\mathbf{x}^{(i)}; \\mathbf{w}, w_0\\right)\\right)} \\  + \\frac{1}{2 C} \\| \\mathbf{w} \\|^2[/math]\n\ngdje je [imath]h \\left(\\mathbf{x}; \\mathbf{w}, w_0\\right) = \\mathbf{w}^{\\mathrm{T}} \\mathbf{x} + w_0[/imath] hipoteza iz primarnog modela ([imath]w_0 = -0.8[/imath] je dan da se mo≈æe izraƒçunati). Zadatak ka≈æe da je kori≈°tena linearna jezgra, pa kao stoga nema dodatnog preslikavanja primjera nego uz te≈æine stoje sirovi, nepreslikani primjeri [imath]\\mathbf{x}[/imath]. Za primjere one redom iznose -1, -1, -0.87\n\nStoga njihovi gubici zglobnice iznose redom 0, 0, 1.87, dakle u zbroju daju 1.87, kvadrat L2 norme iznosi [imath] \\| \\mathbf{w} \\|^2 = 0.0013[/imath], [imath]C = 0.01[/imath] je takoƒëer zadan i kad sve to uvrsti≈° dobije≈°\n\n[imath]E_{R} \\left(\\mathbf{w}, w_0 \\vert \\mathcal{D} \\right) = 1.87 + \\frac{1}{2 \\cdot 0.01} \\cdot 0.0013 = 1.935[/imath]\n\nEdit: tek sad sam shvatio da si mogao iznose hipoteza raƒçunati i bez vraƒáanja nazad u primaran model, al u svakom sluƒçaju ti trebaju te≈æine iz primarnog modela zbog regularizacijskog faktora.\n\n\n\n\nOn topic, jel uspio netko ovaj: V10 - Jezgrene metode, zadaci s ispita 4. zadatak\n\nnikak ne mogu doƒái do rje≈°enja, kod raƒçunanja hipoteze ona suma koja ima alfe, oznake i jezgrenu funkciju mi ispada reda veliƒçine [imath]10^{-3}[/imath], nisam i≈°ao raƒçunati [imath]w_0[/imath] jer sam odustao\n\n![](https://i.imgur.com/25w5UnO.png)",
      "votes": {
        "upvoters": [
          "Ducky",
          "InCogNiTo124",
          "bodNaUvidima",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "boogie_woogie (nika_1999)",
          "gladiator",
          "matt (Matt)",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254691": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-16/00018.png)\n\nzas je ovdje prije sume minus?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254695": {
      "poster": "tomekbeli420",
      "content": "@\"Todd Chavez\"#p254691 \n\nJer ograniƒçenja nejednakosti u standardnom obliku su ne≈°to <= 0, a kad ono ograniƒçenje di ima≈° >= 1 preformulira≈° (prebaci≈° 1 na lijevu stranu i pomno≈æi≈° sa -1 da obrne≈° nejednakost) dobije≈° ovo ≈°to pi≈°e uz alfe",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254704": {
      "poster": "viliml",
      "content": "@\"tomekbeli420\"#p254646 Hipoteze za potporne vektore ispadnu -1.97711 + w0, -1.92673 + w0 i 0.0544753 + w0, a za primjer 0.00106184 + w0\n\nw0 je otprilike 0.95, pa je vrijednost hipoteze za primjer otprilike 0.95.",
      "votes": {
        "upvoters": [
          "boogie_woogie (nika_1999)",
          "tomekbeli420"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254708": {
      "poster": "Rene",
      "content": "Kako odrediti jesu li primjeri linearno odvojivi nakon preslikavanja u prostor znaƒçajki? Veƒá nekoliko takvih zadataka sam susreo, a nije mi ba≈° jasno s obzirom da ne mogu nacrtati ni izraƒçunati izlaz modela da odredim oznake?\n\nNpr. V10 3. zadatak za uƒçenje d), oke dobio sam preslikavanje [imath]\\phi(\\vec{x})=\\begin{pmatrix}x_1^2 &x_2^2 & x1x2\\sqrt2 &x_1\\sqrt2 & x_2\\sqrt2 &1\\end{pmatrix}[/imath], ali kako onda provjeriti je li XOR problem linearno odvojiv?\n>! ![](assets/2021-11-16/00019.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254722": {
      "poster": "viliml",
      "content": "@\"Rene\"#p254708 Treba pogaƒëati i vidjeti da je [math]XOR=x_1+x_2-2x_1 x_2=\\frac{-2\\phi_3+\\phi_4+\\phi_5}{\\sqrt 2}[/math]",
      "votes": {
        "upvoters": [
          "Rene"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254724": {
      "poster": "Rene",
      "content": "@\"viliml\"#p254722 Kako? x=(1, 1) => 1 + 1 - 1 = 1, po tvom izrazu?\n\nEDIT: vidim, zapravo je [imath] x_1 + x_2 - 2x_1x_2[/imath], hvala!",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254727": {
      "poster": "tomekbeli420",
      "content": "@\"Rene\"#p254708 ja sam rekao da jest linearno odvojivi i to sam argumentirao logikom da granica\n\n[imath]h \\left(\\mathbf{x} ; \\mathbf{w}, w_0 \\right) = \\mathbf{w}^{\\mathrm{T}} \\boldsymbol{\\phi} \\left(\\mathbf{x}\\right) + w_0 = 0[/imath]\n\nJe krivulja drugog reda (najopƒáenitija bez ograniƒçenja). Takva krivulja drugog reda je sposobna odvojiti primjere kod XOR problema.\n\nKod jezgrene funkcije [imath]\\kappa \\left(\\mathbf{x}, \\mathbf{z}\\right) = \\left(\\mathbf{x}^{\\mathrm{T}} \\mathbf{z}\\right)^2[/imath] sam pak preslikao u 3D prostor znaƒçajki sa pripadnon funkcijom preslikavanja, dobio sam\n\n[imath]\\boldsymbol{\\phi} \\left(\\mathbf{x}\\right) = \\left(x_1^2 , \\sqrt{2} x_1 x_2 , x_2^2\\right)[/imath]\n\nI tu sam na≈°ao (naprosto sam nacrtao preslikane primjere i gledao koju ravninu povuƒái) ravninu koja razdvaja\n\n[imath]\\mathbf{w} = \\left(2, -2, 2\\right) \\qquad w_0 = -1.5[/imath]\n\nAko ba≈° hoƒáe≈°, iste te≈æine bi se mogle iskoristiti za naƒái hiperravninu kod prve jezgrene funkcije\n\nEvo nadam se da mi sve ≈°tima i da nisam ne≈° sjebo",
      "votes": {
        "upvoters": [
          "Rene"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254741": {
      "poster": "viliml",
      "content": "@\"Rene\"#p254724 Da sori i≈°ao sam napamet i zbunio sam se, znao sam da je tako ne≈°to otprilike.\n\n@\"tomekbeli420\"#p254727 Hoƒáe≈° reƒái da prostor hipoteza obuhvaƒáa *sve* krivulje drugog reda? To je validno, ali treba obrazlo≈æiti za≈°to postoji krivulja drugog reda koja odvaja XOR, ≈°to je ekvivalentno originalnom problemu osim ako se to smatra opƒáe poznatim...\n\nAli u svakom sluƒçaju za drugu jezgru se mora naƒái ruƒçno (hipoteza je isto krivulja drugog reda ali nije opƒáenita), a po≈°to su za  binarne znaƒçaje [imath]x[/imath] i [imath]x^2[/imath] ista stvar, vidi se da je rje≈°enje za jedno ujedno i rje≈°enje za drugu.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254755": {
      "poster": "tomekbeli420",
      "content": "@\"viliml\"#p254741 da to sam mislio\n\nZa≈°to postoji krivulja? Vizualno je trivijalno konstruirati primjer takve krivulje xD\n\nDa mi se da zajebavati sa rotacijama ƒçak bi i slo≈æio te≈æine koje ƒçine elipsu oko pozitivnih primjera, al mi se ne da (a i mo≈æe se napamet ne≈°to nabosti)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254762": {
      "poster": "Rene",
      "content": "@\"viliml\"#p254704 otkud ti da je w0 otprilike 0.95?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254767": {
      "poster": "netko_tamo",
      "content": "![](assets/2021-11-16/00021.png)\n\nmoze neko objasniti? koristimo 50 znacajki ak sam dobro pobrojao",
      "votes": {
        "upvoters": [
          "batman3000"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254774": {
      "poster": "Fica (Prof)",
      "content": "@\"netko_tamo\"#p254767 Izbacuje≈° prosjek ocjena jer ti je savr≈°eno koreliran sa prosjecima svake godine i onda ima≈° 6 linearnih i 6 kvadratnih + 1 i jo≈° za interakcijske ima≈° 6 povrh 2 = 15 i 6 povrh 3 = 20 i onda ispadne 6+6+1+15+20=48",
      "votes": {
        "upvoters": [
          "netko_tamo",
          "zara"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "netko_tamo"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "254776": {
      "poster": "netko_tamo",
      "content": "@\"Prof\"#p254774 tenks :D",
      "votes": {
        "upvoters": [
          "Fica (Prof)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254803": {
      "poster": "netko_tamo",
      "content": "![](assets/2021-11-16/00023.png)\n\nL2 norma je sqrt(wTw), dobivam 2.96, ocito nekaj kardinalno krivo radim pa ne vidim hahah",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254812": {
      "poster": "viliml",
      "content": "@\"Rene\"#p254762 hipoteze potpornih vektora moraju biti +-1",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254814": {
      "poster": "viliml",
      "content": "@\"netko_tamo\"#p254803 Norma gradijenta gubitka, ne norma te≈æina.\n\nHipoteza je mrvicu veƒáa od 0 dakle gre≈°ka je mrvicu manja od 1 dakle gradijent je mrvicu manji od vektora znaƒçajki koji ima normu 2.5",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254815": {
      "poster": "Rene",
      "content": "@\"viliml\"#p254812 ne moraju ako je rijec o mekoj margini?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254880": {
      "poster": "viliml",
      "content": "@\"Rene\"#p254815 Nigdje ne pi≈°e da je meka.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254917": {
      "poster": "Banananjeros",
      "content": "Mo≈æe li neko dati neki hack kako razlikovati induktivnu pristranost jezikom od induktivne pristranosti preferencijom?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254942": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Banananjeros\"#p254917 \n\nPristranosti jezikom biras model, dakle skup svih hipoteza koje dolaze u obzir. Iz tog skupa mora≈° nekako odabrati jednu hipotezu. To ƒçini≈° funkcijom pogre≈°ke, i to je upravo pristranost preferencijom. Dodatno, ako prostor inaƒçica ima vi≈°e hipoteza (2, 3, inf), opet mora≈° izabrati jednu, (kod SVM-a recimo onu s najvecom marginom), to je isto pristranost preferencijom.\n\nProstor inaƒçica je skup svih hipoteza nekog modela koje ispravno klasificiraju (tj predviƒëaju kod regresije) sve primjere.",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254968": {
      "poster": "Banananjeros",
      "content": "@\"Precious Bodily Fluids\"#p254942 Je li pristranost preference iskljuƒçivo tra≈æenje neke hipoteze u prostoru inaƒçica ili tra≈æenje neke hipoteze u prostoru hipoteza opƒáenito?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "254988": {
      "poster": "viliml",
      "content": "@\"Banananjeros\"#p254968 Po definiciji to bi trebalo biti u prostoru inaƒçica, ALI...\n\nMi zapravo skoro nikad ne radimo ba≈° s prostorom inaƒçica.\n\nƒåesto je ili prostor inaƒçica prazan, ili mi mo≈æda odaberemo hipotezu izvan prostora inaƒçica jer ona bolje generalizira.\n\nPrisutnost ≈°uma i moguƒánosti krivo klasificiranih primjera za treniranje ƒçine koncept prostora inaƒçica besmislenim.\n\nJedini sluƒçaj kad uistinu radimo direktno s prostorom inaƒçica je SVM s tvrdom marginom.\n\nAli funkciju pogre≈°ke ipak ƒçesto neprecizno nazivaju pristranost preferencije, i ako doƒëe takvo pitanje u ispitu trebao bi ne razmi≈°ljati preduboko o tome jer oni sigurno nisu.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255125": {
      "poster": "gladiator",
      "content": "Imam pitanje za te≈æinski k-NN. Za≈°to gledamo **sve** primjere (i za sve primjere raƒçunamo k(x_i, x)) kad koristimo k-NN.\n\nTu gubimo \"k\" iz k-NN. Zar ne bi smo trebali gledati najbli≈æe primjere i onda na temelju njih i rezultatata funkcije k(x_i, x) zakljuƒçiti kojoj klasi pripada x?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255128": {
      "poster": "Rene",
      "content": "@\"gladiator\"#p255125 mislim da se moze i jedno i drugo, na predavanju je snajder napisao da se uobicajeno koristi N ali da suma moze ic i samo za k najblizih",
      "votes": {
        "upvoters": [
          "gladiator"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255147": {
      "poster": "gad_gadski",
      "content": "![](assets/2021-11-18/00006.png)\n\nJel zna netko kako oni dobiju 2.69? Meni ispada 2.7346, kvadratna pogreska mi ispadne 2.1846 i onda to zbrojeno s 1/2 * 1.1 = 2.7346 \n\n![](assets/2021-11-18/00007.jpg)",
      "votes": {
        "upvoters": [
          "BillIK",
          "faboche (him)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255179": {
      "poster": "BillIK",
      "content": "![](assets/2021-11-18/00010.png)\n\n zna netko ovaj zadatak?",
      "votes": {
        "upvoters": [
          "blast"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255180": {
      "poster": "Amariska",
      "content": "@\"gad_gadski\"#p255147 \n\nKad se raƒçuna L1-norma uzimaju se apsolutne vrijednosti i to bez te≈æine w0, pa ima≈° 0.94+0.08 = 1.02\n\n2.1846 + 1.02/2 = 2.69",
      "votes": {
        "upvoters": [
          "BillIK",
          "Ducky",
          "Upforpslone",
          "gad_gadski",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255190": {
      "poster": "Amariska",
      "content": "@\"BillIK\"#p255179 \n\nProsjek ocjena se treba izbaciti jer je kombinacija prve ƒçetiri znaƒçajke. \n\nlinearne: x1, x2, x3, x4, x6, x7\n\nkvadratne: x1^2, x2^2....\n\ninterakcijske: parova ima 6C2 = 15, trojki ima 6C3 = 20\n\n6 + 6 + 15 + 20 + dummy = 48\n\nRang matrice mora biti m+1=48, pa treba biti minimalno 48 primjera jer da ih je manje i rang bi bio manji, tj. bio bi max N",
      "votes": {
        "upvoters": [
          "BillIK",
          "Ducky",
          "blast",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255386": {
      "poster": "Banananjeros",
      "content": "![](assets/2021-11-19/00004.png)\n\nMo≈æe li neko objasnit ovaj?Za≈°to je A toƒçno i za≈°to regresija nema ovaj problem, a perceptron ima?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255392": {
      "poster": "BillIK",
      "content": "@\"netko_tamo\"#p254803 mo≈æe≈° slikati postupak ako si rije≈°io?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255407": {
      "poster": "SuperSjajan3",
      "content": "Moze pomoc oko ovog zadatka pls. Raspisem L tako da dobijem h(x), al onda ne znam sta bi dalje s tim\n\n![](assets/2021-11-19/00005.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255408": {
      "poster": "SuperSjajan3",
      "content": "@\"Banananjeros\"#p255386 \n\nova dva odgovora prosle generacije:\n\n@\"cotfuse\"#p93340 \n\n@\"cotfuse\"#p93390",
      "votes": {
        "upvoters": [
          "zara"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255414": {
      "poster": "BillIK",
      "content": "@\"SuperSjajan3\"#p255407 h(x) je sigmoidalna funkcija od umno≈°ka te≈æina i primjera + w0. Izraƒçunaj umno≈æa≈° w^T*X i koristi za raƒçunanje novog gubitka, ali pomno≈æeno s 2 jer ti ka≈æe da se znaƒçajke mno≈æe s dva i s promijenjenom oznakom",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255415": {
      "poster": "lovro (l123)",
      "content": "Jel ima neki jednostavan naƒçin za downgrade matplotlib-a bez da ga deinstaliravam pa instaliravam stariju verziju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255417": {
      "poster": "tomekbeli420",
      "content": "@\"Banananjeros\"#p255386 zato ≈°to algoritam perceptrona se zaustavlja tek onda kad su svi primjeri ispravno klasificirani, dok gradijentni spust kod logistiƒçke regresije se zaustavlja kad se dosegne minimum funkcije pogre≈°ke (globalni, jer je konveksna), koji mo≈æe biti koliki god (nikad 0 tho), pa makar i relativno visok zbog linearne neodvojivosti. To ƒáe se uvijek desiti ako se koristi linijsko pretra≈æivanje",
      "votes": {
        "upvoters": [
          "Banananjeros"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255427": {
      "poster": "SuperSjajan3",
      "content": "@\"BillIK\"#p255392 malo je neuredno, puno brisanja je bilo, reci ak nesto ne vidis procitat\n\n![](assets/2021-11-19/00008.png)",
      "votes": {
        "upvoters": [
          "BillIK",
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255433": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"viliml\"#p250965 \n\nKako si do≈°ao do ove prve dvije formule?\n\n![](assets/2021-11-19/00009.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255438": {
      "poster": "steker",
      "content": "![](assets/2021-11-19/00010.jpg)\n\nZasto D nije tocan",
      "votes": {
        "upvoters": [
          "[deleted]",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255440": {
      "poster": "gad_gadski",
      "content": "@\"BillIK\"#p255414 ![](assets/2021-11-19/00011.jpg)\n\nMeni uporno 1.2164 ispada, je li samo treba ovaj umnozak w*x pomnoziti s dva ili? Nez di mi je greska",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255450": {
      "poster": "cloudies",
      "content": "@\"gad_gadski\"#p255440 Koliko mi se cini, ti si pomnozio sve s 2, a tamo ti se nalazi i dummy jedinica koju si pretvorio u dvojku. Msm da trebas razdvojit na w i w0.",
      "votes": {
        "upvoters": [
          "Jale (ƒçakijale)",
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255453": {
      "poster": "Amariska",
      "content": "@\"gad_gadski\"#p255440 \n\n>!![](assets/2021-11-19/00014.jpg)",
      "votes": {
        "upvoters": [
          "Ducky",
          "gladiator"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255459": {
      "poster": "BillIK",
      "content": "@\"gad_gadski\"#p255440 ovo ≈°to je kolega @\"cloudies\"#p255450  napisao",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255471": {
      "poster": "Banananjeros",
      "content": "![](assets/2021-11-19/00018.png)\n\nJasno mi je za≈°to A i B neƒáe konvergirati, ali koja je razlika izmeƒëu C i D? Za≈°to logistiƒçka regresija s linearno odvojivim PHI1 preslikavanjem neƒáe konvergirati?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255475": {
      "poster": "prx_xD",
      "content": "Ima netko mo≈æda ss od pro≈°logodi≈°njih moodle kvizova",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255482": {
      "poster": "sheriffHorsey",
      "content": "@\"Banananjeros\"#p255471 pa upravo je poanta u tome sto imas linearno odvojiv slucaj, algoritam ce povecavati tezine, ako tezine rastu onda raste i vrijednost umnoska [imath]\\mathbf{w}^T \\phi(\\mathbf{x})[/imath], a ako to raste onda sigmoida uvijek moze biti sve strmija i liciti sve vise na funkciju praga pa onda uvijek mozes smanjiti gubitak, a u d slucaju posto nemas linearnu odvojivost nemas taj problem i u jednom trenu neces vise moc smanjiti gubitak pa dolazi do konvergencije",
      "votes": {
        "upvoters": [
          "Banananjeros"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255485": {
      "poster": "tomekbeli420",
      "content": "@\"steker\"#p255438 Neka je zadana sljedeƒáa situacija:\n\nNeka je [imath]\\mathcal{X} = \\mathbb{R}[/imath], odnosno [imath]n = 1[/imath], i naravno [imath]\\mathcal{Y} = \\left\\{-1, +1\\right\\}[/imath], te neka je skup primjera za uƒçenje\n\n[imath]\\mathcal{D} = \\left\\{\\left( x^{(i)}, y^{(i)} \\right)\\right\\} = \\left\\{\\left(2, -1\\right), \\left(6, +1\\right)\\right\\}[/imath]\n\nJasno je da su primjeri linearno odvojivi.\n\nOdgovor D implicira da postoji moguƒánost da ƒáe SVM izabrati ovakvu hipotezu\n\n[imath]h \\left(x ; w_1, w_0\\right) = x - 5[/imath]\n\nodnosno da je [imath]w_1 = 1[/imath] i [imath]w_0 = -5[/imath]\n\n≈°to bi znaƒçilo da je granica [imath]x = 5[/imath]\n\nproblem je kod ovog \"... za najbli≈æe primjere\" jer se tu nigdje ne spominje da SVM udaljenost najbli≈æih primjera mora maksimizirati, pa je prema tom odgovoru moguƒáe da mu je najbli≈æi samo jedan primjer (u na≈°em primjeru ova ≈°estica), i za taj primjer da vrijedi [imath]y h(x) = 1[/imath]. To naravno kod pravog SVM-a nije istina, jer on maksimizira minimalnu udaljenost, i to je sve ukodirano sa onim problemom minimizacije kvadrata vektora te≈æina uz ograniƒçenja da hipoteze moraju dati iznose apsolutno veƒáe od 1.",
      "votes": {
        "upvoters": [
          "matt (Matt)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255501": {
      "poster": "steker",
      "content": "Koja bi bila pristranost preferencijom kod perceptrona? Jel bi to zapravo bila linearna odvojivost podataka ili to nema veze s pristranoscu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255549": {
      "poster": "steker",
      "content": "@\"steker\"#p255501 ne znam jel ovo glupo razmisljanje, ali takoder jel se moze rec da su pristranosti jezikom kod SVM-a i perceptrona iste s obzirom da svm u primarnom obliku ima za h(x)=sgn(wtx), a perceptron h(x)=step(wtx), (znam da su step i sgn dvije razlicite func ali obje onako kako smo ih definirali na predavanjima bacaju van -1 tj1 za iste vrijednosti x)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255552": {
      "poster": "viliml",
      "content": "@\"Ivanƒçica\"#p255433 Prvo je gubitak primjera x s oznakom 0, drugo je gubitak primjera 2x s oznakom 1. Samo sam odmah izbacio onaj dio koji se mno≈æi s 0 u opƒáenitoj formuli, ionako je to zapravo samo te dvije formule prisilno spojene mno≈æenjem s 0/1.",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255567": {
      "poster": "viliml",
      "content": "@\"viliml\"#p255552 Zapravo mo≈æe≈° proƒái kroz cijeli izvod u poglavlju 2.1 skripte broj 6, preskoƒçiti ono kad zamjene if/else sa potenciranjem i mno≈æenjem i izvesti funkciju gubitka\n\n[math]L(y,h(\\mathbf{x}))=\\begin{cases} -\\ln h(\\mathbf{x}) & \\text{ako }y=1 \\\\ -\\ln (1-h(\\mathbf{x})) & \\text{inaƒçe} \\end{cases}[/math]\n\nIskreno ne znam za≈°to su uopƒáe radili te gluposti, ovaj oblik je puno jasniji.",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)",
          "Kasperinac"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255577": {
      "poster": "viliml",
      "content": "@\"steker\"#p255501 Perceptron nema nikakvu pristranost preferencijom. Svaka hipoteza koja ispravno klasificira skup za treniranje je njemu jednako dobra. To je jedan od mnogih razloga za≈°to je to lo≈° algoritam.\n\n@\"steker\"#p255549 Pristranost jezikom je praktiƒçki ista stvar ≈°to i model. SVM i perceptron oboje koriste linearni model, dakle da.",
      "votes": {
        "upvoters": [
          "matt (Matt)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255581": {
      "poster": "steker",
      "content": "@\"viliml\"#p255577 ![](assets/2021-11-19/00036.jpg)\n\nA onda ne razumijem zasto bi ovo pod B bilo krivo, osim ako je problem u prvom navodu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255583": {
      "poster": "viliml",
      "content": "@\"Banananjeros\"#p255471 Krivo je zadan zadatak jer **empirijska pogre≈°ka** uistinu konvergira i sa linearno odvojivim skupom podataka, stvar je da pritom **te≈æine** divergiraju.",
      "votes": {
        "upvoters": [
          "Banananjeros"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255588": {
      "poster": "viliml",
      "content": "@\"steker\"#p255581 Rekao bih da je to samo krivo zadan zadatak. Nije ni prvi ni zadnji put.\n\nMo≈æda opƒáenito zovu funkciju pogre≈°ke pristranosti preferencijom, ali problem je ≈°to niti perceptron niti SVM s tvrdom marginom nisu definirani kad skup primjera nije linearno odvojiv, a perceptron samo garantira da ƒáe naƒái **neku** hipotezu koja ih odvaja i ni≈°ta ne ka≈æe koju.\n\n*Mooooo≈æda* se mo≈æe reƒái da perceptron \"preferira\" onu hipotezu do koje ga sluƒçajno odvede gradijentni spust? To je malo ƒçudna preferencija, jer on niti ne zna da postoje ikoje druge, ali zapravo kad bolje razmislim, konzistentno je s rigoroznom definicijom pristranosti...",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255592": {
      "poster": "steker",
      "content": "@\"viliml\"#p255588 vrlo moguce, ugl hvala",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255642": {
      "poster": "Banananjeros",
      "content": "Za≈°to u jednom zadatku s SVM-om ka≈æemo da beskonaƒçno mnogo hipoteza zadovoljava uvjet savr≈°ene klasifikacije, ali u zadacima iz prvih tema ka≈æemo da je broj hipoteza konaƒçan jer vrijedi:\n> dvije funkcije su jednake ako jednako preslikavaju elemente iz domene u kodomenu\n\nZar ne bi prema citatu trebali sve te hipoteze smatrati jednom hipotezom jer na isti naƒçin preslikavaju primjere pa bi time broj hipoteza bio 1 tj. konaƒçan? Ali, time bi kardinalitet prostora inaƒçica uvijek bio 1.\n\n![](assets/2021-11-20/00005.png)\n\n![](assets/2021-11-20/00006.png)",
      "votes": {
        "upvoters": [
          "gladiator"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255646": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Banananjeros\"#p255642 \n\nStvar je u tome da je u zadatku \"prostor\" primjera R^n. Iako u prostoru inaƒçica jednako klasificira≈° sve viƒëene primjere (tj. sve iz tvog dataseta), postoji beskonaƒçno mnogo neviƒëenih primjera i svaki pravac ƒáe za njih dati malo drugaƒçiju klasifikaciju.\n\nOvo ≈°to citira≈° na poƒçetku vrlo vjerojatno opisuje klasifikaciju u diskretnom prostoru, npr {0, 1}x{0, 1}x{0, 1}, dakle vrhovi kocke. Tu ima≈° samo 8 moguƒáih primjera (oznaƒçenih i neoznaƒçenih). Ako napravi≈° malu modifikaciju na ravninu ona ƒáe vjerojatno i dalje sve primjere (viƒëene i neviƒëene) klasificirati kao i prije, dok u zadatku gore, gdje radimo u kontinuiranom prostoru to oƒçito nije sluƒçaj.",
      "votes": {
        "upvoters": [
          "gladiator",
          "viliml"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255647": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"viliml\"#p255577 \n\n@\"steker\"#p255581 \n\n> Mooooo≈æda se mo≈æe reƒái da perceptron ‚Äúpreferira‚Äù onu hipotezu do koje ga sluƒçajno odvede gradijentni spust?\n\nTako sam i ja shvatio. Pristranost preferencijom (PP) je cijeli optimizacijski postupak, ukljuƒçujuƒái fju pogre≈°ke i algoritam (npr. gradijentni spust). PP perceptrona je uzimanje hipoteze u kojoj gradijentni spust konvergira. Po toj logici onda PP modificira≈° hiperparametrom stope uƒçenja. \n\nAl idk, mo≈æda samo filozofiram i stvarno je gre≈°ka u zadatku üòÖ",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255712": {
      "poster": "BillIK",
      "content": "![](assets/2021-11-20/00015.png)\n\nima li netko postupak? ne dobivam toƒçno nikako",
      "votes": {
        "upvoters": [
          "Ardura (Maddy)",
          "matt (Matt)",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255719": {
      "poster": "faboche (him)",
      "content": "![](assets/2021-11-20/00016.png)\n\nkako dodemo do 1001 i 2829? (jezgrene metode, 1.zdk sa ispita)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255723": {
      "poster": "Rene",
      "content": "@\"faboche\"#p255719 varijanca gaussovih jezgri je hiperparametar, 28 prototipa√ó100znacajki + 28 pripadnih alfi + w0 je 2829 parametara, a optimiras 1000 alfi i w0",
      "votes": {
        "upvoters": [
          "faboche (him)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255724": {
      "poster": "BillIK",
      "content": "@\"faboche\"#p255719 pogledaj si formulu za gaussovu jezgru. Radi≈° preslikavanje jezgrenom funkcijom za svaki od N primjera pa ƒáe≈° dobiti dobiti Phi (x) = [1, k(x,x_1), k(x,x_2), ... k(x,x_N)] i svaka ta jezgrena funkcija je u biti jedna te≈æina, dakle dobiva≈° N+1 parametara, tj. 1001 (ovaj +1 je za w0). Dakle ima≈° 1001 parametar \n\nA ≈°to se tiƒçe nauƒçenog modela: \n\ndobiva≈° 28 prototipa, svaki od njih ima 100 znaƒçajki (prema tekstu zadatka) to je 28*100 = 2800 \n\nsvakoj znaƒçajki pridru≈æuje≈° jednu te≈æinu, ≈°to znaƒçi da dobiva≈° 28 te≈æina + 1 (za te≈æinu w0)\n\ntoƒçnije ima≈° 28*100 + 28 + 1 = 2829 parametara nauƒçenog modela\n\nEDIT: kad pi≈°em te≈æina, mislim na alfu",
      "votes": {
        "upvoters": [
          "faboche (him)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255735": {
      "poster": "MOXY",
      "content": "![](assets/2021-11-20/00021.png)\n\nzna netko objasniti ovaj?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255738": {
      "poster": "viliml",
      "content": "@\"BillIK\"#p255712 Djelomiƒçni postupak sam napisao u @\"viliml\"#p254704 \n\nOvo izmeƒëu je samo mno≈æenje matrica i vektora, dobar kalkulator bi to trebao moƒái sve odjednom.\n\nReci koje vrijednosti hipoteza dobiva≈° krive.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255741": {
      "poster": "viliml",
      "content": "@\"MOXY\"#p255735 Malo kasni≈°? To je bilo davno za zadaƒáu.\n\n![](assets/2021-11-20/00022.png)\n\nNema ≈°ta za objasniti, uvr≈°tava≈° u formulu.",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "AK10 (endyyyy)",
          "Bica",
          "Drmolirius",
          "Ferkonja (Ferkonja         ‚ÄÆajnokreF )",
          "Fica (Prof)",
          "Jaster111",
          "JogaBonito",
          "Kasperinac",
          "MOXY",
          "Skenk",
          "SuperSjajan3",
          "batman3000",
          "dh333",
          "matt (Matt)",
          "neksi (filip)",
          "netko_tamo",
          "sheriffHorsey",
          "stura",
          "zastozato (studo≈°)"
        ]
      },
      "reactions": {
        "haha": [
          "kix7 (Fish99)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "255743": {
      "poster": "Jaster111",
      "content": "@\"viliml\"#p255741 sori uƒçiteljice",
      "votes": {
        "upvoters": [
          "Bica",
          "Ferkonja (Ferkonja         ‚ÄÆajnokreF )",
          "MOXY",
          "SuperSjajan3",
          "angello2",
          "netko_tamo",
          "stura"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "AK10 (endyyyy)",
          "Bananaking",
          "Bica",
          "BillIK",
          "Bucc (Olive Oil)",
          "Fica (Prof)",
          "Gulbash",
          "MOXY",
          "Ollie",
          "Skenk",
          "Zk6dO73 (burw0r)",
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "cajaznun",
          "neksi (filip)",
          "netko_tamo",
          "pingvinka",
          "rolotex (brr)",
          "steker",
          "tomekbeli420",
          "zastozato (studo≈°)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "255744": {
      "poster": "BillIK",
      "content": "@\"viliml\"#p255738 dobar kalkulator pa w0 ne ispadne OTPRILIKE 0.95 nego 1.46",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255749": {
      "poster": "Rene",
      "content": "![](assets/2021-11-20/00023.png)\n\nMoze objasnjenje?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255764": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-20/00024.png)\n\n zasto ovdje B ne bi bilo toƒçno?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255769": {
      "poster": "Dootz",
      "content": "@\"Todd Chavez\"#p255764 Za razliƒçite parametre mo≈æes dobiti i istu funkciju h",
      "votes": {
        "upvoters": [
          "[deleted]",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "viliml"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255770": {
      "poster": "bodNaUvidima",
      "content": "@\"Todd Chavez\"#p255764 jer nema garancije da ƒáe dva razliƒçita skupa parametara dati drukƒçiju hipotezu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255779": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-20/00028.png)\n\na ovo ako netko zna logiku? prvo sam mislio da B uvodi nelinearnost pa zato, ali nije istina jer se koristi ova True/False fja\n\nnvm skuzio valjda, to je zato sto se u B moze dogodit da se pomno≈æe lossevi s ispravnima i onda rezultat bude 0 sve skupa",
      "votes": {
        "upvoters": [
          "MsBrightside"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255780": {
      "poster": "viliml",
      "content": "@\"BillIK\"#p255744 Kako raƒçuna≈° w0?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255782": {
      "poster": "viliml",
      "content": "@\"Rene\"#p255749 Granica izmeƒëu klasa je krivulja definirana jednad≈æbom h(x)=0. Ta krivulja je pravac ako je funkcija [imath]\\phi[/imath] linearna",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255786": {
      "poster": "viliml",
      "content": "@\"Todd Chavez\"#p255779 Pitanje se svodi na to koliko najvi≈°e predikcija mo≈æe≈° natjerati da istovremeno budu 0 na zadanom skupu. Drugi model je zapravo skup AND-ova hipoteza iz prvog modela, pa je logiƒçno da mo≈æe imati vi≈°e nula (skup nula je unija)",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255791": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-20/00030.png)\n\nkako je ovdje VS veci od 1? nije li nacrtano zelenim jedina ravnina koja ce tocno odvojiti sve mogucnosti uz pretpostavku linearne odvojivosti",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255795": {
      "poster": "Arya",
      "content": "DZ1: Model takoder nazivamo prostorom inacica, a dimenzija tog prostora jednaka je cemu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255796": {
      "poster": "[deleted]",
      "content": "@\"Arya\"#p255795 broju parametara.\n\n\n![](assets/2021-11-20/00031.png)\n\njel ne bi ovdje trebalo biti L(0, 1) > L(1, 0)? nije li redak == stvarni primjeri, a stupac predikcije",
      "votes": {
        "upvoters": [
          "Arya"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255798": {
      "poster": "Jaster111",
      "content": "![](assets/2021-11-20/00032.png)\n\nJel netko shvatio ≈°ta znaƒçi izraz \"do na ...\" jer sam vidio na hrpu mjesta da to spominju, ali uopƒáe ne mogu sku≈æit ≈°ta predstavlja",
      "votes": {
        "upvoters": [
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255803": {
      "poster": "sheriffHorsey",
      "content": "@\"Todd Chavez\"#p255791 \n\n![](assets/2021-11-20/00033.png)\n\nMislim da si samo pogrijesio u oznacavanju tocaka jer ja sam dobio ovakvu skicu u kojoj onda imas dvije hipoteze u version spaceu.",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255806": {
      "poster": "sheriffHorsey",
      "content": "@\"Todd Chavez\"#p255796 Nebi trebalo biti [imath] L(0, 1)> L(1, 0) [/imath]. U ovom zadatku treba skuzit da ti je bitnije imat sto manje false negativa jer ne zelis da tvoj klasifikator nekome ne otkrije karcinom, a zapravo ga ima. S druge strane nije ti toliko bitno ako nekom dijagnosticiras karcinom ako ga nema jer ce vjerojatno ic na neke dodatne pretrage da potvrdi to. Zbog toga zelis vise kaznjavati klasifikator ako napravi ovu prvu pogresku, a drugu manje i to upravo odgovara odnosima gubitka [imath] L(1, 0) > L(0, 1) [/imath].",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255807": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Jaster111\"#p255798 \n\nMislim da to mo≈æe≈° ƒçitat kao izuzev, osim.",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255808": {
      "poster": "[deleted]",
      "content": "@\"sheriffHorsey\"#p255806 to me i muƒçi, svjestan sam ja da je veƒái problem false negative, ali po ovoj matrici ne vidim kak je to ispravno rjesenje:\n\n![](assets/2021-11-20/00034.png)\n\nosim ako je svejedno kako oznacavamo retke/stupce pa zato ovo moje nije ni ponuƒëeno?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255810": {
      "poster": "sheriffHorsey",
      "content": "@\"Todd Chavez\"#p255808 Ako ti redak oznacava stvarnu situaciju onda redak 1 znaci da osoba ima karcinom, a recimo da klasifikator to ne skuzi pa je stupac 0, znaci da je to L(1, 0), tj. prvo indeksiras redak pa stupac.",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255811": {
      "poster": "[deleted]",
      "content": "@\"sheriffHorsey\"#p255810 aha, zanemario sam da su 0 i 1 oznake klase, ja sam to gledao samo kao indekse u tablici :D ty",
      "votes": {
        "upvoters": [
          "sheriffHorsey"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255840": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"tomekbeli420\"#p254646 \n\nJe li mo≈æe≈° molim te reƒái kaj toƒçno uvrsti≈° ovdje jer nemrem sku≈æit nikak\n\n(prebacivanje iz dualnog u primarni oblik)\n\n![](assets/2021-11-20/00036.png)\n\nZnaƒçi npr. kak si do≈°o do w1? ≈†to si toƒçno uvrstio, koje brojeve?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255847": {
      "poster": "Rene",
      "content": "Zna netko ova dva?\n\n![](assets/2021-11-20/00037.png)\n\n![](assets/2021-11-20/00038.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255863": {
      "poster": "viliml",
      "content": "@\"Jaster111\"#p255798 \"isto do na X\" opƒáenito znaƒçi da mijenjanjem X-a prelazi≈° iz jednog u drugo. Ovdje je jedan izraz jednak drugom pomno≈æenom s C.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255864": {
      "poster": "Fica (Prof)",
      "content": "@\"Rene\"#p255847 Ima≈° ovaj prvi detaljno obja≈°njen u snimci sa zadnje rekapitulacije na teamsima, uglavnom za ovu jezgru se izvede preslikavanje (x1^2, sqrt(2)*x1*x2, x2^2), a sa polinomom dobije≈° standardno (1, x1, x2, x1^2, x1x2, x2^2) i onda ovom prvom doda≈° samo 3 nule na poƒçetak jer tih ƒçlanova tamo nema≈° i onda ti je euklidska udaljenost zbroj kvadrata razlike za svaki od njih. Kad uvrsti≈° primjer dobije≈° za jezgreni (0,0,0,0,1,0), a za ovaj (1,1,0,0,1,0) i onda je to korijen iz 1^2 + 1^2 i to ti je rje≈°enje.",
      "votes": {
        "upvoters": [
          "Rene",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255865": {
      "poster": "viliml",
      "content": "@\"Ivanƒçica\"#p255840 \n\n[math]w_1 = \\sum_{i=1}^{N} \\alpha_i y^{(i)} x^{(i)}_1[/math]",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255873": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-20/00043.png)\n\nu d) podzadatku i generalno takvim tipovima zadataka, jel uvijek gledamo s dummy jedinicom? odnosno treba li nam u sluƒçaju bez preslikavanja 4 primjera? (3 znaƒçajke + dummy)\n\nili ako nije direktno nagla≈°eno da je preslikavanje (1, x) ignoriramo?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255874": {
      "poster": "viliml",
      "content": "@\"Rene\"#p255847 Za drugi zadatak, uvijek je moguƒáe barem teoretski izraƒçunati udaljenost\n\n[math]d(\\mathbf{x})=\\frac{h(\\mathbf{x})}{||\\mathbf{w}||}=\\frac{\\sum_i{\\alpha_i y^{(i)} \\kappa(\\mathbf{x},\\mathbf{x}^{(i)} )}+w_0}{\\sqrt{\\sum_i{\\sum_j{\\alpha_i \\alpha_j y^{(i)} y^{(j)} \\kappa(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)} )}}}}[/math]\n\nMo≈æda se referenciraju na to da je prostor znaƒçajki za Gaussovu jezgru neprebrojivo-beskonaƒçno-dimenzionalan pa sumiranje po dimenzijama i sliƒçne stvari nisu zapravo definirane, ali s konkretnom hipotezom ƒáe se sve dogaƒëati u konaƒçno- ili prebrojivo-beskonaƒçno-dimenzionalnom podprostoru gdje sve sume koje nam trebaju konvergiraju...",
      "votes": {
        "upvoters": [
          "Rene"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255888": {
      "poster": "prx_xD",
      "content": "@\"viliml\"#p254704 jel mo≈æe≈° objasniti kako K(x, z) = (xT*z  + 2)^3 rje≈°i≈°",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255912": {
      "poster": "viliml",
      "content": "@\"prx_xD\"#p255888 To je formula. Stavi≈° brojeve unutra i izaƒëu brojevi van.\n\nNa primjer [imath]\\kappa(\\mathbf{x}^{(3)}, \\mathbf{x})=17^3[/imath].\n\nMnoge vrijednosti ƒáe biti u milijunima ali zato su koeficijenti jako mali.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Bucc (Olive Oil)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "255948": {
      "poster": "[deleted]",
      "content": "> Pro≈°li tjedan bavili smo se regresijom te smo razmatrali linearan model regresije, koji ‚Äì uz odabir nelinearne funkcije preslikavanja ‚Äì zapravo postaje nelinearan model.\n\n\n> Ovaj model sada ima linearnu granicu u prostoru znaƒçajki, ali nelinarnu granicu u ulaznom prostoru. Tehniƒçki gledano to je i dalje linearan model, jer je linearan u parametrima.\n\n≈°ta je od ovog onda na kraju, jel se model smatra linearnim ili ne lol",
      "votes": {
        "upvoters": [
          "MsBrightside",
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255964": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p255948 Pa... I dalje je to linearan model jer on u prostoru znaƒçajki stvara linearnu granicu. Nelinearnost nastaje prilikom preslikavanja u prostor znaƒçajki, a to nije unutar \"okvira djelovanja\" modela. Bar si ja tako tumaƒçim...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255968": {
      "poster": "[deleted]",
      "content": "@\"Precious Bodily Fluids\"#p255964 da, kuzim, zato me i muƒçi ovaj \"postaje nelinearan model\" dio",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255973": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p255968 poanta je valjda da ako gleda≈° to kao crnu kutiju zakljuƒçit ƒáe≈° da je nelinearan model, al zapravo se radi o preslikavanju koje se feeda u obiƒçan linearan model. Tako da su vjerojatno oba pogleda toƒçna, samo treba biti svjestan konteksta.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "255985": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-21/00007.png)\n\njel nije poanta doslovno bila da ako promijenimo funkciju gubitka da to vi≈°e nije linearna regresija? \n\ntakoƒëer, jel promjena aktivacijske funkcije ne spada u promjenu modela?",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256002": {
      "poster": "kix7 (Fish99)",
      "content": "@\"Todd Chavez\"#p255985 Mislim da oce rec da nas je najvise mucio onaj kvadratni gubitak i da je dovoljno da njega promijenimo da ce funkcionirat linearna regresija a uz to dolazi i promjena optimizacijskog postupka.\n\nAl da, lakse je opravdat odgovor kad znas vec rjesenje...",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256008": {
      "poster": "tomekbeli420",
      "content": "@\"Ivanƒçica\"#p255840 e sry tek sad vidio\n\nvektorsko zbrajanje, dakle [imath]\\alpha_i[/imath] i [imath]y^{(i)}[/imath] su skalari, a [imath]\\mathbf{x}^{(i)}[/imath] su vektori\n\n[math]\\mathbf{w} = \\alpha_1 y^{(1)} \\mathbf{x}^{(1)} + \\alpha_2 y^{(2)} \\mathbf{x}^{(2)} + \\alpha_3 y^{(3)} \\mathbf{x}^{(3)} \\\\\n\\mathbf{w} = 0 \\cdot (-1) (-1, 3, 6) + 0.01 \\cdot (-1) (-4, 4, 4) + 0.01 \\cdot 1 (-2, 4, 1) \\\\\n\\mathbf{w} = (0, 0, 0) + (0.04, -0.04, -0.04) + (-0.02, 0.04, 0.01) = (0.02, 0, -0.03)[/math]\n\nI onda kako je [imath]\\mathbf{w} = \\left(w_1, w_2, w_3\\right)[/imath] odavdje i≈°ƒçita≈° sve ≈°ta te zanima",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256012": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p255985 mo≈æda je gre≈°ka? Valjda se implicira da se nabroje promjene koje iz lin. reg. daju perceptron, a meƒëu njima je dodavanje aktivacijske funkcije u model, ƒçime se on mijenja.",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256040": {
      "poster": "viliml",
      "content": "@\"Todd Chavez\"#p255985 @\"Precious Bodily Fluids\"#p256012 Kad se linearna regresija koristi za klasifikaciju, odmah veƒá mora imati aktivacijsku funkciju. U skripti se koristi funkcija [imath]\\mathbf{1}\\{\\alpha\\ge0.5\\}[/imath], ali to je ekvivalentno step funkciji do na promjenu w0 i preimenovanje izlaznih klasa iz 0/1 u =+-1 (@\"Jaster111\"#p255798 ) znaƒçi algoritam ekvivalentan perceptronu se mo≈æe dobiti bez promjene aktivacijske funkcije.",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256052": {
      "poster": "Zuzu (Coffe123)",
      "content": "@\"viliml\"#p254704 mo≈æe≈° reƒá molim te kako dobije≈° vrijednosti za ostale vektore, znaƒçi -1.97711, -1.92673 i 0.05117..nikako ne mogu dobiti te vrijednosti formulama pa ne≈°to vjv krivo radim",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256057": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"tomekbeli420\"#p254646 \n\nhvala na odgovoru, sam mi jo≈° jedna stvar nije ba≈° jasna, kako si dobio ove brojeve (zaokru≈æeno plavom)\n\n![](assets/2021-11-21/00021.png)\n\nnemrem sku≈æit kaj si s ƒçim pomno≈æio, ≈°to god poku≈°am gledajuƒái ovu formulu ne dobim te brojeve",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256059": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "Jel zna netko ovo objasniti? Iz zadataka logistiƒçke regresije I\n> mo≈æemo li reƒái da je logistiƒçki gubitak konveksni surogat gubitka 0-1, i ≈°to to znaƒçi?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256064": {
      "poster": "zara",
      "content": "![](assets/2021-11-21/00024.png)\n\nJel zna netko?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256070": {
      "poster": "zastozato (studo≈°)",
      "content": "jel ima netko rjesen 2. iz  Jezgrenih metoda zadatci za uƒçenje",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256071": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"zara\"#p256064 \n\nIz poznate vrijednosti fje gubitka i proizvoljne oznake y mo≈æe≈° izraƒçunati izlaz modela h(x), nakon toga pomoƒáu izraƒçunatog h(x) i suprotne vrijednosti y izraƒçuna≈° gubitak.\n\n![](assets/2021-11-21/00025.jpg)",
      "votes": {
        "upvoters": [
          "Kasperinac",
          "Ollie",
          "zara"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256072": {
      "poster": "viliml",
      "content": "@\"Precious Bodily Fluids\"#p256059 To je jedan termin koje je definiran tek kasnije, vjerojatno su ga gre≈°kom stavili u tu vje≈æbu.\n\n![](assets/2021-11-21/00026.png)",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256075": {
      "poster": "viliml",
      "content": "@\"zara\"#p256064 Zamjena oznake znaƒçi invertiranje vjerojatnosti, pa se u gubitku zamjeni -log(p) sa -log(1-p). Dakle rje≈°enje je -log(1-exp(-L)).",
      "votes": {
        "upvoters": [
          "zara"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256081": {
      "poster": "viliml",
      "content": "@\"Ivanƒçica\"#p256057\n\n[imath]h \\left(\\mathbf{x}\\right) = \\mathbf{w}^{\\mathrm{T}} \\mathbf{x} + w_0[/imath]\n\nVrijednosti [imath]\\mathbf{w} [/imath] i [imath] w_0[/imath] su pokazane izraƒçunate gore u njegovom odgovoru, a primjeri [imath]\\mathbf{x}[/imath] su zadani u zadatku.",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256088": {
      "poster": "tomekbeli420",
      "content": "@\"Ivanƒçica\"#p256057 to su izlazi modela\n\nA s obzirom da smo na≈°li te≈æine [imath]\\mathbf{w} = (0.02, 0, -0.03)[/imath], i u zadatku nam je dan [imath]w_0 = -0.8[/imath], onda hipotezu mo≈æemo raƒçunati sa primarnom formulacijom modela, koji je obiƒçan linearan model\n\n[math]h \\left(\\mathbf{x}\\right) = \\mathbf{w}^{\\mathrm{T}} \\mathbf{x} + w_0[/math]\n\ntako npr za primjer [imath] \\left(\\mathbf{x}^{(3)}, y^{(3)}\\right) = \\left((-2, 4, 1) , +1\\right)[/imath] izlaz modela je\n\n[math]h \\left(\\mathbf{x}^{(3)}\\right) = (0.02, 0, -0.03) \\cdot (-2, 4, 1) - 0.8 = -0.87[/math]",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)",
          "matt (Matt)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256106": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"viliml\"#p256081 \n\n@\"tomekbeli420\"#p256088 \n\nhvala puno, sad ku≈æim",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256108": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-21/00032.png)\n\nmoze netko objasniti ovaj?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256112": {
      "poster": "zara",
      "content": "![](assets/2021-11-21/00034.png)\n\n Jel ima netko postupak i za ovo dvoje plizü•∫",
      "votes": {
        "upvoters": [
          "Ardura (Maddy)",
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256113": {
      "poster": "Arya",
      "content": "![](assets/2021-11-21/00035.png)\n\nZna netko ovaj? Zasto najmanja greska nije 0, a najveca 5/6 (po formuli za empirijsku gresku, N=6 i racunamo da je sve krivo klasificirano 0.5+0.5+1+1+1+1) ?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256115": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p256108 objasnio je papa na predavanju, mo≈æe≈° pogledati na teamsu, predavanje 11.3.2021, pred kraj negdje.\n\nTLDR: aktivacijska funkcija ne utjece na linearnost granice, ono ≈°to treba zadovoljiti je da je preslikavanje obavljeno linearno, a to je sluƒçaj za phi(x) = (1, x)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256116": {
      "poster": "[deleted]",
      "content": "@\"Arya\"#p256113 ako nacrtas vidjet ces da nisu linearno odvojivi tako da ces uvijek imati barem jedan krivo klasificirani, i uzme≈° da je ovaj tip koji iznosi 0.5.\n\na za maksimalnu pogre≈°ku: uvijek ƒáe≈° s neke strane ravnine imati barem jedan toƒçan primjer",
      "votes": {
        "upvoters": [
          "Arya",
          "Ducky",
          "MsBrightside"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256117": {
      "poster": "Fica (Prof)",
      "content": "@\"Arya\"#p256113 Takve zadatke si mora≈° skicirati na kocki i onda dobije≈° da su ti svi ovi pozitivni na 4 dijagonalna vrha, a negativni su na suprotnim stranama pa ih najbolje mo≈æe≈° odvojiti tako da ti se jedan negativni klasificira la≈æno pozitivno i onda je to 0.5/6, a max ƒáe ti biti kad je obrnuto i onda ƒáe≈° imati 4 la≈æno negativna i 1 la≈æno pozitivan pa dobije≈° 4.5/6",
      "votes": {
        "upvoters": [
          "Arya",
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256120": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-21/00036.png)\n\njel se moze ovo rijesit bez da s onog grafa usporedbe pogadas tocnu decimalnu vrijednost",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [
          "netko_tamo",
          "viliml"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "256122": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p256120 \n\n10-ak poruka iznad je postupak, evo\n\n@\"Precious Bodily Fluids\"#p256071",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256125": {
      "poster": "viliml",
      "content": "@\"Todd Chavez\"#p256108 proƒçitaj dretvu @\"viliml\"#p255782",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256130": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "![](assets/2021-11-21/00038.png)\n\nKada pi≈°e da se znaƒçajke mno≈æe sa dva, pretpostavljam da se mno≈æe sve znaƒçajke osim dummy znaƒçajke?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256134": {
      "poster": "[deleted]",
      "content": "@\"Precious Bodily Fluids\"#p256130 da, w0 tretira≈° posebno",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256184": {
      "poster": "Ardura (Maddy)",
      "content": "@\"zara\"#p256112  U auditornim od logreg2 od 1:20 Snajder detaljno rj predzadnji, zadnji je nakon toga nacrtao, ali nije rekao tocan odg (njemu je bilo zacrnjeno 49 kao tocno, a nama je 45, vjv je greska).",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256185": {
      "poster": "gad_gadski",
      "content": "![](assets/2021-11-21/00043.png)\n\n Netko ima postupak?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256187": {
      "poster": "pvmnt (ostaje.mi.to.sto.se.volimo)",
      "content": "![](assets/2021-11-21/00044.png)\n\nJel zna itko ovaj?\n\nJa bi rekao da je rjesenje: najgori slucaj za OVO je kad se usporeduju 2 klase po 400. Buduci da pohranjujemo pola matrice bez dijagonale to je ukupno (400 puta 400 - 400)/2\n\nOVR uvijek ukljucuje sve elemente: dakle to je (1000 puta 1000 - 1000)/2 pohranjenih elemenata\n\nprvi broj / drugi broj je tocno 4 puta manji od pravog rjesenja... di grijesim?",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256189": {
      "poster": "steker",
      "content": "![](assets/2021-11-21/00045.jpg)\n\nKako se ovo dobije",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256195": {
      "poster": "Fica (Prof)",
      "content": "@\"legend649\"#p256187 Za OVO si uzeo samo jednu klasu, a trebalo bi usporediti dvije najveƒáe pa dobije≈° 800 primjera, a ne 400. I inaƒçe jedan tip za sve, veliku veƒáinu tih zadataka sa ispita imate rije≈°enih na teamsima na videu od tjedna gdje se to radilo ili na rekapitulaciji.",
      "votes": {
        "upvoters": [
          "Sulejman",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256196": {
      "poster": "steker",
      "content": "@\"legend649\"#p256187 jel nebi za ovo trebala 800x800 matica da bi bila simetricna",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256199": {
      "poster": "pvmnt (ostaje.mi.to.sto.se.volimo)",
      "content": "@\"steker\"#p256196 bravo. sjeban sam, od jutros sam za laptopom. hvala",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256203": {
      "poster": "prx_xD",
      "content": "![](assets/2021-11-21/00047.png)\n\nMo≈æe netko dat postupak za ovaj zadatak nije mi jasno kak ga rijesit\n\nTocan odg je pod B",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256210": {
      "poster": "steker",
      "content": "@\"prx_xD\"#p256203 ![](assets/2021-11-21/00048.jpg)\n\nValjda je to to",
      "votes": {
        "upvoters": [
          "JogaBonito",
          "Smolaa",
          "cloudies",
          "pingvinka",
          "prx_xD"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Bananaking"
        ]
      }
    },
    "256212": {
      "poster": "prx_xD",
      "content": "@\"steker\"#p256210 hvala",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256214": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"steker\"#p256210 odvratan zadatak lol",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)",
          "Bananaking",
          "cloudies",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "steker"
        ]
      }
    },
    "256215": {
      "poster": "bodNaUvidima",
      "content": "@\"gad_gadski\"#p256185 predavanje na teamsu iz te lekcije ≈†najder rje≈°i isti zadatak samo druge brojke.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256220": {
      "poster": "steker",
      "content": "moze neko pametan mi malo pojasnit zasto se minimizira druga norma od W za rjesenje maksimalne margine, tj. Zasto se potporni vektori udaljavju vise od hiperravnine sto je W manji. Nikako mi to ne ide u glavu ba≈°",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256226": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"steker\"#p256220 dosta je dense izvod, probaj shvatit svaki korak pojedinaƒçno.\n\nKeypointovi za razumjet su (SVM 1, poglavlje 1.1):\n- definicija udaljenosti primjera od hiperravnine\n- izraz za maksimalnu marginu (minimizacija unutar argmax-a),\n- uvoƒëenje pretpostavke da je udaljenost potpornih vektora od klasifikacijske granice jednaka 1,\n- ƒçinjenica argmax(1 / |\\|w|\\|)  ekvivalentna argmin ||w|\\|.",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256253": {
      "poster": "viliml",
      "content": "@\"prx_xD\"#p256203 @\"steker\"#p256210 @\"Precious Bodily Fluids\"#p256214\n\nNije toliko ru≈æno ako zgura≈° sve detalje linearno algebarskih raƒçuna pod tepih. Na primjer vrijednosti hipoteze za sve primjere mo≈æe≈° odmah izraƒçunati trikom da da≈° jezgri za argument matricu umjesto vektora, i sve one sume s alfama i ipsilonima se isto mogu prikazati kao matriƒçno mno≈æenje.\n\nOvo je isti zadatak s drugaƒçijim krajnjim primjerom x:\n\n![](assets/2021-11-21/00054.png)",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256281": {
      "poster": "AK10 (endyyyy)",
      "content": "![](assets/2021-11-22/00000.png)\n\nkako?",
      "votes": {
        "upvoters": [
          "Arya",
          "nnn (dinoo)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256287": {
      "poster": "Dootz",
      "content": "![](assets/2021-11-22/00001.png)\n\nMo≈æe li netko objasniti ovo?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256296": {
      "poster": "123 (FERella)",
      "content": "Zna li netko za≈°to ovdje ne bi mogao bit odgovor pod D?\n\n![](assets/2021-11-22/00002.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256308": {
      "poster": "Rene",
      "content": "@\"FERella\"#p256296 jer ne znamo kako regularizacija utjece na model, mozda je s tolikim faktorom model jos jednostavniji od H2,0",
      "votes": {
        "upvoters": [
          "123 (FERella)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256309": {
      "poster": "nnn (dinoo)",
      "content": "@\"FERella\"#p256296 Neka me netko ispravi ali sjeƒáam se da sam priƒçao sa asistenticom i stvar je da ne mo≈æe≈° ni≈°ta reƒái o generalizaciji hipoteza, i ovaj drugi dio \"imat ƒáe manju pogre≈°ku na skupu za uƒçenje\" ne mora nu≈æno bit toƒçno. Mo≈æda je lambda=100 prevelik faktor i gre≈°ka je puno veƒáa",
      "votes": {
        "upvoters": [
          "123 (FERella)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256315": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"endyyyy\"#p256281 \n\nIz fje gubitka izraƒçuna≈° h(x). Pomoƒáu h(x) i w0 izrazi≈° w^T x, zatim ga pomno≈æi s 2 i na kraju novi h(x) = 2w^T x + w0 i obrnutu oznaku ubacuje≈° nazad u funkciju gubitka i to je rje≈°enje.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256317": {
      "poster": "AK10 (endyyyy)",
      "content": "@\"Precious Bodily Fluids\"#p256315 to radim ali iz nekog razloga mi ne ispada dobro, ako mozes uslikat postupak bila bih jako zahvalnaa",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256345": {
      "poster": "tomekbeli420",
      "content": "@\"Dootz\"#p256287 Da bi raƒçunao udaljenost od hiperravnine u prostoru znaƒçajki trebaju ti te≈æine i preslikani primjeri. Funkcija preslikavanja je implicitno poznata iz kori≈°tene jezgre (kako se radi o algoritmu SVM onda mo≈æemo biti sigurni da je jezgra Mercerova), pa onda iz Lagrangeovih multiplikatora [imath]\\alpha_i[/imath] i preslikanih ulaznih primjera se lako dobiju te≈æine [imath]\\mathbf{w}[/imath]. Dakle to je sve moguƒáe, jedino problem sa Gaussovom jezgrom ili slo≈æenijim koje koriste Gaussovu jezgru kao gradivni blok jest taj da je preslikavanje beskonaƒçno dimenzijsko, pa je to valjda (nisam ni ja siguran lmao) razlog za≈°to se ne mo≈æe sa Gaussovom jezgrom.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256347": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-22/00006.png)\n\nmoze netko objasnit zasto je ovo C, a ne npr D",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256350": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Todd Chavez\"#p256347 \n\nD nije tocan jer se pozicija hiperravnine ne mijenja porastom vektora w, isto vrijedi i za udaljenost primjera od hipperavnine, mnozenje vektora skalarom ne utjece na udaljenost.\n\nOno ≈°to se mjenja je izlaz modela, h(x) i on raste proporcionalno porastom w.",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256375": {
      "poster": "BillIK",
      "content": "![](assets/2021-11-22/00007.png)\n\nBi li u ovome zadatku iskljuƒçili x4 jer je u zavisnosti s x3 (ako dobro razmisljam)? \n\nKoliko bi bilo rje≈°enje jer zbunjuje me ovo s parovima i trojkama kvadrata. Uzimamo li u obzir da npr. za par imamo mogucnost birati dva elementa od 6 mogucih ili od 12?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256381": {
      "poster": "angello2",
      "content": "@\"BillIK\"#p256375 to su dva odvojena racuna, nisu u ovisnosti\n\nreko bi da je x7 suvisan jer ga mozes izracunat iz ostalih podataka - imas ukupan iznos kredita i imas iznos otplacenih, ne treba ti podatak koliko je preostalih. istom logikom se moze maknut bilo koji od x5, x6, x7 - dovoljna su dva od ta tri.",
      "votes": {
        "upvoters": [
          "BillIK",
          "MsBrightside"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256384": {
      "poster": "viliml",
      "content": "@\"tomekbeli420\"#p256345 Nije strogo nu≈æno eksplicitno izraƒçunati te≈æine niti koristiti funkciju preslikavanja po≈°to se sve mo≈æe prikazati preko unutarnjih produkata/jezgri, vidi @\"viliml\"#p255874 \n\nJedino je mo≈æda problem da ta formula vrijedi *ako udaljenost postoji*, mo≈æda se mo≈æe reƒái da udaljenost ne postoji pa ta formula iako daje neki broj nije ba≈° rigorozno toƒçno zvati \"udaljenost\"?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256409": {
      "poster": "gad_gadski",
      "content": "@\"endyyyy\"#p256317 ![](assets/2021-11-22/00010.jpg)\n\nPretpostavljam da nisi stavila izraz -(w*x + w0) u potenciju kod formule za h(x), vec samo -w*x",
      "votes": {
        "upvoters": [
          "AK10 (endyyyy)",
          "Jale (ƒçakijale)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256421": {
      "poster": "matt (Matt)",
      "content": "V07 4. Zadatak: Svi poopcÃÅeni linearni modeli mogu se trenirati u ‚Äúonline‚Äù (pojedinacÃånom) nacÃåinu, primjernom\n\nalgoritma LMS. To vrijedi i za algoritam linearne regresije, za koji smo prvotno kao minimizaciju\n\nkvadrata provodili racÃåunajucÃÅi pseudoinverz matrice dizajna. Jedna od prednosti algoritma LMS\n\nu odnosu na izracÃåun pseudoinverza kod linearne regresije je manja racÃåunalna slozÃåenost LMS-a.\n\nNeka E oznacÃåava broj epoha, N je broj primjera, a m broj znacÃåajki u prostoru znacÃåajki. Koja je\n\n(vremenska) racÃåunalna slozÃåenost algoritma LMS, primijenjenog na linearnu regresiju?\n\n![](assets/2021-11-22/00011.png)\n\nIz predavanja:\n\n![](assets/2021-11-22/00012.png)\n\nNije mi jasno za≈°to se pojavljuje izraz [imath]m[/imath], tj. koja operacija uzrokuje tu kompleksnost?\n\nJe li to operacija preslikavanja [imath]\\phi(x)[/imath] ili izraƒçun skalarnih produkta unutar izraza za a≈æuriranje te≈æine [imath]w[/imath]?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256432": {
      "poster": "RickyMorty",
      "content": "![](assets/2021-11-22/00013.jpg)\n\nKak se ovo toƒçno radi, tojest nije mi jasno odkud mi po dvije te≈æine za x1 itd...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256445": {
      "poster": "Antuunn",
      "content": "@\"zara\"#p256112 Jel pronadeno rjesenje za ova dva zadatka?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256447": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"RickyMorty\"#p256432 Ovaj zadatak je detaljno obja≈°njen na teams predavanjima.",
      "votes": {
        "upvoters": [
          "RickyMorty",
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256452": {
      "poster": "gad_gadski",
      "content": "![](assets/2021-11-22/00018.png)\n\nOvo je mi s materijala na studosima, u rj pise da je A tocno, jel to krivo ili? Ja nevidim kako nije C",
      "votes": {
        "upvoters": [
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256457": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"gad_gadski\"#p256452 \n\nGrafiƒçki se lagano rijesi\n\n![](assets/2021-11-22/00020.jpg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256458": {
      "poster": "jobi (azex)",
      "content": "@\"BillIK\"#p256375 \n\n@\"angello2\"#p256381 \n\nmozete li napisat postupak pls, ne kuzim nikako kako doc do rjesenja",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256463": {
      "poster": "bodNaUvidima",
      "content": "@\"tomekbeli420\"#p254646 Je si li uspio ovdje doci do njihovog rjesenja? Takoder mi h(x) ispada 1.06 x [imath]10^{-3}[/imath] + w0, a w0 mi ispada 0.999999 po njihovoj formuli.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256475": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"bodNaUvidima\"#p256463 rje≈°io ga je ≈†najder na predavanju",
      "votes": {
        "upvoters": [
          "bodNaUvidima"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256476": {
      "poster": "steker",
      "content": "![](assets/2021-11-22/00023.jpg)\n\nKako se ovo rjesava",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256477": {
      "poster": "[deleted]",
      "content": "@\"steker\"#p256476 znaƒçajke == klasifikatori, i onda kad napravis K, odnosno K povrh 2 vidi≈° da OVO ima duplo, a OVR lo≈°ije radi na \"znanost\" kategoriji jer je osjetljiv na class imbalance, odnosno ima jako malo primjera pa ih \"trpa\" u veƒáinsku klasu i tako grije≈°i",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "steker"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256479": {
      "poster": "steker",
      "content": "@\"Todd Chavez\"#p256477 aha zbunjivalo me taj dio sa znacajkama",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256487": {
      "poster": "batman3000",
      "content": "E zna netko?\n\n![](assets/2021-11-22/00024.png)",
      "votes": {
        "upvoters": [
          "ZliDule"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256491": {
      "poster": "viliml",
      "content": "@\"matt\"#p256421 Za svaku epohu, za svaki primjer, svaka te≈æina se mora a≈æurirati.\n\nOvo u tvojoj drugoj slici je vektorska jednad≈æba koja je skraƒáeni prikaz za [imath]m[/imath] zasebnih operacija.",
      "votes": {
        "upvoters": [
          "matt (Matt)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256494": {
      "poster": "viliml",
      "content": "@\"bodNaUvidima\"#p256463 [imath]h(\\mathbf x)[/imath] ti je toƒçan, kako raƒçuna≈° w0 da ti ispadne krivo? Trebao bi takav da je [imath]h(\\mathbf x^{(i)})=y^{(i)}[/imath]. ≈†to dobije≈° za [imath]h(\\mathbf x^{(i)})[/imath]?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256523": {
      "poster": "bodNaUvidima",
      "content": "@\"viliml\"#p256494 w0 poku≈°avam izraƒçunati preko ove formule iz P08 pdfa\n\n![](assets/2021-11-22/00029.png)\n\nAko uzmem 3. potporni vektor sa oznakom y=+1, uvrstim u tu formulu dobijem w0 = 0.999998026, svakako predaleko od 0.95.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256526": {
      "poster": "bodNaUvidima",
      "content": "@\"bodNaUvidima\"#p256523 Da odgovorim sam sebi, imao sam brain fart i nisam koristio kernel funkciju nego samo mnozio dva vektora.",
      "votes": {
        "upvoters": [
          "Me1 (Me)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256528": {
      "poster": "ppooww (pp)",
      "content": "![](assets/2021-11-22/00031.png)\n\nJel ovo znaci da mozemo 2 pitanja krivo zaokruzit bez negativnih? Ili tocni odgovori nose 35/20 bodova, a krivi odgovori -1/3 * 35/20 ?",
      "votes": {
        "upvoters": [
          "ZliDule",
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256535": {
      "poster": "Reznox",
      "content": "![](assets/2021-11-22/00032.png)\n\nIma ko postupak?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256545": {
      "poster": "boogie_woogie (nika_1999)",
      "content": "@\"Reznox\"#p256535 \n\n![](assets/2021-11-22/00033.jpg)",
      "votes": {
        "upvoters": [
          "Reznox"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256547": {
      "poster": "boogie_woogie (nika_1999)",
      "content": "Zna netko ovaj?\n\n![](assets/2021-11-22/00034.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256558": {
      "poster": "Sulejman",
      "content": "@\"pp\"#p256528 Rekao bih da dobije≈° negativne ako krivo odgovori≈°, sumnjam da bi ti dopustili da dvaput besplatno pogaƒëa≈°. Ali da, ak odgovori≈° na 21 pitanje toƒçno onda mo≈æe≈° fulat jedno üòÖ",
      "votes": {
        "upvoters": [
          "ppooww (pp)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256559": {
      "poster": "angello2",
      "content": "![](assets/2021-11-22/00036.png)\n\n![](assets/2021-11-22/00037.png)\n\n![](assets/2021-11-22/00038.png)\n\nmoze neki savjet oko ovakvih zadataka di se trazi broj parametara? krenem ja tu nesto brojat i dobijem neki broj al nikad ne dobim tocno rjesenje tak da mi ocito nesto fali",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256572": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"angello2\"#p256559 zadnji je rje≈°io Mediƒá, na identiƒçan naƒçin se rje≈°i i prvi. drugi je rje≈°io tatica, isto na predavanju.\n\nUostalom, veƒáina zadataka je rje≈°ena na predavanjima, a ona su sva su dostupna u repozitoriju na teamsu.",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)",
          "viliml"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256578": {
      "poster": "zastozato (studo≈°)",
      "content": "![](assets/2021-11-22/00041.png)\n\novaj? za≈°to?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256579": {
      "poster": "zastozato (studo≈°)",
      "content": "@\"studo≈°\"#p256578 toƒçan odg je C",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "Kaiser"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256583": {
      "poster": "steker",
      "content": "@\"studo≈°\"#p256578 ja sam to shvatila ovako: model ima 6 svojih wj tezina. Imamo 5 fi j parametriziranih baznih funkcija gdje svaka ima n+1 tezina tj svaka ima 101 tezinu, jos dodatno imamo i tu fi 0 baznu funkciju koju na predavanju nismo parametrizirali pa onda imamo: 5*101 tezina baznih funkcija + 6 tezina modela= 511. Valjda...",
      "votes": {
        "upvoters": [
          "sheriffHorsey",
          "zastozato (studo≈°)"
        ],
        "downvoters": [
          "matt (Matt)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256592": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"steker\"#p256583 Znaƒçi imamo 5 baznih funkcija koje preslikavaju na naƒçin da implementiraju logistiƒçku regresiju, dakle svaka 100 + 1 parametara? A ≈°to toƒçno predstavlja [imath]\\phi_0[/imath]? Jel to simulira dummy znaƒçajku, as in [imath]\\phi(x) = 1[/imath], pa nema parametara? Ima smisla, al ne vidim tu pretpostavku nigdje u skripti predavanja tho...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256596": {
      "poster": "viliml",
      "content": "@\"angello2\"#p256559 vidi @\"Rene\"#p255723",
      "votes": {
        "upvoters": [
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256597": {
      "poster": "steker",
      "content": "@\"Precious Bodily Fluids\"#p256592 nez ja znam da je snajder reko kad je rjesavo slican zadatak da je to dogovorno jednako 1. Ali ocito bi trebalo simulirat nesto valjda kao prag u neuronskoj mrezi lmao",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256641": {
      "poster": "InCogNiTo124",
      "content": "@\"Precious Bodily Fluids\"#p256592 phi_0 je po dogovoru uvijek 1 to se sjecam da je nama govorio",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256652": {
      "poster": "zastozato (studo≈°)",
      "content": "![](assets/2021-11-22/00052.png)\n\na ovaj? odg je a",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256654": {
      "poster": "steker",
      "content": "@\"studo≈°\"#p256652 valjda jer je sum malen mozes rec da je y= -1+2x\n\nZa optimizacijski postupak znas da zelis minimizirat (y+2h(x))^2 pa izjednacis sa 0 valjda\n\nKorjenujes tu jednadzbu i dobijes 2h(x)=-y\n\n2h(x)=-(-1+2x)\n\nh(x)=1/2 -1x",
      "votes": {
        "upvoters": [
          "Tone"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256657": {
      "poster": "gladiator",
      "content": "@\"Precious Bodily Fluids\"#p256592 phi_0 je 1, to je jasno kao dan, ali upitan je w0. Zato taj 101. parametar",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256658": {
      "poster": "Arya",
      "content": "![](assets/2021-11-23/00000.png)\n\nKako se racuna klasifikacija za 3-NN?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256670": {
      "poster": "tomekbeli420",
      "content": "@\"steker\"#p256654 oof, ne znam je li to legitimno obja≈°njenje lmao al ispada dobro\n\nanyways\n\n@\"studo≈°\"#p256652 \n\nznaƒçi ako gleda≈° taj krivi gubitak i malo ga prepravi≈°\n\n[math]L \\left(y, h \\left(\\mathbf{x}\\right) \\right) = \\left(y + 2 h\\left(\\mathbf{x}\\right)\\right)^2 = 4\\left(\\frac{y}{2} +  h\\left(\\mathbf{x}\\right)\\right)^2 = 4 \\left(- \\left(-\\frac{y}{2}\\right) + h\\left(\\mathbf{x}\\right)\\right)^2 = 4 \\left( h\\left(\\mathbf{x}\\right) - \\left(-\\frac{y}{2}\\right)\\right)^2[/math]\n\nprimijeƒáujemo da kada bi svaka oznaka [imath]y[/imath] bila pretvorena u [imath]-\\frac{y}{2}[/imath] da bi onda takva \"kriva\" funkcija odgovarala funkciji kvadratnog gubitka i onda bi takav prema metodi najmanjih kvadrata vratio oƒçekivane parametre. Ovaj faktor 4 nije bitan zbog optimizacijskog postupka.\n\nZakljuƒçak: ako uzmemo podatke, transformiramo svaki tako da [imath]\\mathbf{x}[/imath] ostane kakav je, ali [imath]y[/imath] promijenimo u [imath]-\\frac{y}{2}[/imath], onda je implementirana funkcija kvadratni gubitak i onda ƒáe nauƒçiti parametre za generiranje transformiranih podataka.\n\nDakle samo se oznaka mijenja, kako je originalno bilo da su [imath]y[/imath] uzorkovane iz [imath]\\mathcal{N} \\left(-1 + 2x, \\sigma^2\\right)[/imath], onda skaliranjem se samo mijenja oƒçekivanje, prema tome [imath]-\\frac{y}{2}[/imath] onda dolazi iz distribucije [imath]\\mathcal{N} \\left(\\frac{1}{2} - x, \\sigma^2\\right)[/imath]\n\nI iz toga je vidljivo da ƒáemo onda dobiti te≈æine [imath] \\left(w_0, w_1\\right) = \\left(\\frac{1}{2}, -1\\right) [/imath]",
      "votes": {
        "upvoters": [
          "Jale (ƒçakijale)",
          "Rene",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "funky_funghi",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256682": {
      "poster": "Rene",
      "content": "@\"tomekbeli420\"#p256670 drugi naƒçin, vi≈°e raƒçunski a manje kreativan, je da napisete funkciju pogre≈°ke [imath]E(w|D)=(2X\\vec{w}+\\vec{y})^T(2X\\vec{w}+\\vec{y}) [/imath] i izvedete rjesenje najmanjih kvadrata gdje cete dobit [imath] \\vec{w}' = \\frac{-1}{2}w [/imath] pa isti zakljucak kao kolega",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Unity (Sgt. Forge)",
          "kix7 (Fish99)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "256684": {
      "poster": "viliml",
      "content": "@\"tomekbeli420\"#p256670 @\"Rene\"#p256682 Isusek mileni koji je ovo autizam.\n\nTreba se rije≈°iti zadatak, ne napisati znanstveni rad pobogu.\n\nVidi≈° da algoritam ima gubitak [imath](y-g(\\mathbf x))^2[/imath] gdje je [imath]g(\\mathbf x)=-2h(\\mathbf x)[/imath]. [imath]g(\\mathbf x)[/imath] ƒáe konvergirati na [imath]-1+2x[/imath] jer je to ispravna linearna regresija, pa se onda vidi [imath]h(\\mathbf x) = -\\frac{1}{2}g(\\mathbf x)=\\frac{1}{2}-x[/imath] i gotov si.",
      "votes": {
        "upvoters": [
          "Unity (Sgt. Forge)",
          "cajaznun"
        ],
        "downvoters": [
          "Diego"
        ]
      },
      "reactions": {
        "haha": [
          "Fica (Prof)",
          "Lyras",
          "Rene",
          "Sulejman",
          "Unity (Sgt. Forge)",
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "kix7 (Fish99)",
          "member",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "256693": {
      "poster": "tomekbeli420",
      "content": "@\"viliml\"#p256684 doslovno si istu stvar napravio, a ja sam onda autist lmao",
      "votes": {
        "upvoters": [
          "JustinCase"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Ducky",
          "Fica (Prof)",
          "Lyras",
          "Rene",
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "matt (Matt)",
          "member",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "256745": {
      "poster": "Rene",
      "content": "Jel iko uspio onaj s kreditima potrosio sam 15 minuta i nikako dobit\n\nMoja logika je 6 nezavisnih varijabli\n\n6 linearnih + 6 kvadrata + 4 kombinacije za svaku od 15 dvojki + 8 kombinacija za svaku od 20 trojki",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256748": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Rene\"#p256745 dvije su multikolinearne barem, starost<- >prihodi i neplaceni-placeni krediti, al idk nisam uspio rjesit",
      "votes": {
        "upvoters": [
          "Rene"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256751": {
      "poster": "Rene",
      "content": "@\"Precious Bodily Fluids\"#p256748 isprobao sam i za 5 i za 4 nezavisne i svejedno nisam dobia nista od ponudenog, tako da mislim da je greska u prebrojavanju\n\nCak sam probao i izbacit dvojke i trojke di su sve kvadratne opet nista",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256752": {
      "poster": "angello2",
      "content": "@\"Rene\"#p256745 ja sam nekak zakljucio da je 5 varijabli, s obzirom da za 6 varijabli ispadnu puno puno veci rezultati od ponudenog, pa je valjda x2 suvisan jer kao iz stanja racuna mozes dobit prinose na racun (ne bas al aj...) \n\nnaravno problem je bio da cak i za 5 varijabli dobim 130 znacajki a najvise ponudeno je bilo 92\n\nza 4 varijable sam dobio 64 sta isto nije ponudeno\n\nsve u svemu wtf",
      "votes": {
        "upvoters": [
          "PaleAle",
          "Rene",
          "[deleted]",
          "cajaznun",
          "miss_anthropocene (neunist.iva)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256763": {
      "poster": "Rene",
      "content": "@\"angello2\"#p256752 evo ako nesto masno ne grijesim, isprobao sam programski sve moguce kombinacije (broj nezavisnih varijabli, broj dvojki koji se uzima u obzir za neke dvije znacajke, broj trojki koji se uzima u obzir za neke tri znacajke) i jedina moguca rjesenja da se dobije nesto od ponudenog su 6 nezavisnih gdje uzimamo samo po 1 dvojku i 1 trojku (npr samo linearne) ili 7 nezavisnih s 2 dvojke i 1 trojkom\n\nStvarno ne kuzim",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256772": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Rene\"#p256763 svima je priznat ako sam dobro procitao obavijest. Krivo su rjesenja zadali\n\nJo≈° da nisam potro≈°io 30 min na njega al aj üòÑ",
      "votes": {
        "upvoters": [
          "AK10 (endyyyy)",
          "Gulbash",
          "InCogNiTo124",
          "Jale (ƒçakijale)",
          "Lyras",
          "Rene",
          "[deleted]",
          "angello2",
          "at5611",
          "gladiator",
          "joj (poni)",
          "kix7 (Fish99)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256786": {
      "poster": "grga_it_is (it_is_what_it_is)",
      "content": "Znaƒçi grupa A, za≈°to bi bio krivi 3. B)?\n\nI grupa A, za≈°to nije 15. C) (jer sam doslovno uvr≈°tavao brojke i provjeravao)?",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256789": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"it_is_what_it_is\"#p256786 isto sam dobio 3. B, nije mi jasno...",
      "votes": {
        "upvoters": [
          "grga_it_is (it_is_what_it_is)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256791": {
      "poster": "tomekbeli420",
      "content": "15 takoƒëer zbunjen kako jbt, uvrstavao brojke lemao\n\nA kod treceg je opceniti linearan model i granicu se moze fino naginjati tako da ispravno klasificira ona 3 preslikana primjera ali da ima razlike u ostalima iz prostora znaƒçajki, pa je zato version space veƒái od 1",
      "votes": {
        "upvoters": [
          "grga_it_is (it_is_what_it_is)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256795": {
      "poster": "grga_it_is (it_is_what_it_is)",
      "content": "@\"tomekbeli420\"#p256791 ali zar ne mo≈æe≈° to reƒái i za recimo koji su oni oznaƒçili kao toƒçan. To bi bio odsjeƒçak na y osi, pa mo≈æe≈° dobiti koliko hoƒáe≈° odsjeƒçaka?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256797": {
      "poster": "tomekbeli420",
      "content": "@\"it_is_what_it_is\"#p256795 da ali za bilokoji takav odsjecak klasifikacije svih primjera u prostoru znacajki su iste, to je ona situacija da razliciti parametri daju istu hipotezu, kod opcenitog linearnog modela pak dolazi do razlike",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256799": {
      "poster": "grga_it_is (it_is_what_it_is)",
      "content": "@\"tomekbeli420\"#p256797 \n\nAli ja mogu kontra primjer dati. Recimo ti si rekao da dobijem razliƒçite modele ovisno kako je pozicioniran pravac koji ih razdvaja, a recimo kod odsjeƒçka ja isto mogu pozicionirati ga kako ≈æelim, pa isto tako dobijem koliko hoƒáe≈° modela koji savr≈°eno klasificiraju model.\n\nZanƒçi razliƒçiti parametri za odjeƒçak daju razliƒçiti model po toj logici.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256801": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"it_is_what_it_is\"#p256786 jesi gledao apsolutno poveƒáanje il omjer prije-poslije?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256802": {
      "poster": "tomekbeli420",
      "content": "@\"it_is_what_it_is\"#p256799 uzmi u obzir da je prostor primjera parovi cijelih brojeva, ako i dalje si uvjeren okej mo≈æe≈° li dati dvije hipoteze koje nisu iste a dobro klasificiraju ulazne primjete",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "grga_it_is (it_is_what_it_is)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256805": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "Evo ovak sam rje≈°avo 3. u grupi A, ne ispada mi nigdje |Vs| = 1 . Vidi itko gre≈°ku?\n\n![](assets/2021-11-23/00012.jpg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "256806": {
      "poster": "grga_it_is (it_is_what_it_is)",
      "content": "@\"tomekbeli420\"#p256802 JAOO TO NISAM VIDIO üòÇüòÇüòÇ",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "tomekbeli420"
        ]
      }
    },
    "256807": {
      "poster": "tomekbeli420",
      "content": "@\"it_is_what_it_is\"#p256806 eh da, vrag je u detaljima prijatelju moj",
      "votes": {
        "upvoters": [
          "grga_it_is (it_is_what_it_is)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "InCogNiTo124",
          "steker"
        ]
      }
    },
    "257573": {
      "poster": "viliml",
      "content": "@\"Precious Bodily Fluids\"#p256805 Hipoteze se ne broje po parametrima nego po razliƒçitim outputima.\n\nZa D, granica zapravo odvaja [imath]x_2[/imath] vrijednosti, i toƒçno je jedna granica koja toƒçno klasificira primjere: ona izmeƒëu 0 i 1.",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "262435": {
      "poster": "Daeyarn",
      "content": "postoji li skripta za neparametarske metode?",
      "votes": {
        "upvoters": [
          "matt (Matt)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "262445": {
      "poster": "steker",
      "content": "@\"Daeyarn\"#p262435 ne, imaju samo natuknice i video",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "matt (Matt)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "262487": {
      "poster": "Daeyarn",
      "content": "@\"steker\"#p262445 hvalaa, e a gdje ima video?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "262492": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Daeyarn\"#p262487 na stranici predmeta je link takelabovog yt kanala, na njemu su sva videopredavanja",
      "votes": {
        "upvoters": [
          "Daeyarn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "262509": {
      "poster": "Daeyarn",
      "content": "@\"Precious Bodily Fluids\"#p262492 ok, hvala:D",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "264038": {
      "poster": "steker",
      "content": "U ovoj zadaci iz neparametarskih u 3. Zadatku (zadatci s ispita) jel se ‚Äúlj‚Äù uzima kao dva slova ili kao jedno slovo",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "264046": {
      "poster": "angello2",
      "content": "@\"steker\"#p264038 trebalo bi kao jedno",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "264099": {
      "poster": "[deleted]",
      "content": "jel uspio netko rijesiti 3. iz zadataka s ispita?",
      "votes": {
        "upvoters": [
          "MsBrightside",
          "rolotex (brr)"
        ],
        "downvoters": [
          "atp0lar (‚ÄÆ üè≥Ô∏è‚Äç‚ößÔ∏è‚Äç‚É† üè≥Ô∏è‚Äçüåà‚É† üáÆüá±‚É†at‚Å≠p‚Å©‚Å´0‚ÅÆlar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "266193": {
      "poster": "Artemis",
      "content": "Mo≈æe netko rije≈°iti 5.zadatak (zadatci s ispita) iz V16 Bayesov klasifikator II? Rje≈°avao se na rekapitulaciji, ali ga zapravo nije rije≈°io jer raƒçunski dugo traje.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "266272": {
      "poster": "batman3000",
      "content": "@\"Artemis\"#p266193 pogledaj tu https://fer.studosi.net/d/2793-struce-zavrsni-ispit-20202021, ima≈° dokument https://docs.google.com/document/d/15drigevvwo3wOvZ3uFZgCAO2hgEHdCUa-a1DTMWV7_k/edit#heading=h.me2a23xgw8o koji su pro≈°le godine napravili, tamo je takoƒëer rije≈°en i ovaj zadatak, mo≈æda pomogne",
      "votes": {
        "upvoters": [
          "Artemis"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "266895": {
      "poster": "rolotex (brr)",
      "content": "Jel nekto rj V13 zad za ucenje 1.zad",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "267172": {
      "poster": "viliml",
      "content": "Kako se modelira zavisnost izmeƒëu kontinuirane i kategoriƒçke znaƒçajke u Bayesovom klasifikatoru?\n\nNe znam rije≈°iti zadnji zadatak iz DZ 15-16\n\nNaivni model bi trebao imati 14 parametara i polunaivni 18, ali kako dobiti 32 za generalni?\n\nAko ignoriram tu mije≈°anu zavisnost dobijem 29.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "267383": {
      "poster": "maraska",
      "content": "Je li netko rijesio 5. zadatak s ispita za V15?\n\nNikako ne dobivam toƒçan rezultat a ne znam ≈°to toƒçno radim krivo.\n\nPrvo sam izraƒçunala zajedniƒçku kovarijacijsku matricu i dobila dijagonalnu matricu s 6, 2 i 4 na dijagonali (to su kvadrirane sigme).\n\nOnda sam isla izraƒçunati h1(x) s uvr≈°tavanjem 1 za mi(1,1), 0 za mi (2,1) i -2 za mi (3,1) te 0,2 za P(y = 1).\n\nJel ne≈°to krivo uvr≈°tavam ili?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "267438": {
      "poster": "viliml",
      "content": "@\"maraska\"#p267383 Ne≈°to si krivo uvrstila. Ne mogu reƒái ≈°to kad nisi rekla koji si rezultat i meƒëurezultate dobila.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "267773": {
      "poster": "matrica",
      "content": "![](assets/2022-01-03/00005.jpg)\n\nJe li mozda netko rjesio ovaj zadatak pod a i b?",
      "votes": {
        "upvoters": [
          "blast"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "268010": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "Koliko su 15. i 16. cjelina povezane cjelinama nakon?",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "268501": {
      "poster": "gad_gadski",
      "content": "![](assets/2022-01-06/00012.png)\n\nPGM2 skripta druga stranica, zna netko kako ovo izraƒçunati?",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "268867": {
      "poster": "Stoja_9 (Bije_san_u_autobusu)",
      "content": "@\"gad_gadski\"#p268501 Za svaku od vrijednosti c, s i r (svaka je binarna varijabla, ukupno 8 mogucih kombinacija) racunas zajednicku vjerojatnost pomocu izraza `P(c, s, r, w = 1) = P(c)P(s|c)P(r|c)P(w=1|s,r)` pomocu vjerojatnosti iz tablica na slici di je prikazana Bayesova mreza s tim da uvijek vrijedi da je w=1 i dobivene izraze pozbrajas. Znaci za c=0, s=0, r=0 dobijes izraz `P(c=0)P(s=0|c=0)P(r=0|c=0)P(w=1|s=0,r=0) = 0.5*0.5*0.8*0.0` i to zbrojis sa svim ostalim mogucim kobinacijama varijabli c, s i r.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [
          "dodo",
          "neksi (filip)"
        ],
        "tuga": []
      }
    },
    "269000": {
      "poster": "blast",
      "content": "@\"matrica\"#p267773 jel netko uspio",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "269053": {
      "poster": "ana (anci)",
      "content": "@\"blast\"#p269000 rjeseno je na recapu u srijedu negdje oko 1:15 na snimci",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "270928": {
      "poster": "RickyMorty",
      "content": "Zadatak za zadacu V19 s ispita 4. K-medoida PAM algoritam pls obja≈°njenje ovog drugog dijela algoritma di se odreduju medoidi ovo s predavanja mi fkt nije jasno kaj bi trebao racunat... skroz kontradiktorno je napisano...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "271214": {
      "poster": "netko_tamo",
      "content": "![](assets/2022-01-16/00028.png)\n\nkojoj formuli odgovara raƒçunanje P(x1=Istra | y=1)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "271308": {
      "poster": "Ducky",
      "content": "Jel zna tko objasnit ovo rje≈°enje iz zadaƒáe?\n\n ![](assets/2022-01-16/00032.png)\n\n![](assets/2022-01-16/00033.png)\n\nLL* je prosjeƒçna log-izglednost za taj model na kraju izvodenja EM-algoritma.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "271419": {
      "poster": "gad_gadski",
      "content": "![](assets/2022-01-17/00024.png)\n\nKako oni uspiju dobiti 0.56? Nez sta krivo radim\n\n![](assets/2022-01-17/00025.jpg)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "271422": {
      "poster": "Valentino",
      "content": "@\"gad_gadski\"#p271419 Ima≈° sliƒçni zadatak obja≈°njen u predavanju na Teamsima od pro≈°log ponedjeljka, poka≈æe jednostavno kako se b raƒçuna",
      "votes": {
        "upvoters": [
          "Ducky",
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "271744": {
      "poster": "zastozato (studo≈°)",
      "content": "![](assets/2022-01-18/00012.png)\n\nneko ovaj?",
      "votes": {
        "upvoters": [
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "271964": {
      "poster": "gad_gadski",
      "content": "@\"studo≈°\"#p271744 mene isto zanima, snajder je na teamsu predavanjima pricao o tim zadatcima, kao da je to najlaksa verzija zadataka s randovim indeksom, al kako je on to jednostavno prebrojavo u svom primjeru na ovom nikako da dobijes dobro rjesenje",
      "votes": {
        "upvoters": [
          "SuperSaiyano"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272065": {
      "poster": "Bananaking",
      "content": "Mo≈æe netko objasniti proces razmi≈°ljanja za ovaj zadatak? Jel se radi samo o napi≈°i formulu za log izglednost i vidi kako utjeƒçe kad se smanji N zbog manjeg podskupa i da je varijanca u nazivniku pa kad je nepristrana procjena je veƒáa varijanca pa ƒáe log izglednost izgl biti manja? I ≈°to mi ovih 0,1 za parametre znaƒçi?\n\n![](assets/2022-01-19/00018.png)",
      "votes": {
        "upvoters": [
          "Jaster111",
          "Lyras",
          "Tootha",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272297": {
      "poster": "dora (AE)",
      "content": "![](assets/2022-01-20/00007.png)\n\nJel bi mogao netko napisat postupak za ovaj zadatak?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272299": {
      "poster": "Bananaking",
      "content": "@\"AE\"#p272297 Ne znam treba li nekako pametnije/kompliciranije ali ja sam tocno rjesenje dobio tako da sam sa stranice 13 skripte procjena parametara II uzeo formulu za MAP procjenitelj, izracunas prvo za 1. korak onda za 1.+2. korak (zbrojis M i n), oduzmes ovaj drugi izracun od prvog i voila. Vjerojatno bi trebao tu formulu izvest kao oni u skripti par koraka ranije ali eto, valjda pomaze",
      "votes": {
        "upvoters": [
          "dora (AE)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272377": {
      "poster": "Daho_Cro",
      "content": "Zna li netko imaju li negdje rije≈°eni zadatci s ispita koji se nalaze u vje≈æbama za pojedinu lekciju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272390": {
      "poster": "Bananaking",
      "content": "@\"Daho_Cro\"#p272377 Nema, ≈°to je ≈°teta jer bi se dalo napraviti od toga kuharicu za ispite i sigurno ima ljudi koji su ih sve rije≈°ili",
      "votes": {
        "upvoters": [
          "Daho_Cro",
          "Ducky",
          "Gulbash",
          "JeleeII",
          "[deleted]",
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "cajaznun"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Daho_Cro",
          "Ducky",
          "Gulbash",
          "cajaznun",
          "soplagaitas (sopla)"
        ]
      }
    },
    "272471": {
      "poster": "Ducky",
      "content": "jel ima ko snimljenja predavanja koja nisu izbrisana na teamsu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272675": {
      "poster": "Dootz",
      "content": "![](assets/2022-01-22/00001.png)\n\n F1 vrijednosti sam si cak uspio objasniti, ali ove lambda nemogu smisliti. Jel zna netko zasto je C tocno?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272707": {
      "poster": "Rene",
      "content": "Mo≈æe mi netko objasnit kako su do≈°li do ovog broja parametara (17 odnosno 59)?\n\n![](assets/2022-01-22/00002.png)",
      "votes": {
        "upvoters": [
          "Daho_Cro"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272708": {
      "poster": "JoKing",
      "content": "@\"Ducky\"#p272471 Zar nisu sva predavanja dostupna kada odabere≈° General -> Files -> Recordings",
      "votes": {
        "upvoters": [
          "Ducky",
          "bodNaUvidima",
          "kix7 (Fish99)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272712": {
      "poster": "InCogNiTo124",
      "content": "Tko bumpa dokument SU2020/21 Zadaci iz zadaca i kvizova i zasto tocno?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "angello2",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "272715": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@\"AE\"#p272297 ![](assets/2022-01-22/00003.jpg)\n\n Eo lepi",
      "votes": {
        "upvoters": [
          "dora (AE)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272716": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "@\"Bananaking\"#p272065 dobro bi nam to doslo. Ja sam raspisao formule i uvrstio sve, ali nisam bas nesto previse shvatio. Tako da mislim da mora bit neka glupa caka.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272717": {
      "poster": "vidraKida (Œñ Œµ œç œÇ)",
      "content": "Ima netko postupak za ovaj zadatak? \n\n![](assets/2022-01-22/00004.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272726": {
      "poster": "gladiator",
      "content": "@\"Œñ Œµ œç œÇ\"#p272717 \n\novaj video  https://ferhr.sharepoint.com/sites/SU120212022/Zajednicki%20dokumenti/Forms/AllItems.aspx?id=%2Fsites%2FSU120212022%2FZajednicki%20dokumenti%2FGeneral%2FRecordings%2FGeneral%2D20211220%5F102034%2DMeeting%20Recording%2Emp4&parent=%2Fsites%2FSU120212022%2FZajednicki%20dokumenti%2FGeneral%2FRecordings\n\nna 4:20 ga asistent jako dobro objasni :)\n\nako ne mozes otvorit link onda nadi na teamsu snimku od predavanja 20.12 (ponedjeljak) pa pogledaj",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272763": {
      "poster": "Bananaking",
      "content": "![](assets/2022-01-22/00008.png)\n\nU ovom zadatku ka≈æe nam da je na lijevoj slici izglednost klase, na desnoj aposteriorne vrijednosti\n\nBayesovo pravilo -> P(y|x) = P(x|y) * P(y) (uz izostavljeno P(x) jer je konstanta)\n\nNas zanimaju apriorne vjerojatnosti klasa odnosno P(y). Iz Bayesovog pravila P(y) = P(y|x) / P(x|y) odnosno aposteriorna vjerojatnost kroz izglednost, za sliku to je onda P(y) = desna slika / lijeva.\n\nIz danih varijanci i slike izglednosti zakljuƒçim da je plava linija \"srednja\" odnosno odgovara klasi y = 1 jer je za nju varijanca 3, izmeƒëu 5 (≈°iroke, crvene) i 2 ( zelene, uske)\n\nDakle idem gledati za plavu liniju desna slika / lijeva. Odaberem recimo x = -10, na lijevoj slici imam otprilike 0.105, na desnoj slici imam otprilike 0.95.  Desna / lijeva je onda 0.95/0.105 = 9.04, a ne 0.1 koliko bi trebalo biti (lijeva / desna daje 0.1). Oƒçito P(y = 1) ne mo≈æe biti 9.04 ali gdje grije≈°im u logici rje≈°avanja?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272771": {
      "poster": "InCogNiTo124",
      "content": "@\"Bananaking\"#p272763 zasto dijelis desnu sliku kroz lijevu?\n\nUgl desna slika je nastala kao [imath]\\frac{f_i(x)}{f_1(x)+f_2(x)+f_3(x)}[/imath], gdje je i=1 plava klasa, i=2 crvena, a i=3 zelena. funkcije su svaki od grafiƒáa. dakle, nazivnik bayesa je suma tih funkcija. Nacrtas si u https://desmos.com/calculator ako zelis vizualizaciju kaj se dogada\n\nEvo primjer: lijeva strana x=15, crveni gaus ima f(x) od 0.03 dok zeleni za isti x ima f(x) oko 0.02. plavi x je dovoljno malen da cu ga smatrat 0\n\nSta to znaci za desnu sliku: za x=15 gledaju se omjeri. Crvena boja je 0.03/(0.02+0.03) sto je oko 0.6, zelena ima 0.02/0.05 sto je oko 0.4, plavo je 0",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272775": {
      "poster": "InCogNiTo124",
      "content": "@\"Bananaking\"#p272763 cekaj ova slika nema smisla. Postoji pogreska u grafovima, nije velika ali je dovoljna da je krivo",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272776": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"InCogNiTo124\"#p272775 di",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272778": {
      "poster": "InCogNiTo124",
      "content": "@\"Precious Bodily Fluids\"#p272776 na x=15 lijevo je zeleno vece, a na x=15 desno je crveno vece i to nije dobro\n\nevo tu sam nacrtao\n\nhttps://www.desmos.com/calculator/cd8ietcxvg",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272781": {
      "poster": "Mikki",
      "content": "@\"InCogNiTo124\"#p272771 Nije li da bi ovo tvoje vrijedilo da je lijevi graf zajedniƒçka gustoƒáa p(x,y), a ne p(x|y)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272782": {
      "poster": "InCogNiTo124",
      "content": "@\"Mikki\"#p272781 vidi graf iznad",
      "votes": {
        "upvoters": [
          "Mikki"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272806": {
      "poster": "Cubi",
      "content": "@\"Bananaking\"#p272763 Mucio sam se s ovim neko vrijeme i mislim da sam skuzio, pa da pokusam objasniti.\n\nZnaci prva stvar, izostavio si p(x) na pocetku, a kasnije si trazio tocnu vrijednost od p(y|x) sto ne ide. P(x) se izostavlja pri maksimizaciji i usporedbi koja je vrijednost veƒáa jer onda ta konstanta nema utjecaja.\n\nE sad kako naci p(y). Kad bi sve vjerojatnosi p(y) bile jednake, onda bi desna slika izgledala drugacije. Plavi i crveni graf bi se sjekli na istom mjestu na lijevom i na desnom grafu. Npr. s lijeve slike se vidi da je vjerojatnost za primjer x=-4 veci za plavi graf. Meƒëutim, da bi crvena klasa bila vjerojatnija tu, to mora znaciti da se plavi primjeri generiraju rijeƒëe, tj. da je p(y=plava) < p(y=crvena). Slicno i za ostale. \n\nKako naci tocne vrijednosti. Ja sam gledao sjecista na desnom grafu. Vidimo da se plavi i crveni graf sijeku u x=-5, tj. tu su jednako vjerojatni. Na lijevoj slici je vrijednost za x=-5 za plavi oko 0.7, a za crveni 0.1. Da bi bili jednako vjerojatni u x=-5 to znaci da crvena klasa mora biti 7 puta vjerojatnija od plave. I vec tu se otkriva odgovor, jedino moguce je 0.7 za crvenu i 0.1 za plavu. Isto razmisljanje moze se ponoviti za crveni i zeleni graf. Kod x=10 vidimo da je vrijednost za zeleni graf oko 0.17, a za crveni oko 0.5, znaci malo vise od 3 puta manja. Znaci vjerojatnost za crvene primjere mora biti malo vise od 3 puta vjerojatnija od zelenog. 0.7 i 0.2 odgovaraju tome.\n\nMalo je objasnjenje zbrda zdola, al nadam se da ce pomoci. Mogu pokusati objasniti neki detalj ako bude potrebno.",
      "votes": {
        "upvoters": [
          "Jale (ƒçakijale)",
          "Skenk",
          "cile",
          "zastozato (studo≈°)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272829": {
      "poster": "gad_gadski",
      "content": "@\"studo≈°\"#p271744 snajder pojasnio zadatak na predavanju u srijedu ovu zadnju, imas na temsu",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272837": {
      "poster": "Heklijo (Geralt of Rivia)",
      "content": "![](assets/2022-01-22/00014.png)\n\nJel se kod odredivanja topoloskog uredaja gleda po razinama? Npr. prvo nodes koji nemaju parent (w,y) pa zatim njihova djeca (z, x) itd...\n\nJel bi onda TU bio : W, Y, X, Z?",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272839": {
      "poster": "Bananaking",
      "content": "@\"Heklijo\"#p272837 Tako je",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272840": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "![](assets/2022-01-22/00015.png)\n\nzasto je tu D tocno ? a ne C?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272841": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Tompa007\"#p272840 na predavanju je rje≈°en, ugl ima≈° rubni sluƒçaj kada je N=2, i tada  slijedi mi1 = mi3, dakle ne vrijedi stroga nejednakost",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272842": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "@\"Precious Bodily Fluids\"#p272841 ahaaaa, mislis kada je N =1 ? pa onda moze biti da je mi1 = mi2 ili mi1 = mi3 ovisno koja realizacija se dogodila",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272844": {
      "poster": "Bananaking",
      "content": "@\"Tompa007\"#p272840 map procjena je ( Nk + Alfak - 1 ) / (Suma-po-k(Nk + Alfak) - K)\n\nN1 = 0, N2 = 1/2 N, N3 = 1/2 N\n\nAlfa1 = 2, Alfa2 = 2, Alfa3 = 1\n\nKad uvrsti≈° dobije≈° \n\nmi(MAP, 1) = 1 / N + 2\n\nmi(MAP, 2) = 0.5 N + 1 / N + 2\n\nmi(MAP, 3) = 0.5N / N + 2\n\nN je broj primjera, Nk je broj nastupanja k-te vrijednosti. I sad u N stavi≈° najmanji moguƒái N=1 i dobije≈° za 1 -> 1/3, za 2 -> 1/2, za 3 -> 1/6\n\nPod c) ka≈æe da je mi3 uvijek veƒái od mi1 (≈°to vidi≈° gore da nije toƒçno)\n\nPod d) ka≈æe da je:\n* mi1 od 0 do 1/3 (za N = 1 je 1/3, za veƒái N se smanjuje)\n* mi2 izmeƒëu 0.5 i 1 (za N = 1  je 0.5, za veƒái raste ali ne mo≈æe biti veƒái od jedan jer se N u brojniku dijeli sa 2 a u naz ne)\n* da je mi2 uvijek veƒái od mi3 i da su izmeƒëu 0 i 1 ( mi2 ima taj \"+1\" u brojniku)\n\nVoila.",
      "votes": {
        "upvoters": [
          "Jale (ƒçakijale)",
          "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272854": {
      "poster": "Dootz",
      "content": "@\"Bananaking\"#p272844 Nije li najmanji moguƒái broj N=2, jer kak ƒáe≈° podijelit 1 primjer na x2 i x3?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272859": {
      "poster": "Bananaking",
      "content": "Mo≈æe netko raspisati ovaj, ƒçini se jednostavno ali ne znam kako tretirati ovu prvu i zadnju uvjetnu nezavisnost\n\n![](assets/2022-01-22/00017.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272878": {
      "poster": "tomekbeli420",
      "content": "jel uspio netko? nema ≈°anse da ikako pogodim tih 64\n\n![](https://i.imgur.com/yrXAEzS.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272889": {
      "poster": "sheriffHorsey",
      "content": "@\"tomekbeli420\"#p272878 \n\nznaci za [imath]\\mathcal{H}_0[/imath] imas dio koji se odnosi na numericke znacajke: [imath]\\frac{2 \\cdot 3}{2} + 2\\cdot 2 + 2 - 1 = 8[/imath]\n\nu tom izrazu redom imas parametre za dijeljenu kovarijacijsku matricu (cuvas dijagonalu i jedan trokut), za svaku klasu po jedan vektor sredine [imath]\\mathbf{\\mu}_k[/imath] i jos [imath]K - 1[/imath] parametar za apriorne vjerojatnosti\n\nnakon ovoga ide dio za kategoricke znacajke: [imath] (3\\cdot 2\\cdot 2 - 1) \\cdot 2 = 22[/imath]\n\novdje moras isprobat sve kombinacije vrijednosti svih znacajki osim jedne koju mozes dobit iz uvjeta da se vjerojatnosti zbrajaju u 1 i to jos pomnozit s brojem klasa\n\nsljedeci je model [imath]\\mathcal{H}_1[/imath]:\n\nkod numerickih znacajki se sad mijenja prica jer je sad kovarijacijska matrica dijeljena ali i dijagonalna pa ti vise ne treba trokut, ali ostalo ostaje isto: [imath] 2 + 2 \\cdot 2 + 2 -1 = 7 [/imath]\n\nkod kategorickih znacajki su sad [imath]x_1[/imath] i [imath]x_4[/imath] zdru≈æene pa se smanjuje broj kombinacija: [imath] [(3\\cdot 2 - 1) + (2-1)]\\cdot 2 = 12[/imath]\n\ni na kraju [imath]\\mathcal{H}_2[/imath]:\n\nopet vrijedi isto za numericke kao i u prethodnom modelu: [imath] 2 + 2 \\cdot 2 + 2 -1 = 7 [/imath]\n\nkod kategorickih se pak jos vise smanjuje broj parametara: [imath] [(3-1) + (2-1) + (2-1) ] \\cdot 2 = 8 [/imath]\n\nNa kraju kad se sve sumira: [imath] (8+22) + (7+12) + (7+8) = 64 [/imath] parametra",
      "votes": {
        "upvoters": [
          "Cubi",
          "Jale (ƒçakijale)",
          "js51856 (6ak)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272894": {
      "poster": "cajaznun",
      "content": "Je li ima netko raspisano rjesenje ovog zadatka (zavrsni prosle godine) sa uzajamnom informacijom? U predavanju asistent samo preleti preko njega,  a u onom doc fileu su napisana gotova rjesenja. Takoder postupak rjesavanja  i brojevi od asistenta sa predavanja se razlikuje od onih iz doc filea za vjerojatnost x2.\n\n ![](assets/2022-01-23/00000.png)",
      "votes": {
        "upvoters": [
          "SuperSaiyano",
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272920": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "![](assets/2022-01-23/00005.png)\n\njel bi znao neko ovog objasnit ? nemogu si namapirat ove h1,h2,h3 na one kruznice",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272922": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Tompa007\"#p272920 ima ga na predavanju ako se ne varam.\n\nUkratko, u predavanju postoje formule za izraƒçun parametara za razne varijante bayesovog klasifikatora. U te formule uvr≈°tava≈° podatke iz zadataka, pa tako usporedi≈° broj parametara.\n\n≈†to se tiƒáe slo≈æenosti, mo≈æe se zakljuƒçiti da je model H2 je jednostavniji od H1 jer je on, prema njegovov definiciji, podskup modela H1. O odnosu H1 i H2 naspram H3 ne mo≈æemo ba≈° pametno zakljuƒçiti jer oni nisu podskup modela H3.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272924": {
      "poster": "Rene",
      "content": "@\"Tompa007\"#p272920 ne znam o kakvim kruznicama govoris, ali izracunas broj parametara za svaku model:\n\nH1: dijagonalna kovarijacijska za svaku klasu\n\nn * K + n*K + K-1 = 109\n\nH2: izotropna ali nije dijeljena \n\nK + n*K + K-1 = 69\n\nH3: dijeljena\n\nn(n+1)/2 + n*K + K-1 = 74\n\nJedini odgovor koji se s ovim poretkom slaze je A",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272925": {
      "poster": "Heklijo (Geralt of Rivia)",
      "content": "![](assets/2022-01-23/00006.png)\n\n≈†to predstavlja nazivnik i kako se odredi?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272931": {
      "poster": "tomekbeli420",
      "content": "@\"Heklijo\"#p272925 Dakle kod naivnog Bayesovog klasifikatora vrijedi\n\n[math]P \\left(\\mathbf{x}, y\\right) = P \\left(x_1, x_2, x_3, x_4, y\\right) = P (y) P (x_1 \\mid y) P (x_2 \\mid y) P (x_3 \\mid y) P (x_4 \\mid y)[/math]\n\nE a sad ove vjerojatnosti [imath]P (x_k \\mid y)[/imath] su vjerojatnosti kategoriƒçke (ili Bernoullijeve ako su moguƒáe samo 2 vrijednosti) sluƒçajne varijable [imath]X_k[/imath], koje se procjenjuju Laplaceovim zaglaƒëivanjem (MAP procjena sa onim alfama 2).\n\nU nazivnik ide\n\nukupan broj primjera sa oznakom [imath]y[/imath] (kako nas zanima [imath]y=1[/imath] gleda≈° ukupan broj primjera koji imaju tu oznaku, dakle ima ih 3)\n\nplus\n\nukupan broj razliƒçitih vrijednosti varijable [imath]x_k[/imath]. Ova dva koja si zaokru≈æio su faktori koji predstavljaju [imath]P(x_1 = \\text{\"Istra\"} \\mid y=1)[/imath] i [imath]P(x_2 = \\text{\"ne\"} \\mid y=1)[/imath]\n\nDakle za ovaj prvi faktor [imath]x_1[/imath] ima moguƒáe 3 vrijednosti (Kvarner Dalmacija Istra) zato jo≈° stoji +3 a za ovaj drugi faktor [imath]x_2[/imath] ima moguƒáe 2 vrijednosti (da ne).\n\n\n\n\n@\"sheriffHorsey\"#p272889 \n\nUm.... Jasno mi je da je to toƒçno rje≈°enje ali\n\nNeka mi netko objasni kako, na koji naƒçin, ovaj komad o [imath]\\mathcal{H}_0[/imath] ne uvodi pretpostavku o uvjetnoj nezavisnosti????????????????????\n\nOvim postupkom koji si ti naveo bi se zdru≈æena vjerojatnost faktorizirala kao\n\n[math]P \\left(x_1, x_2, x_3, x_4, x_5, y\\right) = P (y) P (x_2 ,x_3 \\mid y) P (x_1, x_4, x_5 \\mid y)[/math]\n\nDakle ove brojke koje si naveo, 1, 8, 22, su upravo brojevi parametara za procjenu ovih faktora\n\n≈†to **nije** potpuna faktorizacija bez nekih uvjetnih nezavisnosti. Konkretno ovdje bi onda, ƒçisto gledajuƒái samo ovu faktorizaciju vrijedilo [imath]\\{x_2, x_3\\} \\perp \\{x_1, x_4, x_5\\} \\mid y[/imath]\n\nI kako je sad to toƒçan odgovor ako ka≈æe da [imath]\\mathcal{H}_0[/imath] ne uvodi nikakve pretpostavke o uvjetnoj nezavisnosti???? Ono ≈°to sam ja dobio isprve pa sam bio u ƒçudu je broj parametara samo za [imath]\\mathcal{H}_0[/imath] je prelazio sve ove odgovore.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272939": {
      "poster": "Bananaking",
      "content": "Glupo pitanje ali kod algoritma k-sredina, kriterijska funkcija J je L2-norma, ako je centroid (1,2) a primjer x = (1,1), koliko iznosi J za taj primjer?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272940": {
      "poster": "soplagaitas (sopla)",
      "content": "@\"Bananaking\"#p272859 ![](assets/2022-01-23/00007.jpg)\n\nsori ako nije ƒçitljivo",
      "votes": {
        "upvoters": [
          "Bananaking",
          "Sulejman"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272941": {
      "poster": "Bananaking",
      "content": "@\"sopla\"#p272940 Super, hvala, ovo p(z|v,w,x,y) me zanimalo, imamo da je P(z|w,x,y) = P(z|x,y) ali nije mi bilo jasno jel mo≈æemo i v izbaciti",
      "votes": {
        "upvoters": [
          "soplagaitas (sopla)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272942": {
      "poster": "tomekbeli420",
      "content": "@\"Bananaking\"#p272939 zbroj kvadriranih euklidskih udaljenosti (euklidska udaljenost = L2 norma vektorske razlike), dakle ne korjenuje se zbroj kvadrata po dimenzijama.\n\n[imath]\\boldsymbol{\\mu} = (1, 2) \\qquad \\mathbf{x} = (1, 1) \\\\\n{\\Vert \\mathbf{x} - \\boldsymbol{\\mu} \\Vert} ^2 = (1-1)^2 + (2-1)^2 = 1[/imath]",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272944": {
      "poster": "sheriffHorsey",
      "content": "@\"tomekbeli420\"#p272931 Ima smisla ovo sto kazes, ali nije mi uopce jasno kako iskombinirati onda numericke i kategoricke znacajke",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272951": {
      "poster": "Dootz",
      "content": "@\"sheriffHorsey\"#p272944 \n\n@\"tomekbeli420\"#p272931 \n\nImate to rje≈°eno https://docs.google.com/document/d/15drigevvwo3wOvZ3uFZgCAO2hgEHdCUa-a1DTMWV7_k/edit#\n\n≈†najder je i potvrdio da je toƒçno i dobro obja≈°njeno, makar ja osobno ne razumijem neke dijelove obja≈°njenja.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272952": {
      "poster": "Bananaking",
      "content": "@\"tomekbeli420\"#p272942 Poku≈°avam ovaj rije≈°iti, nisam vidio na predavanjima da su rije≈°ili ba≈° iteracije k-sredina, ovako sam ga ja shvatio ali oƒçito nisam dobro\n\n![](assets/2022-01-23/00008.png)\n\n![](assets/2022-01-23/00009.jpg)\n\nEDIT: ups, u centriranju za mi 2 je u nazivniku 2 a ne 3 hahah, sad sve valja, nek ostane post na moju sramotu ali mo≈æda nekom pomogne",
      "votes": {
        "upvoters": [
          "tomekbeli420"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272960": {
      "poster": "tomekbeli420",
      "content": "@\"sheriffHorsey\"#p272944 e dakle ja sam inicijalno ovako to iskombinirao\n\ndakle hoƒáemo raƒçunati neke uvjetne vjerojatnosti i moramo onda parametre procijeniti\n\ne sad je pitanje kako faktorizaciju napraviti, jer nije moguƒáe kao u onom primjeru u skripti napraviti sve moguƒáe kombinacije vektora [imath]\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)[/imath] jer takvih ima neprebrojivo mnogo zbog [imath]x_2[/imath] i [imath]x_3[/imath]\n\nE sad sam si razmisljao okej kako napraviti (potpunu) faktorizaciju a da opet mogu prikazati sve to u konaƒçnom broju parametara\n\nPa mislim si okej ne mogu imati situaciju gdje u uvjetnom dijelu imam neku kontinuiranu varijablu, jer onda opet imam beskonaƒçno kombinacija\n\nDakle onda moram imati faktor [imath]P(x_2, x_3 \\mid x_1, x_4, x_5, y)[/imath] i ovo se da u konaƒçno mnogo parametara prikazati. Za svaku kombinaciju ovih uvjetnih varijabli imat ƒáu jedan 2D Gausijan\n\nOnda konaƒçna faktorizacija bi bila\n\n[math]P(x_1, x_2, x_3, x_4, x_5, y) = P(y) P(x_1, x_4, x_5 \\mid y) P(x_2, x_3 \\mid x_1, x_4, x_5, y)[/math]\n\nZa raƒçunati prvi faktor treba 1 parametar\n\nZa drugi treba 22, kao ≈°to i kod tvog postupka (3\\*2\\*2-1 kombinacija za svaku klasu)\n\nE a za ovaj treƒái, treba nam dakle 3\\*2\\*2\\*2 = 24 dvodimenzionalnih Gausijana za svaku kombinaciju\n\nDakle 24 dvodimenzionalnih lokacija + jedna dijeljena kovarijacijska matrica od 3 parametra = 24*2+3 = 51 parametar\n\n1+22+51 = 74\n\nI to je samo za [imath]\\mathcal{H}_0[/imath]\n\nEvo ovo je moje mi≈°ljenje ≈°to bi trebalo biti dobro, ovo njihovo fakat nema smisla...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272964": {
      "poster": "tomekbeli420",
      "content": "@\"Dootz\"#p272951 di toƒçno, ja ne vidim da uopƒáe se pojavljuje taj zadatak u tom docu\n\nedit: nvm na≈°ao sam sad gledam\n\nma kakvi nema ≈°anse da je ovo obja≈°njenje dobro, ƒçini mi se da je i on ukljuƒçio uvjetne nezavisnosti, da ima vremena popriƒçao bih s njim, uvjeren sam 100% da je sjebao",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272968": {
      "poster": "Dootz",
      "content": "@\"tomekbeli420\"#p272960 Stranica 16",
      "votes": {
        "upvoters": [
          "tomekbeli420"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272974": {
      "poster": "Cubi",
      "content": "@\"cajaznun\"#p272894 Znaci polunaivan bayesov klasifikator je slican kao naivan Bayesov klasifikator. Znaci rastavlja [imath]P(x_1, x_2, x_3, y) = P(y) P(x_1 \\mid y) P(x_2 \\mid y) P(x_3 \\mid y)[/imath] ako su sve varijable uvjetno nezavisne. Ako nisu, onda te zdruzi, npr recimo da su [imath]x_2[/imath] i [imath]x_3[/imath] uvjetno zavisne onda bi zajednicka vjerojatnost bila: [imath]P(x_1, x_2, x_3, y) = P(y) P(x_1 \\mid y) P(x_2, x_3 \\mid y)[/imath]\n\nProblem koji se dogadja je da je tesko odrediti koje su varijable uvjetno zavisne i onda postoje razliciti postupci objasnjeni u skripti da sad ne ulazim u detalje. U zadatku kaze da su varijable uvjetno zavisne ako je [imath]I(x_i, x_j) > 0.01[/imath] tj. uzajamna informacija veca od 0.01. Sad samo treba izracunati [imath]I[/imath] za svaki par i vidjeti koji su parovi zavisni. Njih cemo zdruziti u faktorizaciji [imath]P(x_1, x_2, x_3, y)[/imath] poslije.\n\n[imath]I(X, Y)[/imath] se raƒçuna kao [imath]\\sum{P(X, Y) ln \\frac{P(X, Y)}{P(X)P(Y)}}[/imath] za svaku vrijednost X i Y.\n\nPrimjerice: \n\n[imath] I(x_1, x_2) = P(x_1=0, x_2=0)  ln \\frac{P(x_1=0, x_2=0)}{P(x_1=0)P(x_2=0)}  +P(x_1=0, x_2=1)  ln \\frac{P(x_1=0, x_2=1)}{P(x_1=0)P(x_2=1)} +P(x_1=1, x_2=0)  ln \\frac{P(x_1=1, x_2=0)}{P(x_1=1)P(x_2=0)}+P(x_1=1, x_2=1)  ln \\frac{P(x_1=1, x_2=1)}{P(x_1=1)P(x_2=1)} [/imath]\n\nNe da mi se sad raspisivat dalje detaljno, al iz tablice se mogu odrediti [imath]P(x_1, x_2)[/imath] za svaki par vrijednosti. Npr za (0, 0) samo zbroji kad su [imath]x_1, x_2[/imath] = 0 za svaki [imath]x_3[/imath]. Slicno i za [imath]P(x_1)[/imath], samo se zbroje sve vrijednosti za svaki [imath]x_2[/imath] i [imath]x_3[/imath]\n\nAko je ovo isti zadatak kao u zadacima za vjezbu, dobije se:\n\n[imath] I(x_1, x_2)=0.00513164[/imath]\n\n[imath] I(x_1, x_3)=0.03[/imath]\n\n[imath] I(x_2, x_3)=0.00513[/imath]\n\niz cega slijeda da su varijable [imath]x_1[/imath] i [imath]x_3[/imath] zavisne i faktorizacija je [imath]P(x_1, x_2, x_3, y) = P(y) P(x_2 \\mid y) P(x_1, x_3 \\mid y)[/imath]",
      "votes": {
        "upvoters": [
          "Ducky",
          "cajaznun",
          "plavisnajper",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "272986": {
      "poster": "prx_xD",
      "content": "![](assets/2022-01-23/00012.png)\n\n![](assets/2022-01-23/00013.png)\n\nmoze netko objasnit ova 2 zadatka iz zzv-ova Bayesov Klasifikator 2 \n\nimaju rjesenja u [docu](https://docs.google.com/document/d/15drigevvwo3wOvZ3uFZgCAO2hgEHdCUa-a1DTMWV7_k/edit#heading=h.me2a23xgw8o) al mi nisu jasna\n\nsada sam vidio da je @\"Cubi\"#p272974 ovjasnio 5 zadatak al moze netko 4",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273003": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"prx_xD\"#p272986  jos skrolanja 5 sekundi gore i nasao bi 4.  @\"sheriffHorsey\"#p272889",
      "votes": {
        "upvoters": [
          "prx_xD"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273123": {
      "poster": "matrica",
      "content": "[OVDJE](https://drive.google.com/file/d/1WsLuEwz9FNfZaBUoj9qTGJWfTwSGMdJm/view?usp=sharing) mozete pronaci sve zadatke sa ispita za ZI i neke za ucenje.\n\nMozda nekome pomogne pri sutrasnjem ponavljanju ili kasnije... üòÖ \n\nako nekome treba dio za MI bacite kom",
      "votes": {
        "upvoters": [
          "2more (Shooshur)",
          "AK10 (endyyyy)",
          "Ardura (Maddy)",
          "Bananaking",
          "BrownPerson (Bambi)",
          "Daho_Cro",
          "Dootz",
          "Ducky",
          "ErnestHemingway (Alfetta)",
          "Fica (Prof)",
          "Han",
          "JBear",
          "Jale (ƒçakijale)",
          "JeleeII",
          "JoKing",
          "Mario1",
          "Me1 (Me)",
          "MsBrightside",
          "Ollie",
          "Ryder (Pepper)",
          "Smolaa",
          "Stark",
          "Sulejman",
          "SuperSaiyano",
          "SuperSjajan3",
          "Uchenikowitz (Uƒçeƒçuƒçu)",
          "Unity (Sgt. Forge)",
          "Upforpslone",
          "YenOfVen",
          "Zuzu (Coffe123)",
          "angello2",
          "blablajar",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "djeno",
          "dora (AE)",
          "eaypeasy (easypeasy)",
          "gladiator",
          "idontwannabemyself",
          "indythedog",
          "jobi (azex)",
          "kix7 (Fish99)",
          "matej1423",
          "matt (Matt)",
          "miss_anthropocene (neunist.iva)",
          "neksi (filip)",
          "plavisnajper",
          "soplagaitas (sopla)",
          "spampers (majmunska boginja)",
          "swish41 (Plavu≈°aSFilozofskog)",
          "tempest"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273125": {
      "poster": "Bananaking",
      "content": "@\"matrica\"#p273123 <3",
      "votes": {
        "upvoters": [
          "matrica"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273165": {
      "poster": "matrica",
      "content": "@\"matrica\"#p273123 \n\nupdate: [evo](https://drive.google.com/file/d/1xX65XuS85S8VhQFQHE61auqYJpLrdwYV/view?usp=sharing) i za MI, nije toliko sredeno u nedostatku vremena, ali nadam se da ce pomoci üòä",
      "votes": {
        "upvoters": [
          "AK10 (endyyyy)",
          "Bananaking",
          "BillIK",
          "Daho_Cro",
          "Ducky",
          "Han",
          "Jale (ƒçakijale)",
          "JoKing",
          "Ollie",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
          "djeno",
          "eaypeasy (easypeasy)",
          "indythedog",
          "matt (Matt)",
          "plavisnajper"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273167": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "![](assets/2022-01-24/00001.png)\n\nZna netko objasnit ovaj? S pro≈°logodi≈°njeg ZI, rje≈°enjima pi≈°e da je A toƒçno, ali ako je tema ƒçlanka veƒá brexit, rijeƒç brexit sama po sebi nebi trebala dodatno utjecati na pojavu rijeƒçi UK.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273168": {
      "poster": "matrica",
      "content": "@\"Precious Bodily Fluids\"#p273167 obzirom da ocekujes rijec brexit u clancima u brexitu, bas kao i uk - to bi znacilo da te dvije rijeci nisu uvjetno nezavisne u kateogriji clanaka koji pricaju o brexitu, to sto je tema brexit ne utjece. c i d su cini mi se jasni sami po sebi. b nije jer ne ocekujemo da ce se rijec brexit pojavljivati u clancima cija tema nije brexit, a u takvim clancima bi se recimo mogla pojaviti rijec konzum, tj skup tema koje se ne bave brexitom smo dodatno suzili na skup tema koje u sebi imaju i konzum. dakle ako nista, metodom eliminacije dolazis do istog odg",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273169": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"matrica\"#p273168 \n\n![](assets/2022-01-24/00002.png)\n\n> obzirom da ocekujes rijec brexit u clancima u brexitu, bas kao i uk - to bi znacilo da te dvije rijeci nisu uvjetno nezavisne u kateogriji clanaka koji pricaju o brexitu\n\nsori, nije mi ba≈° jasno i dalje... Ovaj zadatak je rije≈°en na predavanju i ovdje A nije toƒçan odgovor \"jer rijeƒç pandemija u temama o covidu ne pridonosi nikakvu informacijsku dobit\". \n\nKako se ova situacija razlikuje od prethodnog zadatka? Ako je tema o brexitu, pretpostavljam da pojava rijeƒçi brexit neƒáe ni≈°ta promijeniti u vjerojatnostima?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273171": {
      "poster": "matrica",
      "content": "@\"Precious Bodily Fluids\"#p273169 okej, kuzim, kontradiktorno je samo po sebi. Jedino bih i dalje ostala pri tom odgovoru zbog drugih ponudenih. Ako ovo dode na ZI, lagani prigovor setacu.",
      "votes": {
        "upvoters": [
          "Ducky",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273199": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"Precious Bodily Fluids\"#p273167 Taj zadatak je odbaƒçen pro≈°le godine tj. rekli su da nije imao toƒçno rje≈°enje",
      "votes": {
        "upvoters": [
          "Ardura (Maddy)",
          "Ducky",
          "Sulejman",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273217": {
      "poster": "Sulejman",
      "content": "@\"matrica\"#p273168 Zasto je d) jasan po sebi. Da je tema brexita i da se spominje konzum rekao bi da ce se ostatak teksta odnosit na utjecaj brexita na trgovine u hrvatskoj i mozda se uopce ne spomene uk. Sam ja ne≈° krivo sku≈æio ili?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273227": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Sulejman\"#p273217 U zadatku se dosta da filozofirati pa su ga vjerojatno zato maknuli. Pod D) se gleda koja je vjerojatnost da se u clanku koji prica o brexitu spominje rijec \"Ujedinjeno Kravljevstvo\". IMO, kad je vec tema brexit to ce imate toliko veliki utjecaj na pojavu rijeci \"Ujedinjeno Kraljevstvo\" da utjecaj uvjeta \"Konzum\" postaje zanemariv.",
      "votes": {
        "upvoters": [
          "Sulejman"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273232": {
      "poster": "BillIK",
      "content": "![](assets/2022-01-24/00008.png)\n\nMo≈æe pomoƒá s ovim? Ne dobivam ni jedan od ponuƒëenih rezultata",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273235": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"BillIK\"#p273232 Mislim da dobi≈° \"toƒçan\" odgovor kada pribroji≈° onu konstantu s pi. Iz nekog razloga su je uvrstili.",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273239": {
      "poster": "Sulejman",
      "content": "@\"BillIK\"#p273232 ![](assets/2022-01-24/00009.jpg)",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273250": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Ducky\"#p271308 jesi sku≈æio? Ne mogu shvatit LL2* >= LL3*",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273253": {
      "poster": "Rene",
      "content": "@\"Precious Bodily Fluids\"#p273250 pa oba modela imaju isti broj komponenti i dijeljenu kov. Matricu. Jedino u cemu se razlikuju je to sto H2 koristi k-means za inicijalizirati sredista a H3 to radi nasumicno. Moze se diskutirati da nasumicno mozda bas pogodi savrseno, ali u zadatku pise da ponavljas to 100 puta i uzmes prosjek, pa je za ocekivati da ce H2 biti bolji od H3 tj. LL2*>=LL3*",
      "votes": {
        "upvoters": [
          "Ducky",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273261": {
      "poster": "Tootha",
      "content": "@\"Bananaking\"#p272763 Mo≈æe≈° rje≈°iti i raƒçunanjem apriornih vjerojatnosti iz sjeci≈°ta desnog grafa.\n\nU x  = -5 vrijedi P(y=1)P(x=-5 | y=1) = P(y=2)P(x=-5 | y = 2). Nazivnik se ovdje mo≈æe maknuti jer je jednak za oba sluƒçaja.\n\nU x = 10 vrijedi P(y=2)P(x=10 | y=2) = P(y=3)P(x=10 | y=3). Izglednosti u ovim jednad≈æbama mo≈æe≈° dobiti egzaktno preko formule za Gaussovu distribuciju.  Kada dobije≈° te vrijednosti mo≈æe≈° izraziti P(y=1) i P(y=3) preko P(y=2). Iskoristi jo≈° P(y=1) + P(y=2) + P(y=3) = 1 da dobije≈° P(y=2) i preko toga dobije≈° P(y=1) i P(y=3).\n\nNapomena:\n\nU zadatku koriste notaciju N(mi, sigma)] umjesto N(mi, sigma^2).",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273264": {
      "poster": "Me1 (Me)",
      "content": "![](assets/2022-01-24/00014.png)\n\nzasto tu ne dodaju K-1 u broj parametara u svakom retku, a kod pojednostavljenja koja se nalaze odma iznad tablice dodaju? npr. ovaj zadnji redak odgovara 3.pojednostavljanju ali broj parametara nije isti",
      "votes": {
        "upvoters": [
          "Sulejman",
          "Unity (Sgt. Forge)",
          "plavisnajper"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273275": {
      "poster": "Ducky",
      "content": "![](assets/2022-01-24/00017.png)\n\njel ku≈æi tko za≈°to je mijenja za 12?\n\noke, imam teoriju, al neznam jel toƒçna...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273282": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Ducky\"#p273275 ima dosta primjera gdje se za bayesovu mre≈æu prebrojavaju parametri, pogledaj jedan od njih. Treba samo raskinut, odnosno dodat vezu pa usporediti broj parametra s orginalom, trivijalan zadatak\n\nOvdje ima primjer sliƒçnog @\"matrica\"#p273123",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273286": {
      "poster": "Rene",
      "content": "@\"Ducky\"#p273275 to je opet prebrojavanje parametara za bayesov klasifikator, imas slicnih vec rjesenih u temi\n\nMoze se rjesit preko formula za broj parametara, ali meni je lak≈°e iƒá po mre≈æi:\n\nH1: treba ti 2 parametra za P(y), za svaku od 3 vrijednosti y ti treba po 2 parametra za x1, x2 i x3, dakle ukupno [imath] 2 + 3 \\cdot 2 + 3\\cdot 2 + 3\\cdot2 = 20 [/imath]\n\nH2: treba ti 2 parametra za P(y), za svaku od 3 vrijednosti y ti trebaju 2 parametra za x1 i x2, a za svaku od 9 kombinacija y i x2 ti trebaju 2 parametra za x3: [imath] 2 + 3\\cdot 2 + 3\\cdot 2 + 9\\cdot 2 = 32 [/imath]\n\nH3: treba ti 2 parametra za P(y), za svaku od 3 vrijednosti y ti trebaju 2 parametra za x1, za svaku od 9 kombinacija x1 i y ti treba 2 parametra za x2 i za svaku od 9 kombinacija x2 i y ti treba 2 parametra za x3: [imath] 2 + 3\\cdot2 + 9 \\cdot 2 + 9\\cdot 2 = 44 [/imath].\n\n\"Parametar\" ovdje znaƒçi definirati vjerojatnost za pojedinu kombinaciju.",
      "votes": {
        "upvoters": [
          "Ducky",
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273293": {
      "poster": "Ducky",
      "content": "@\"Rene\"#p273286 hvala na postupku, ali nije jo≈° mi nije jasno teoretski odkud ti parametri dolaze.\n\nRecimo, na primjer, da su klase true (T), false (F) i ne znam (IDK). Za≈°to mi trebaju 2 parametra za P(y)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273295": {
      "poster": "sheriffHorsey",
      "content": "@\"Ducky\"#p273293 treci parametar uvijek mozes dobit preko uvjeta [imath] \\sum_{i=1}^{K} P(y = i) = 1 [/imath] pa zapravo trebas zapamtiti samo dva",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273296": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Ducky\"#p273293 ak imas kategoricu varijablu s 3 stanja, mo≈æe≈° ju modelirat s dva parametra, recimo\n\nP(y=T) = 0.2\n\np(y=F) = 0.3\n\np(y=Ne znam) = 1 - P(y=T) - P(y=F)   jer suma mora biti 1\n\nTo bi bilo da varijable nije ovisna ni o kojoj drugoj. A recimo da sad y ovisi o x, koji ima 2 stanja. Pa ima≈°\n\nP(y=T | x=0) = ...\n\np(y=F | x=0) = ...\n\np(y=Ne znam  | x=0) = ovaj dobiva≈° od prethodna dva\n\nP(y=T | x=1) = ...\n\np(y=F | x=1) = ...\n\np(y=Ne znam  | x=1) = ovaj dobiva≈° od prethodna dva\n\ndakle broj parametara koliko bi ti trebalo od y apriorno * broj stanja od x.\n\nNe znam jel ova logika korektna, al uspio sam tako rje≈°iti veƒáinu sliƒçnih zadataka",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273297": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "![](assets/2022-01-24/00020.png)\n\nOvo je super ezi zad al opet negdje grije≈°im mada neku≈æim di.\n\nP(y|x=0, z=1) = P(x=0) * P(y=0) * P(z=1|x=0, y=0) + P(x=0) * P(y=1) * P(z=1|x=0, y=1)\n\nP(...) = 0.8 * 0.7 * 0.9 + 0.8 * 0.3 * 0.8 = 0.696\n\n500 * 0.696 = 348\n\nNije ponuƒëeno?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273298": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Ivanƒçica\"#p273297 ovo je broj prihvaƒáenih uzoraka, treba≈° to oduzet od 500, jer se tra≈æi broj odbaƒçenih",
      "votes": {
        "upvoters": [
          "-Ivan- (Ivanƒçica)",
          "Ducky",
          "MsBrightside"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273300": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"Precious Bodily Fluids\"#p273298 \n\neh kad ne ƒçitam podrobno\n\ntenkju",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273301": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "ima netko tumaƒçenje ovoga?\n\n![](assets/2022-01-24/00022.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273304": {
      "poster": "-Ivan- (Ivanƒçica)",
      "content": "@\"Precious Bodily Fluids\"#p273301 \n\nAko se dobro sjeƒáam, ≈†najder je rje≈°avao ovaj zadatak i rekao da se ne sla≈æe s rje≈°enjem, toƒçnije s ovim ha2>ha3\n\nKao da to ne mo≈æemo zapravo znati je li taj dio vrijedi",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uƒçenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273305": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Ivanƒçica\"#p273304 mene taj dio isto buni, ali bi mi imalo smisla da je obrnuto, onda bi se grupe mogle fino poravnati",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273311": {
      "poster": "sheriffHorsey",
      "content": "![](assets/2022-01-24/00024.png)\n\nsto je s ovom usporedbom modela, ulazi li to u zavrsni i otkud bi to uopce trebalo ucit?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273327": {
      "poster": "Reznox",
      "content": "![](assets/2022-01-24/00030.png)\n\nMoze neko pojasnit?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273333": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uƒçenja)",
      "content": "@\"Reznox\"#p273327 znaci da ispobavas svaku kombinaciju C i gamma. resetka as in kartezijev produkt",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "273336": {
      "poster": "Rene",
      "content": "@\"Reznox\"#p273327 \n\n10 puta vrtis vanjsku petlju, ali u 9 slucajeva ce svaki primjer biti u train setu a jednom u test setu\n\nSvaki put u vanjskoj petlji prolazis sve hiperparametre dakle 31 (linearna jezgra) + 31√ó31 (rbf)\n\nU unutarnjoj petlji 4 od 5 puta ce biti u train setu, a jednom u validation\n\nNa kraju vanjske petlje jos istreniras s najboljim parametrima i testiras\n\n[imath] 9 \\cdot ((31 + 31^2) \\cdot 4 + 1) = 35721 [/imath]\n\nAko nisi ba≈° sku≈æio pogledaj pseudokod ove ugnije≈æƒëene provjere pa si probaj vizualizirat",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "276096": {
      "poster": "branimir1999",
      "content": "Postoji neka preporuka kako uciti za rok? Ishodi ucenja, skripta, stari zadaci i videopredavanja?",
      "votes": {
        "upvoters": [
          "Asdf",
          "Daho_Cro",
          "Gulbash"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "276532": {
      "poster": "Bananaking",
      "content": "Rje≈°avam ZI pa bi stavio rje≈°enja za sve osim gradivo koje nisam pro≈°ao (Bayesov klasifikator, ako netko je mo≈æe staviti svoja rje≈°enja), do≈°ao sam do ovog zadatka. Jel bi ga mogao netko raspisati? Ne znam jel dobro raspisujem nezavisnosti odnosno kako se dekomponiraju kad imam skupove npr {v, w}. Ima mi smisla da se to rastavi na dvije, v / y | x i w / y | x ali mi malo mr≈°avo izgleda pool nezavisnosti s kojima bi pojednostavio zajedniƒçku distribuciju.\n\n![](assets/2022-02-02/00025.jpg)",
      "votes": {
        "upvoters": [
          "Daho_Cro",
          "Vuk99"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "276581": {
      "poster": "tomekbeli420",
      "content": "@\"Bananaking\"#p276532 Ja sam to i≈°ao rje≈°avati tako da sam direktno poku≈°ao konstruirati Bayesovu mre≈æu tako da sam obrnutim postupkom primjenjivao ureƒëajno Markovljevo svojstvo (UMS) nad svakom varijablom:\n\n[math]x_k \\perp \\operatorname{pred}(x_k) \\setminus \\operatorname{pa}(x_k) \\mid \\operatorname{pa}(x_k)[/math]\n\nTopolo≈°ki ureƒëaj je zadan u zadatku, stoga nam je  [imath]\\operatorname{pred}(x_k)[/imath] poznat za sve varijable.\n\nNpr. [imath]\\operatorname{pred}(y) = \\{v, w, x \\}[/imath].\n\nKako?\n\nPa prvo krene≈° od Bayesove mre≈æe koja nema nikakvih uvjetnih nezavisnosti, dakle to je usmjereni acikliƒçki graf sa svim moguƒáim bridovima, pritom imajuƒái na umu topolo≈°ki ureƒëaj.\n\nI onda uzme≈° ove uvjetne nezavisnosti koje ima≈° i gleda≈° onu varijablu koja se pojavljuje sama, odnosno ne u parovima varijabli. Npr. uzme≈° ovu prvu uvjetnu nezavisnost [imath]\\{v, w\\} \\perp y \\mid x[/imath]\n\nI vidi≈° da se [imath]y[/imath] pojavljuje sam, i onda ≈°to napravi≈° jest proba≈° sku≈æiti iz ureƒëajnog Markovljevog svojstva za varijablu [imath]y[/imath] koji su roditelji od [imath]y[/imath] odnosno kakav je [imath]\\operatorname{pa} (y)[/imath]. Pa ƒçini se da je samo [imath]x[/imath], ≈°to ima smisla jer [imath]\\operatorname{pred} (y) \\setminus \\operatorname{pa} (y)[/imath] ispadne stvarno [imath]\\{v, w\\}[/imath], ≈°to odgovara onda ovoj uvjetnoj nezavisnosti koja je zadana. Dakle onda pobri≈°e≈° bridove [imath]vy[/imath] i [imath]wy[/imath].\n\nNa istu foru se za drugu uvjetnu nezavisnost zakljuƒçi da je [imath]\\operatorname{pa}(z) = \\{w, y\\}[/imath] pa onda samo te bridove koje vode do [imath]z[/imath] saƒçuva≈° (odnosno pobri≈°e≈° bridove [imath]xz[/imath] i [imath]vz[/imath] ).\n\nI onda iz dobivene mre≈æe lako i≈°ƒçita≈° faktorizaciju:\n\n[math]p (v, w, x, y, z) = p(v) p(w \\mid v) p(x \\mid v, w) p (y \\mid x) p(z \\mid w, y)[/math]\n\nDistribucija [imath]p(v)[/imath] ima 3-1=2 parametra\n\nDistribucija [imath]p(w \\mid v)[/imath] ima 3\\*(2-1)=3 parametra\n\nDistribucija [imath]p(x \\mid v, w)[/imath] ima 3\\*2\\*(3-1)=12 parametara\n\nDistribucija [imath]p (y \\mid x)[/imath] ima 3\\*(2-1)=3 parametra\n\nDistribucija [imath]p(z \\mid w, y)[/imath] ima 2\\*2\\*(2-1)=4 parametra\n\nSve skupa 24 parametara",
      "votes": {
        "upvoters": [
          "Jale (ƒçakijale)",
          "Stark",
          "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "276937": {
      "poster": "Bananaking",
      "content": "Za≈°to su B) C) i D) krivi?\n\n![](assets/2022-02-04/00000.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "276938": {
      "poster": "sheriffHorsey",
      "content": "@\"Bananaking\"#p276937 \n\nb) newtonov postupak moze koristit l2 regularizaciju (skripta, log reg 2, str. 5)\n\nc) ovaj odgovor je otrovan jer ti u pitanju kaze \"konkretno kod logisticke regresije\" a pise da gradijentni spust moze zaglaviti u lokalnom optimumu sto nije istina jer je funkcija pogreske za logisticku regresiju konveksna i onda te gradijentni spust mora dovesti do globalnog minimuma uz razumnu stopu ucenja\n\nd) u drugom dijelu odgovora kaze \"kod l2-regularizirane regresije ne konvergira ako primjeri nisu linearno odvojivi\" sto nije istina, sjeti se da logisticka regresije ne konvergira za linearno odvojive primjere ako NE koristis regularizaciju dok u slucaju regularizirane verzije ce povecanje tezina u odredenoj iteraciji povecat vrijednost funkcije pogreske umjesto smanjiti i time doc do konvergencije",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "276951": {
      "poster": "Heklijo (Geralt of Rivia)",
      "content": "Ima koji dokument sa skupljenim zadacima (i postupak) sa MI i ZI?",
      "votes": {
        "upvoters": [
          "Gulbash"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277048": {
      "poster": "Asdf",
      "content": "![](assets/2022-02-04/00006.png)\n\nmoze netko objasnit postupak rje≈°avanja ovog zadatka?\n\nIzracunam gubitke ali ne dobijem odg pod A",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277051": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"sheriffHorsey\"#p276938 u b nije krivo ≈°to newtonov postupak isto mo≈æe koristiti l2, nego ≈°to ƒáe on isto divergirati za preveliku stopu uƒçenja",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277074": {
      "poster": "sheriffHorsey",
      "content": "@\"Miƒáo Simpƒáo\"#p277051 nisam ni rekao da je krivo sto MOZE koristit l2 regularizaciju jer odgovor kaze \"za razliku od newtonovog postupka, gradijentni spust moze se koristiti za l2 regulariziranu logisticku regresiju\" sto bi znacilo da se newtonov postupak NE MOZE koristiti za l2 regulariziranu logisticku regresiju sto je odmah krivo pa dalje ni ne trebas citat, a ovaj dio s divergiranjem u odgovoru se odnosi na gradijentni spust",
      "votes": {
        "upvoters": [
          "Daho_Cro"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277085": {
      "poster": "micho (MÃµÕëÕÄÕùÃ©ÃßiÃ∂ÃÇÃâÕçƒáÃ¥ÃæÃÅÃÄÃùoÃ∂ÕÇÃΩÃ∫ÃüÃ£)",
      "content": "@\"sheriffHorsey\"#p277074 Da ali pi≈°e ti \"dok Newtonov postupak nema taj problem\", koji se vjv odnosi na divergenciju, po≈°to je to konkretan problem",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277436": {
      "poster": "Bananaking",
      "content": "Koja je razlika izmeƒëu 3-NN i te≈æinskog k-NN? U zadatku izraƒçunam sliƒçnost izmeƒëu rijeƒçi i za 3-NN uzmem 3 najveƒáe sliƒçnosti, pogledam njihove oznake (recimo 1, 1, 0) i zakljuƒçim da je oznaka primjera 1. Kako za te≈æinski?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277461": {
      "poster": "sheriffHorsey",
      "content": "@\"Bananaking\"#p277436 \n\n![](assets/2022-02-05/00016.png)\n\ndrzis se ove formule kad racunas tezinski, zapravo to vec i radis kod 3-NN ali su uvijek vrijednosti jezgrene funkcije iste pa ti ne utjece na argmax",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277492": {
      "poster": "Bananaking",
      "content": "![](assets/2022-02-06/00002.png)\n\nKako se ovdje dobije D) 79? Po meni od 7 znaƒçajki jednu odbacujemo (jer je x7 = x5 - x6) pa ih imam 6. Znaƒçi 6 nekvadriranih, 6 kvadriranih, 6C2 parova puta 2^2 kombinacije kvadrata, 6C3 trojki puta 2^3 kombinacije kvadrata = 232",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277493": {
      "poster": "Jaster111",
      "content": "@\"Bananaking\"#p277492 \n\nJa sam tu stavio da treba 5 znaƒçajki, jer x4 ti ne treba jer je kolinearan sa x3, i jo≈° izbacimo bilo ≈°ta od x5 ili x6 ili x7. Dakle 5 znaƒçajki imamo. Stoga imamo 5 nekvadriranih, 5 kvadriranih, 40 interakcijskih parova (10C2 = 45, ali oduzimamo sve one parove koji su sami sa sobom na kvadrat, dakle x1 i x1^2 npr, pa je takvih 5, dakle imamo 40), i jo≈° 30 interakcijskih trojki (svaku od nekvadriranih znaƒçajki moramo spojiti sa parom kvadriranih znaƒçajki, ali moramo paziti da ne spojimo x1 i x1^2 i x3^2 npr... kvadriranih parova ima 10, ali za x1 moramo oduzeti 4 koja imaju x1 u sebi... to nas dovodi do 6 moguƒáih parova, dakle 6 parova kvadriranih * 5 nekvadriranih znaƒçajki = 30)\n\nTo sve skupa daje 80 pa sam nekako zakljuƒçio da je 79 najbli≈æi broj pa je toƒçno lol, ne znam jel to ima logike.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277495": {
      "poster": "sheriffHorsey",
      "content": "@\"Bananaking\"#p277492 ovo mi izgleda kao zadatak s meduispita koji je bio ponisten pa vjerojatno tocan odgovor nije ni bio ponuden",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277498": {
      "poster": "Bananaking",
      "content": "@\"sheriffHorsey\"#p277495 u obavijestima na ferwebu ka≈æu da je poni≈°ten 15. u A grupi a ovo je 6. u A grupi\n\nAko je i ovaj poni≈°ten ok ali jel mi dobar naƒçin razmi≈°ljanja? Primjer u zadacima za vje≈æbu nema kvadrate u interakcijskim",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277500": {
      "poster": "sheriffHorsey",
      "content": "@\"Bananaking\"#p277498 \n\n![](assets/2022-02-06/00003.png)\n\nprvo su 6. ponistili, a 15. naknadno\n\ne jebiga davno je ovo gradivo bilo tak da ti ne mogu rec jel dobro, ali ovo kaj si napisao mi ima smisla i tako bi ga i ja rijesio\n\nmislim da ovo kaj je kolega poslije iskomentirao za x3 i x4 nije dobro jer brijem da ukupna ustedevina nije isto sto i ukupna devizna ustedevina, ali nemam pojma o financijama",
      "votes": {
        "upvoters": [
          "Bananaking"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277562": {
      "poster": "Daeyarn",
      "content": "ima negdje dokument sa zadacima iz prvog ciklusa ko kak ima ovaj doc za drugi ciklus? https://docs.google.com/document/d/15drigevvwo3wOvZ3uFZgCAO2hgEHdCUa-a1DTMWV7_k/edit#heading=h.me2a23xgw8o",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277569": {
      "poster": "Bananaking",
      "content": "@\"Daeyarn\"#p277562 ima≈° ovdje @\"matrica\"#p273123 @\"matrica\"#p273165  bilje≈ænice sa rije≈°enim svim zadacima s ispita iz vje≈æbi, i prvi i drugi dio gradiva",
      "votes": {
        "upvoters": [
          "Daeyarn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277576": {
      "poster": "Daeyarn",
      "content": "@\"Bananaking\"#p277569 hvala!!",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277580": {
      "poster": "cajaznun",
      "content": "![](assets/2022-02-06/00018.png)\n\nJe li itko zna postupak rjesavanja ova tri zadatka s MI od ove godine.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277605": {
      "poster": "Bananaking",
      "content": "Kako iz alfa proƒçitam da su primjeri potporni? U skripti ka≈æe da su svi primjeri za koje je Alfa >= 0 potporni, one za koje je alfa 0 zanemarujem, koja je razlika izmeƒëu Alfa = 1 i 0 < Alfa < 1? Jesu ti izmeƒëu unutar meke margine?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277614": {
      "poster": "Bananaking",
      "content": "@\"cajaznun\"#p277580 17. ne znam, pogledat ƒáu ga jo≈° pa ako rije≈°im stavim a ovdje su 18. i 19. Malo neuredno jbg ali mislim da se ku≈æi. Kad zna≈° ovo ≈°to sam ispod napisao onda zna≈° da su 2, 3 i 4 primjer potporni na margini, ostalo je sve raƒçunanje dijagonala i euklidske udaljenosti primjera. U 18. se pojavljuje taj izraz k(x, z) = (x^T Z)^2 i to je u primjeru u skripti izvedeno tako, asistent je kad je rje≈°avao sliƒçan zadatak isto otvorio skriptu i prepisao.\n\n![](assets/2022-02-06/00023.jpg)\n\n\n\n@\"Bananaking\"#p277605 da odgovorim sam sebi, 0 < Alfa <= C su potporni, Alfa < C su na margini, Alfa = C mogu le≈æati i unutar margine",
      "votes": {
        "upvoters": [
          "cajaznun"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277619": {
      "poster": "Han",
      "content": "Netko postupak za ovaj mozda? Dobim krivo uvijek nezz kaj krivo radim\n\n![](assets/2022-02-06/00026.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277622": {
      "poster": "Bananaking",
      "content": "@\"Han\"#p277619 I ja sam uvijek na tome krivo dobio (2.4242), on je ≈°to se mene tiƒçe krivo zadan, ako sam u krivu nek me ispravi netko",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277627": {
      "poster": "Bananaking",
      "content": "Evo moja rje≈°enja ovogodi≈°njeg MI-a, nisu ba≈° svi zadaci rje≈°eni (npr 11.) i malo je neuredno, planirao sam u ponavljanju opet ga rije≈°iti na ƒçistim papirima da bude lijepo za slikanje ali nema se vremena. \n\n![](assets/2022-02-06/00027.jpg)![](assets/2022-02-06/00028.jpg)![](assets/2022-02-06/00029.jpg)![](assets/2022-02-06/00030.jpg)![](assets/2022-02-06/00031.jpg)![](assets/2022-02-06/00032.jpg)![](assets/2022-02-06/00033.jpg)![](assets/2022-02-06/00034.jpg)![](assets/2022-02-06/00035.jpg)![](assets/2022-02-06/00036.jpg)![](assets/2022-02-06/00037.jpg)![](assets/2022-02-06/00038.jpg)![](assets/2022-02-06/00039.jpg)![](assets/2022-02-06/00040.jpg)",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Daho_Cro",
          "Jale (ƒçakijale)",
          "cajaznun",
          "krokodil",
          "miss_anthropocene (neunist.iva)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277629": {
      "poster": "Jaster111",
      "content": "@\"Han\"#p277619 ![](assets/2022-02-06/00041.jpg)\n\nMeni je ovako ispalo, jedino sta sam dugo vremena gubio da skuzim da w0 se ne regularizira, a ja sam to redovno radio.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277630": {
      "poster": "Jaster111",
      "content": "![](assets/2022-02-06/00042.png)\n\nKoji bi bio postupak rje≈°avanja ovakvog zadatka?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277632": {
      "poster": "miss_anthropocene (neunist.iva)",
      "content": "![](assets/2022-02-06/00043.png)\n\nzas su TP ovdje [math] 3 * {2 \\choose 2} [/math] a ne [math] 4 * {2 \\choose 2} [/math]?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "277877": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "![](assets/2022-02-07/00027.png)\n\njel neko ovog skuzio ?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278193": {
      "poster": "Jaster111",
      "content": "@\"Vamonos\"#p278188 kakva su generalno pitanja i ≈°ta se smatra osnovama nekog pitanja? Jesu teorijska ƒçisto ili?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278252": {
      "poster": "Vamonos (Idemo)",
      "content": "@\"Jaster111\"#p278193 esejska, da ti ne≈°to ≈°to ste obraƒëivali tipa jezgrine funkcije i ti obja≈°njava≈° o ƒçem se radi, napi≈°e≈° na ploƒçu povezane izraze tako to. Ako ne≈°to bitno izostavis pitati ƒáe te podpitanja, ako vidi da ba≈° ne zna≈° poku≈°ati ƒáe te voditi do odgovora. A ≈°to je osnovno ti ne znam ovako genericno reci.",
      "votes": {
        "upvoters": [
          "Haki"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278321": {
      "poster": "Han",
      "content": "@\"Vamonos\"#p278252 Je li medu izvucenim pitanjima moguce izvuc neki racunski zadatak ili su svi esejskog tipa? Takoder prolaizi li se po pismenom dijelu ispita kojeg smo pisali i onda kao sto je bilo krivo sto tocno ili se samo izvlace ta nova pitanja?\n\nMalo sam u strahu pa zato pitam, tenks na info unaprijed.",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278366": {
      "poster": "Vamonos (Idemo)",
      "content": "@\"Han\"#p278321 kod mene i ostalih ƒçetvero koji su bili u isto vrijeme u prostoriji nije bilo zadatka. Pitanja nemaju veze s ispitommizvlacis na slijepo",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278387": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "@\"Vamonos\"#p278188 Teoretski ako sada imam trojku, jel me moze rusit snajder ili mi moze samo spustit na 2 ? :D",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278394": {
      "poster": "Vamonos (Idemo)",
      "content": "@\"Tompa007\"#p278387 a ako jo≈° uvijek pi≈°e da je potreban prag na usmenom uvijek te mo≈æe sru≈°iti. Dal hoƒáe ne znam",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278395": {
      "poster": "Tompa007 (ùêìùêáùêÑ ùêíùêÑùêÇùêëùêÑùêì - ùêÇùêãùêîùêÅ)",
      "content": "@\"Vamonos\"#p278394 Pise da nema praga, odnosno 70% je ispit 30%labosi, ovo je citat za usmeni s preze \"usmenom ispitu koji sluÀázi kao dodatna provjera i za\n\neventualnu korekciju ocjene u graniÀácnim sluÀácajevima \"",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "278417": {
      "poster": "Vamonos (Idemo)",
      "content": "@\"Tompa007\"#p278395 aha, ja sam bio na roku gjde je zapravo nosio bodove. Iz ovog ≈°to pi≈°e rekao bih da te neƒáe ru≈°iti ako zna≈° barem ne≈°to, ali ono to je totalni guessworj",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "306662": {
      "poster": "Vuk99",
      "content": "![](assets/2022-06-29/00010.png)\n\njel bi znao netko ovo rijesit",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "306729": {
      "poster": "Reznox",
      "content": "Postoji li gdje dokument sa risenim zadacima za ispite sa vjezbi (postupci)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "306877": {
      "poster": "Reznox",
      "content": "![](assets/2022-06-30/00010.png)\n\nZna netko ovaj, ispada mi 2.41",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "306894": {
      "poster": "Daeyarn",
      "content": "@\"Reznox\"#p306877 ![](assets/2022-06-30/00022.png)\n\nedit: tu sam izostavio dvojku, mb\n\n![](assets/2022-06-30/00023.png)",
      "votes": {
        "upvoters": [
          "Reznox"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "306940": {
      "poster": "Reznox",
      "content": "![](assets/2022-06-30/00031.png)\n\nZasto se tu rjesava na ovakav nacin? Malo zbunjujuce",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "306980": {
      "poster": "snowman",
      "content": "@\"Reznox\"#p306940 sta ti tu nije jasno? to je samo x.T * w",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "307017": {
      "poster": "Reznox",
      "content": "@\"snowman\"#p306980 Da al zar nije definicija h = wTx haha",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "307050": {
      "poster": "snowman",
      "content": "@\"Reznox\"#p307017 pa isto ti dode na kraju za ovakve zadatke. ili dobijes 1x3 ili 3x1 matricu.",
      "votes": {
        "upvoters": [
          "Reznox",
          "djeno"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "307056": {
      "poster": "djeno",
      "content": "@\"Reznox\"#p306940 to sam i ja razmisljao -- mozes i po formuli wT x wT je redak matrica od w i X je znacajke po stupcima \n\nnajbitnije ti je da ti pase matricno mnozenje i da ima smisla da sve dimenzije ulaza mnozis sa svakom tezinom a sad oces rjesit ovako ili onako nije bitno",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "307060": {
      "poster": "djeno",
      "content": "![](assets/2022-07-01/00019.png)\n\nOvaj zadatak mi je mal nejasan. Ako dobijem Fi_k gore i popunim ga s nulama u lijevo kako se dobije\n\n(0 0 0 0 1 0) a ne (0 0 0 1 0 0) jer bi valjda x_1^2 trebo bit 1 a ne ovaj drugi koef?\n\nEDIT: skuzio sam treba se poredat kao i funkcija preslikavanja pa zapravo su (0, 0, 0, root(2)x1x2, x1^2, x2^2)",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Reznox"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "307090": {
      "poster": "Zuzu (Coffe123)",
      "content": "@\"Vuk99\"#p306662 ako otkrije≈° javiüòÖ",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}