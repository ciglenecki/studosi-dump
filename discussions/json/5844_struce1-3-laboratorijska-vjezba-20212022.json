{
  "title": "[STRUCE1] 3. laboratorijska vježba - 2021/2022",
  "creator": "tomekbeli420",
  "slug": "struce1-3-laboratorijska-vjezba-20212022",
  "tags": [
    "FER",
    "Strojno učenje 1",
    "Laboratorijske vježbe"
  ],
  "posts": {
    "249116": {
      "poster": "tomekbeli420",
      "content": "Heads up, pazite kad implementirate gradijentni spust kod logističke regresije\n\n![](https://i.imgur.com/oTHKR0v.png)\n\nlinija 8 u pseudokodu mora biti\n\n[imath]w_0 \\gets w_0 + \\eta \\Delta w_0[/imath]\n\ndakle sa plusom, jer ako ste akumulirali negativan gradijent u [imath]w_0[/imath] onda ga treba zbrojiti kod ažuriranja a ne ponovno oduzimati",
      "votes": {
        "upvoters": [
          "AK10 (endyyyy)",
          "Daeyarn",
          "Gulbash",
          "Jale (čakijale)",
          "Lyras",
          "Mikki",
          "Tone",
          "angello2",
          "cloudies",
          "dh333",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
          "nnn (dinoo)",
          "plavisnajper",
          "sheriffHorsey",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249138": {
      "poster": "cloudies",
      "content": "@\"tomekbeli420\"#p249116 Di si bio u nedjelju kad sam izgubila cijelo popodne zureci u kod i kad mi nije bilo jasno zasto ne radi s minusom :')",
      "votes": {
        "upvoters": [
          "Jale (čakijale)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Bucc (Olive Oil)",
          "Ducky",
          "InCogNiTo124",
          "Jale (čakijale)",
          "angello2",
          "steker",
          "tomekbeli420"
        ]
      }
    },
    "249148": {
      "poster": "[deleted]",
      "content": "@\"cloudies\"#p249138 to kad prerano počinjete s labosima heh",
      "votes": {
        "upvoters": [
          "123 (FERella)",
          "AK10 (endyyyy)",
          "BrownPerson (Bambi)",
          "Bucc (Olive Oil)",
          "Daho_Cro",
          "Ducky",
          "Gulbash",
          "Jale (čakijale)",
          "Lyras",
          "MsBrightside",
          "Ollie",
          "Uchenikowitz (Učečuču)",
          "Upforpslone",
          "angello2",
          "blablajar",
          "cajaznun",
          "cloudies",
          "gladiator",
          "iva7740 (Mica Trofrtaljka)",
          "kix7 (Fish99)",
          "kjkszpj",
          "krokodil",
          "lucylu",
          "neksi (filip)",
          "nnn (dinoo)",
          "steker",
          "tomekbeli420"
        ],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [
          "AK10 (endyyyy)",
          "Bucc (Olive Oil)",
          "InCogNiTo124",
          "Lusy (MGJ)",
          "Lyras",
          "Nocna_smjena",
          "Tinx (pingvin)",
          "blablajar",
          "in1",
          "iva7740 (Mica Trofrtaljka)",
          "kix7 (Fish99)",
          "krokodil",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "249154": {
      "poster": "tomekbeli420",
      "content": "@\"Todd Chavez\"#p249148 brt u sljedeća dva tjedna moram složit 4 labosa pa reko prvo ću ovu zvjerku jebenu",
      "votes": {
        "upvoters": [
          "Bucc (Olive Oil)",
          "[deleted]",
          "angello2",
          "jobi (azex)",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Bucc (Olive Oil)",
          "InCogNiTo124",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "249280": {
      "poster": "kix7 (Fish99)",
      "content": "@\"tomekbeli420\"#p249116 Otkud ti ova slika? U natuknicama piše ok kolko vidim",
      "votes": {
        "upvoters": [
          "Ollie"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249301": {
      "poster": "tomekbeli420",
      "content": "@\"Fish99\"#p249280 Skripta P06 - Logistička regresija, stranica u PDF-u numerirana sa 17",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249436": {
      "poster": "dora (AE)",
      "content": "Je su li ovo dobre tezine u 1.c?    [ 6.44150959 -2.11012128  0.53522851]",
      "votes": {
        "upvoters": [
          "samo_vagabundo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249440": {
      "poster": "gladiator",
      "content": "dobijam \"math domain error\" u funkciji za pogrešku unakrsne entropije. Problem nastaje kad pokušam logaritmirati izraz koji je 0. Kako ovo zaobići?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249443": {
      "poster": "viliml",
      "content": "@\"gladiator\"#p249440 Možeš clipati input na [eps, 1-eps] gdje je eps neki mali broj.\n\nAli mislim da ne bi smio nikada uopće dobiti točno 0, pazi da nisi nešto drugo krivo.",
      "votes": {
        "upvoters": [
          "gladiator"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249446": {
      "poster": "Zero",
      "content": "Kako se dobiva stopa ucenja?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249449": {
      "poster": "tomekbeli420",
      "content": "@\"gladiator\"#p249440 e jučer sam se cijelu noć zajebavao sa ovim problemom, evo što sam zaključio\n\nProblemi nastaju prilikom evaluacije [imath]\\ln{\\left(1 - \\sigma(x)\\right)}[/imath] što se više [imath]x[/imath] povećava (taj [imath]x[/imath] će kod nas biti onaj [imath]\\mathbf{w}^{\\mathrm{T}} \\mathbf{x} + w_0[/imath], no nebitno za ovaj konkretan problem, bitno je da je to neki realan broj koji je input u sigmoidalnu funkciju)\n\ni prilikom evaluacije [imath]\\ln{\\left(\\sigma(x)\\right)}[/imath] što se više [imath]x[/imath] smanjuje.\n\nKoji je uzrok problema? Output sigmoide. Pa ako ideš računati upravo tako, za **relativno veliki** [imath]x[/imath] će ti u jednom trenutku ispasti [imath]\\sigma(x) = 1[/imath] zbog računalne nepreciznosti, odnosno ne može računalo prikazati takav broj koji je toliko blizu 1. Npr. meni već za [imath]x \\geq 36.7[/imath] ispada tako. To je onda problem jer će ti dojavljivati greške/bacati exceptione ako ideš računati [imath]\\ln{\\left(1 - \\sigma(x)\\right)}[/imath] jer će pokušati računati [imath]\\ln{0}[/imath]. Kako to zaobići?\n\nPa ako malo drukčije izrazimo, dobijemo\n\n[math]\\ln{\\left(1 - \\sigma(x)\\right)} = \\ln{\\left(1 - \\frac{1}{1+ e^{-x}}\\right)} = \\ln{\\left(\\frac{e^{-x}}{1+e^{-x}}\\right)} = \\ln{\\left(e^{-x}\\right)} - \\ln{\\left(1 + e^{-x}\\right)} = -x - \\ln{\\left(1 + e^{-x}\\right)}[/math]\n\nŠto neće biti problematično za relativno velike [imath]x[/imath]. Možeš otići korak dalje i primijetiti da će za relativno velike [imath]x[/imath] izraz [imath]e^{-x}[/imath] biti blizu 0, pa onda gornji izraz u tom slučaju aproksimirati na samo [imath]-x[/imath].\n\nIsto vrijedi i za drugi problematični slučaj računanja [imath]\\ln{\\left(\\sigma(x)\\right)}[/imath] kada je [imath]x[/imath] relativno mali (kod mene je to [imath]x \\leq -700[/imath])\n\nOpet preformuliraš izraz kao i gore\n\n[math]\\ln{\\left(\\sigma(x)\\right)} = \\ln{\\left( \\frac{1}{1+e^{-x}} \\right)} = -\\ln{\\left( 1+e^{-x} \\right)}[/math]\n\nŠto je sasvim u redu jer će u logaritam onda ući dosta veliki broj zbog ovog [imath]e^{-x}[/imath]. Opet, ako hoćeš jednostavnu aproksimaciju, onda možeš ju ostvariti argumentiranjem (ili limesima) da ovih 1 nadodanih na [imath]e^{-x}[/imath] nije značajna pa onda aproksimirati gornji izraz sa samo [imath]x[/imath].\n\n@\"Zero\"#p249446 dobije se kao argument `eta` i cijelo vrijeme je ista, ne moraš raditi linijsko pretraživanje",
      "votes": {
        "upvoters": [
          "Jale (čakijale)",
          "Lyras",
          "Ollie",
          "angello2",
          "gladiator",
          "iva7740 (Mica Trofrtaljka)",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249458": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@\"gladiator\"#p249440 umjesto `log(x)` napravi `log(min(1, x + 1e-6))`. Ne stavljaj premali epsilon jer ćeš uzrokovati jedan drugi problem. Bolja rješenja od ovoga će zahtijevati funkciju koja nema takvih problema, kao npr. izraz kolege @\"tomekbeli420\"#225 . Jedini problem kod tog izraza je što nije uvijek primjenjiv, npr. tu se moglo radi sigmoide.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249462": {
      "poster": "tomekbeli420",
      "content": "@\"BDSMićo\"#p249458 Kako to misliš nije primjenjiv?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "jobi (azex)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "249468": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@\"tomekbeli420\"#p249462 ako imaš neku drugu funkciju osim sigmoide",
      "votes": {
        "upvoters": [
          "tomekbeli420"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249493": {
      "poster": "Lyras",
      "content": "@\"AE\"#p249436 te i ja dobijem",
      "votes": {
        "upvoters": [
          "dora (AE)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249526": {
      "poster": "Me1 (Me)",
      "content": "@\"AE\"#p249436 [ 4.45449454 -1.71089242  0.68413507]  0.13521872720206748\n\nja dobivamo ove tezine i ovu pogrešku unakrsne entropije, ove tvoje dobivamo kad maknem uvjet za prestanek iteracije kod premale promjene greške između dva koraka",
      "votes": {
        "upvoters": [
          "ErnestHemingway (Alfetta)",
          "Stoja_9 (Bije_san_u_autobusu)",
          "[deleted]",
          "dora (AE)",
          "gladiator",
          "lucylu",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249608": {
      "poster": "viliml",
      "content": "@\"gladiator\"#p249440 \n\n@\"tomekbeli420\"#p249449 \n\n@\"BDSMićo\"#p249458 \n\nOzbiljno, kako svi vi dobivate nule?\n\nMeni su svi rezultati uvijek između 0.005 i 0.995.\n\nOvo nikad ne bi uopće trebao biti problem osim ako je input beskonačan, težina beskonačna, ili greškom računate nad `h >= 0.5` umjesto `h`.\n\nTakođer, vidim da samo `math.log` uopće baca math domain error, `np.log` pristojna vraća negativno beskonačnost kao što bi trebao. A u svakom slučaju bi inače trebalo koristiti `np.log`, bolji je u svakom pogledu, pogotovo kad se u projektu već koristi numpy na hrpi drugih mjesta. To vrijedi općenito, sve iz standardne biblioteke što se može zamijeniti numpyom treba se, život će vam biti lakši.",
      "votes": {
        "upvoters": [
          "gladiator"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249620": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "> @\"viliml\"#p249608 Ozbiljno, kako svi vi dobivate nule?\n\nJa ne dobivam ali je sasvim moguće dobiti 0 radi nepreciznosti float32. A numpy neće baciti error jer ima +-inf vrijednost (koja je dio float specifikacije), no to ne znači da nećeš uletiti u probleme jer će ti opet poharati brojke.\n\nZapravo je korištenje numpyja gore jer si sakrivaš pravu pogrešku i teže ćeš debuggirati. Kao i neke druge stavke numpyja koje su jednostavno krivo implementirane, ali o tom po tom ako ćete ga koristiti dovoljno da si poželite iskopati oči. Dobro ga je koristiti jedino jer je brži od `math`.\n\nA i mislim dobro je ovakve stvari pohvatati na faksu, ovakve greške vam ruše produkcijske modele ko iz šale i nevjerojatno ih je teško naći. T5 je npr. bacao NaN gradijente nakon cca 2000000 ulaznih primjeraka jer nisu clippali logite.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249704": {
      "poster": "Zero",
      "content": "Jel se ovaj labos prezentira sljedeci tjedan ili poslije ispita?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249718": {
      "poster": "[deleted]",
      "content": "@\"Zero\"#p249704 sljedeći tjedan, imaš tu detaljno: [link](https://docs.google.com/spreadsheets/d/1Bzj0C3hlBcU84td0a0EF3QV4tKbdU7_85Jpq2OK5Ziw/)",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249719": {
      "poster": "Ollie",
      "content": "Kako bi trebali azurirati  [imath]\\ Δw_0[/imath] prema ovom algorimu u liniji 6?\n\nNema mi smisla da na isti način azuriram [imath]\\ Δw_0[/imath] i  [imath]Δ\\mathbf{w}[/imath]\n\n![](assets/2021-11-04/00006.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249733": {
      "poster": "lucylu",
      "content": "@\"Ollie\"#p249719 algoritam iz videa ima raspisano za svaku deltu posebno\n\n![](assets/2021-11-04/00008.png)",
      "votes": {
        "upvoters": [
          "JayOhAit",
          "Ollie"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249741": {
      "poster": "[deleted]",
      "content": "@\"Me\"#p249526 hmm ja dobivam kao kolega kad mi je max_iter == 2000, i ne breaka mi zbog uvjeta, a kad povećam broj iteracija na npr. 4000 -> breaka zbog uvjete i dobijem težine: \n\n[ 7.73426648 -2.38474752  0.46232798]",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249743": {
      "poster": "Ollie",
      "content": "@\"lucylu\"#p249733 e tenks, ali jel ovaj [imath]Δ\\mathbf{w_0}[/imath] neki vektor (jer je napisan tak boldano) ili je to sam obični [imath]\\ Δw_0[/imath]?\n\nja sam uzela da je to samo običan [imath]\\ Δw_0[/imath] i ispadaju mi ok rezultati",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249744": {
      "poster": "[deleted]",
      "content": "također,  dobijem pogrešku od 0.38, a plottano mi izgleda ok:\n\n![](assets/2021-11-04/00010.png)\n\nimao netko nešto slično?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249755": {
      "poster": "lucylu",
      "content": "@\"Ollie\"#p249743 mislim da može biti i običan taj w0",
      "votes": {
        "upvoters": [
          "Ollie"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249761": {
      "poster": "Me1 (Me)",
      "content": "@\"Todd Chavez\"#p249741 racunao sam cross_entropy_error, i njega onda gledao dal se promijenio, onda ja ubiti dodatno dijelim sa 1/N, a pretpostavljam da ste ti i kolega racunala zbroj loss-ova. Mislim da je vase tocno, moze neko potvrdit samo.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249894": {
      "poster": "Skenk",
      "content": "Kak vam izgleda dio koda za plotat granicu u 1.c)? Algoritam mi daje dobre tezine / cross_entropy_error al me konstantno zeza \"reshape\" kod plotanja.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249945": {
      "poster": "[deleted]",
      "content": "jel za cross_entropy_error u dijelu s regularizacijom dodajemo reg. faktor? odnosno jel nam se regularizacija svodi samo na weight decay pribrojnik?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249948": {
      "poster": "Skenk",
      "content": "@\"Skenk\"#p249894 nema veze, uspio",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249971": {
      "poster": "Daho_Cro",
      "content": "Jeste li u drugom zadatku koristili ugrađenu logističku regresiju(LogisticRegression) ili onu koju smo mi morali napisati tj. lr_train?",
      "votes": {
        "upvoters": [
          "angello2",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "249980": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@\"Me\"#p249761 Eh zanemari što sam napisao ranije.\n\nOkej je i jedno i drugo za taj zadatak. Što je točnije ovisi o definiciji točnosti i problemu, oba načina mogu imati i boljke i nedostatke. U praksi ljudi više vole uprosječivanje i ono se koristi za taj grupni gradijentni spust da gradijent ne ovisi o broju primjeraka.",
      "votes": {
        "upvoters": [
          "Me1 (Me)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250110": {
      "poster": "bjunolulz",
      "content": "@\"Skenk\"#p249948 kako si popravio",
      "votes": {
        "upvoters": [
          "SuperSjajan3"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250127": {
      "poster": "SuperSjajan3",
      "content": "@\"Skenk\"#p249894 moze podijelit kako si uspio ovo, dosta vremena sam vec izgubio na ovome",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250140": {
      "poster": "angello2",
      "content": "u 1.e) i 2.a) dobim identicnu granicu izmedu klasa. S obzirom da ispod stoji pitanje \"Zašto se rezultat razlikuje od onog koji je dobio model klasifikacije linearnom regresijom iz prvog zadatka?\" pretpostavljam da ne bi tak trebalo bit? mislim koristio sam LogisticRegression u oba zadatka ne vidim sta sam mogo krivo napravit",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250151": {
      "poster": "bodNaUvidima",
      "content": "@\"bjunolulz\"#p250110 @\"SuperSjajan3\"#p250127 \n\nMožete napraviti razred CustomModel kojem predajete dobivene težine u konstruktoru. U tom razredu ponudimo funkciju predict(X) koja vraca np.array u kojem se nalaze predikcije za svaki primjer u X, uz zapamćene težine w. \n\nNa kraju, poziv plot funckije može izgledati nekako ovako:\n\n`plot_2d_clf_problem(X, y, lambda x: customModel.predict(x) <= 0.5)`\n\nAko vam se pojave greške radi različitih dimenzija w i x vodite računa o preslikavanju x unutar lambda funckije u Φ(x).",
      "votes": {
        "upvoters": [
          "bjunolulz"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250153": {
      "poster": "angello2",
      "content": "@\"angello2\"#p250140 evo skuzio sam sam, u drugom izleda treba radit sa svojom funkcijom. \n\nkako vam izgleda graf u 3.? jel normalno da jedino za a=0 dobimo oke rjesenje a ostala su sva losija?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250154": {
      "poster": "steker",
      "content": "u 1 e) ovaj C parametar u logistic regression bi trebo bit neki dosta velik broj??",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250266": {
      "poster": "Reznox",
      "content": "U 2. i 3. zadatku koristite li vi nasu implementiranu funkciju ili LogisticalRegression?",
      "votes": {
        "upvoters": [
          "matej1423",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250350": {
      "poster": "MyKnee",
      "content": "Kako se azurira eta u svakoj iteraciji u 1. b) zadatu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250468": {
      "poster": "[deleted]",
      "content": "@\"angello2\"#p250153 ovako je meni ispalo:\n\n![](assets/2021-11-06/00015.png)",
      "votes": {
        "upvoters": [
          "Ollie"
        ],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250473": {
      "poster": "angello2",
      "content": "@\"Todd Chavez\"#p250468 da tak je i meni otprilike\n\nsamo zas ti iteracije idu preko 2k?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250475": {
      "poster": "[deleted]",
      "content": "@\"angello2\"#p250473 tako je kad dignem max_iter. radio sam tak svaki put kad mi u 2000 iteracija nije prekinuto zbog uvjeta za razliku greške s prošlom iteracijom, ne znam jel to dobro tbh",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250494": {
      "poster": "bjunolulz",
      "content": "@\"MyKnee\"#p250350 ne azuriras",
      "votes": {
        "upvoters": [
          "MyKnee"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250495": {
      "poster": "Skenk",
      "content": "@\"SuperSjajan3\"#p250127 @\"bjunolulz\"#p250494 \n\nEvo ovako mi izgleda taj dio za plotanje\n\n![](assets/2021-11-06/00018.png)",
      "votes": {
        "upvoters": [
          "Ollie",
          "SuperSjajan3",
          "wesley"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250659": {
      "poster": "mbeno2358 (doug345)",
      "content": "> @\"angello2\"#p250140 S obzirom da ispod stoji pitanje “Zašto se rezultat razlikuje od onog koji je dobio model klasifikacije linearnom regresijom iz prvog zadatka?”\n\nPretpostavljam da se taj dio odnosi na prethodni lab jer smo u njemu klasificirali pomocu lin. reg. Mozda su ta dva labosa bila zajedno prije pa su zaboravili to updateat.",
      "votes": {
        "upvoters": [
          "BillIK",
          "Ducky",
          "angello2",
          "kix7 (Fish99)",
          "nnn (dinoo)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250692": {
      "poster": "Ducky",
      "content": "jel trebamo rijesit zadatke označene sa * ili to znači da nas neće pitat?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250730": {
      "poster": "BillIK",
      "content": "@\"Ducky\"#p250692 pitaju te ako riješiš da obajsniš, odgovoriš na pitanja i sl. Moguće i da ti postavi teorijsko pitanje iz tog dijela gradiva, ali ako ne znaš ne skidaju baš bodove. Mene je na prvom labu pitao asistent multikolinearnost iako taj dodatni zadatak nisam riješio",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250788": {
      "poster": "Daho_Cro",
      "content": "@\"Reznox\"#p250266 Ja sam koristio našu implementiranu funkciju iz prvog zadatka. Ne znam točno koju je trebalo koristiti, ali vjerujem da neće biti problem bez obzira koju koristimo.",
      "votes": {
        "upvoters": [
          "Reznox"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250843": {
      "poster": "BillIK",
      "content": "ZADATAK 1.a) \n\nKakav utjecaj ima faktor  𝛼  na oblik sigmoide? Što to znači za model logističke regresije (tj. kako izlaz modela ovisi o normi vektora težina  𝐰 )?\n\nFaktor utječe na nagib sigmoide, ali kako to utječe na model? Hoće za veći alpha model biti prenaučen u smislu brže će doći bliže vrijednosti 1?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250845": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"BillIK\"#p250843 Tako nekako. Model sa strmom sigmoidom teži k tome da daje vrijednosti jako blizu ili 0 ili 1, pa je teško interetirati točnost klasifikacije. Dodatno, mozda ti ovo pomogne,\n\n@\"Precious Bodily Fluids\"#p249659",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250859": {
      "poster": "at5611",
      "content": "U 4. zadatku ako koristimo linear_model.LogisticRegression, kako odgovorit na ovo pitanje u vezi regularizacijskog faktora alpha? Koliko vidim LogisticRegression automatski implementira regularizaciju i taj se parametar ne moze postavit proizvoljno, pa pretpostavljam da se pitanje odnosi samo ako koristimo vlastitu implementaciju??",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250861": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"at5611\"#p250859 imaš u dokumentaciji LogisticRegressiona, atribut C je faktor regularizacije.",
      "votes": {
        "upvoters": [
          "at5611"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250868": {
      "poster": "at5611",
      "content": "@\"Precious Bodily Fluids\"#p250861  ty, stvarno san slip...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250889": {
      "poster": "Daeyarn",
      "content": "treba li se za eta raditi linijsko pretrazivanje ili se moze uzeti eta/N kako pise u skripti?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250899": {
      "poster": "nnn (dinoo)",
      "content": "Ima netko 2b) graf da može skrinat?",
      "votes": {
        "upvoters": [
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250943": {
      "poster": "sheriffHorsey",
      "content": "Treba li dodavati u pogrešku izraz [imath]\\frac{\\alpha}{2} \\mathbf{w}^T \\mathbf{w}[/imath]? Graf u 3. zadatku mi drastično drukčije izgleda kad maknem to",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250952": {
      "poster": "viliml",
      "content": "@\"Daeyarn\"#p250889 Eta ti je zadan, ne smiješ koristiti nikoji drugi.",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250956": {
      "poster": "gad_gadski",
      "content": "Kod 4. zadatka mi prilikom poly.transform(x) izbacuje error NotFittedError. Čak i kada probam izvan funkcije za graf prosiriti X u vise dimenzije mi izbacuje error. Zna netko zasto?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250957": {
      "poster": "2more (Shooshur)",
      "content": "@\"dino\"#p250899 ![](assets/2021-11-07/00017.png)\n\n![](assets/2021-11-07/00018.png)",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)",
          "nnn (dinoo)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250960": {
      "poster": "kix7 (Fish99)",
      "content": "@\"gad_gadski\"#p250956 moras fit_transform",
      "votes": {
        "upvoters": [
          "gad_gadski"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250972": {
      "poster": "Daeyarn",
      "content": "@\"2more\"#p250957 meni ovako izgleda za 2.c ovaj graf za h, za 2.b mi je drugaciji, a oba grafa za tezine w0, w1 i w2 su mi ispala jednaka\n\nedit: nisu ispali jednaki, ali se ne vidi neka golema razlika(mada postoji)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "250983": {
      "poster": "BillIK",
      "content": "Pitanje 4. zadatka\n\nQ: Koji biste stupanj polinoma upotrijebili i zašto? Je li taj odabir povezan s odabirom regularizacijskog faktora  𝛼 ? Zašto?\n\nŠto bi bio odgovor na ovo?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251012": {
      "poster": "hellvetica",
      "content": "![](assets/2021-11-07/00023.png)\n\nIma ko ideju zasto mi u 3. error ovako cudno ispada?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251020": {
      "poster": "Daeyarn",
      "content": "@\"hellvetica\"#p251012 i meni se dogodilo, probaj kod rerunnati par puta, meni je tako proradilo",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251030": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"BillIK\"#p250983 Stupanj polinoma povećava složenost klasifikacijske funkcije. Veći stupanj polinoma nam pomaže jer dopušta predviđanje na složenijim datasetima, ali ima i mane jer su takvi modeli skloniji prenaučenosti, pogotovo ako je dataset malen. Tu na snagu stupa regularizacija koja omogućava da smanjimo složenost modela tako da ih kaznimo povećanjem fje pogreške. Dakle, veći stupanj polinoma povećava složenost i smanjuje fju pogreške, a regularizacija obrnuto . Poanta je njihov optimalan omjer.",
      "votes": {
        "upvoters": [
          "BillIK",
          "Daeyarn",
          "Ducky",
          "Ollie"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251046": {
      "poster": "Ducky",
      "content": "1. d) \n\nKoju stopu učenja η biste odabrali i zašto?\n\nNajmanji, kako bi procjena bila najbolja?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251084": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"Ducky\"#p251046 \n\nOvdje sam vec odgovorio @\"Precious Bodily Fluids\"#p250872",
      "votes": {
        "upvoters": [
          "Ducky"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251358": {
      "poster": "JogaBonito",
      "content": "Ispitivanje u 13:00\n\nSva pitanja su bila iz uputa za labos i mislim cak da me je doslovno svako pitala. Dodatno traži ukratko objašnjenje koda kod implementacije funkcija (npr. za lr_train), sve skupa je trajalo nekih 15 min. Ocjenjivanje vise nego korektno.",
      "votes": {
        "upvoters": [
          "BillIK",
          "Daho_Cro",
          "Ducky",
          "Gulbash",
          "Kasperinac",
          "Lyras",
          "Ollie",
          "diskobanana",
          "idontwannabemyself",
          "netko_tamo"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251388": {
      "poster": "kix7 (Fish99)",
      "content": "@\"hellvetica\"#p251012 meni se slicno dogadalo, popravilo mi se kad smanjio toleranciju na tipa 0.00001",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251631": {
      "poster": "Reznox",
      "content": "Zna li netko odgovor na \"Kako biste utvrdili da je optimizacijski postupak doista pronašao hipotezu koja minimizira pogrešku učenja? O čemu to ovisi?\"",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251803": {
      "poster": "Kasperinac",
      "content": "Treba li za ispitivanje znati gradivo 7.predavanja logistička regresija 2? Ako nisam nes previdjeo, ovo gradivo nema u labosu.",
      "votes": {
        "upvoters": [
          "zastozato (studoš)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251849": {
      "poster": "fraki",
      "content": "@\"Kasperinac\"#p251803 Ja sam dobio samo jedno pitanje iz toga jucer (multinomijalna logisticka regresija), vjerojatno mozes i bez toga ili samo zapamtit osnovne pojmove",
      "votes": {
        "upvoters": [
          "Kasperinac",
          "zastozato (studoš)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251932": {
      "poster": "[deleted]",
      "content": "![](assets/2021-11-09/00045.png)\n\n zna netko ovo? nisam siguran jel se tu samo traži da bi granica bila na 0, a ne 0.5",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251936": {
      "poster": "tomekbeli420",
      "content": "@\"Todd Chavez\"#p251932 da, onda bi u onu funkciju plotanja stavio\n\n``plot_2d_clf_problem(X, y, lambda x: lr_h(x, w) >= 0)`` (doduše da bi ovo radilo trebalo bi neke stvari promijeniti oko modela i gubitka, al poanta je da je granica 0)",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "251956": {
      "poster": "[deleted]",
      "content": "@\"tomekbeli420\"#p251936 hvala, a jel znas mozda ovdje odgovor na 3.?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "252019": {
      "poster": "Valentino",
      "content": "2.c) Nije mi baš jasno kakva bi trebala biti razlika ovisno o linearnoj odvojivosti ulaznog skupa. Grafovi izgledaju gotovo isto, ali zašto?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "252034": {
      "poster": "sheriffHorsey",
      "content": "@\"Valentino\"#p252019 mislim da se razlika vidi kad povecas broj iteracija i smanjis epsilon, onda se u grafu s outputima modela svi outputi priblize 1 ili 0, a kod nelinearno odvojivog slucaja ostaje otprilike konstantno jer se ne moze vise smanjiti funkcija gubitka",
      "votes": {
        "upvoters": [
          "Valentino"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "252234": {
      "poster": "netbitan11 (netbitan)",
      "content": "@\"Valentino\"#p252019  @\"Precious Bodily Fluids\"#p250845",
      "votes": {
        "upvoters": [
          "Valentino",
          "bodilyfluids (Dragi prijatelj strojnog učenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}