{
  "title": "[DUBUCE] 4. laboratorijska vježba - 2019/2020",
  "creator": "InCogNiTo124",
  "slug": "dubuce-4-laboratorijska-vjezba-20192020",
  "tags": [
    "FER",
    "Duboko učenje",
    "Laboratorijske vježbe"
  ],
  "posts": {
    "29674": {
      "poster": "InCogNiTo124",
      "content": "Jel itko stigo pogledat predavanja, jesu kvalitetna? Kolega od prošlih godina je reko da je ovaj labos najgadniji",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "29708": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "Okej su\n\nMalo su po meni spora pa pitanje koliko su korisna, al se može staviti na 1.5x i to je to",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32536": {
      "poster": "InCogNiTo124",
      "content": "Jel ima itko da je poceo implementaciju? nekako mi smrdi da nije vrijedno 5 bodova",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32537": {
      "poster": "Denn",
      "content": "@InCogNiTo124#32536 Zadnja dva zadatka su lakša od prvog, a prvi je u RBM matematika i onda ponavljanje toga N puta. Koji dio se čini najspetljanijim?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32538": {
      "poster": "InCogNiTo124",
      "content": "@Denn#32537 tbh najspetljanije mi je pocet, nosi 5 bodova, rok sutra navecer, milijun stvari za iskodirat (unatoc tome sto je dan stub)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32560": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@InCogNiTo124#32538 that's loser talk\n\nono što je fucked je što mislim da će trebat GPU za ovo",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32564": {
      "poster": "InCogNiTo124",
      "content": "> @micho#32560 ono što je fucked je što mislim da će trebat GPU za ovo\n\nPa zar nisi za ostale labose koristio gpu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32579": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@InCogNiTo124#32564 Za prvi jesam, za ostale nisam :^)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32580": {
      "poster": "Denn",
      "content": "@micho#32560 Google Colab to the rescure :D",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32588": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Denn#32580 Don't get it twisted imam ja grafičke samo ih ne volim koristiti za ove mim stvari xD\n\nBTW collab je sad u rasulu, izgleda da je navala kak je kraj godine u većini svijeta, good luck",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "32589": {
      "poster": "InCogNiTo124",
      "content": "@micho#32588 ima nekih alternativa colabu poput paperspace, al moguce da i oni imaju iste probleme",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ]
      }
    },
    "32932": {
      "poster": "talos",
      "content": "Ovaj se labos može komotno prepolovit na dva labosa...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "wtf": [],
        "tuga": [
          "InCogNiTo124"
        ]
      }
    },
    "32950": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@talos#32932 tbh ja radim samo VAE i GAN, baš je opušteno\n\npretpostavljam da je to 40% bodova (pa možda nije dobra strategija nekome tko treba bodova), ali ionako se u praksi samo ova 2 koriste a fakat ih je lagano za napisati... VAE je na nivou prvog labosa lol",
      "votes": {
        "upvoters": [
          "talos"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33144": {
      "poster": "Toma (Tamel)",
      "content": "Ako je netko rijesio 3. zadatak, kako ste rijesili rekonstrukciju? Ne kuzim na koji tocno dio se odnosi v_out_tmp_prob koji su dali u predlosku, i trebamo li koristiti jos nesto u toj funkciji?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33156": {
      "poster": "Jimothy",
      "content": "Jel nekome funkcija walk_in_latent_space() radi dobro za LATENT_SIZE=20 u 4. zadatku?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33182": {
      "poster": "Denn",
      "content": "@Jimothy#33156 Kak ti se ponaša? Provjeri da imaš najnoviju verziju, bio je update, ima napomena na vrhu.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33190": {
      "poster": "Denn",
      "content": "@Toma#33144 Pogledaj si što ti funkcija za gibbs vraća, obrati pozornost na tome koje je stanje \"naj\" up-to-date. Iz toga si onda možeš vidjet koje korake moraš poduzet da dođeš od naj up-to-date stanja do v.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33195": {
      "poster": "Jimothy",
      "content": "@Denn#33182 \n\nBaci mi error vezan uz shape, odnosno oni u decoder šalju tensor dimenzija 225x2, a ja očekujem recimo 225x20 jer je latent_size=20. Mislim da imam najnoviju verziju, danas skinutu.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33199": {
      "poster": "Denn",
      "content": "@Jimothy#33195 Za tu funkciju moraš odabrat samo dvije dimenzije, da se može plotat u 2D. Pogledaj si boxplotove i odaberi dvije koje imaju koristi. Možeš plotat i jednu koja je korisna i jednu koja se urušila dodatno, čisto da pokažeš da ti model radi OK, ali da ti se desio variational collpase.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33210": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "Ako netko ne može dobiti dobre rezultate za VAE, pročitajte si [ovo](https://www.microsoft.com/en-us/research/blog/less-pain-more-gain-a-simple-method-for-vae-training-with-less-of-that-kl-vanishing-agony/). Mene je jebalo u mozak što je latentan vektor i nakon 1000 epoha imao oblik prototipa znamenki za svaki ulaz, nakon što sam postavio [imath]\\beta[/imath] (iz članka) na apsolutnu sinusoidu stvari su proradile.\n\n**SAMO PAZITE** da je apsolutna sinusoida, ako stavite običnu loss će vam eksplodirati u NaN hehe\n\nBez ove modifikacije:\n\n>! ![](assets/2020-05-31/00024.png)\n\nS modifikacijom:\n\n>! ![](assets/2020-05-31/00025.png)\n\nAko vam eksplodira loss u negativu, pormijenite predznak KL divergenciji: dio lossa u smislu KL divergencije treba imati [imath]-[/imath] predznak",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33212": {
      "poster": "Jimothy",
      "content": "@Denn#33199 \n\nAli zar nije tu problem broj neurona u u zadnjem sloju enkodera (200, 20)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33228": {
      "poster": "Denn",
      "content": "@Jimothy#33212 Mislim da ne razumijem točno. Kad se trenira VAE mreža sa latent_size=2, plotaju se sve dimenzije. Kad se trenira VAE mreža sa latent_size=20, plotaju se samo dvije. Kako zadnji sloj enkodera tu radi problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33233": {
      "poster": "talos",
      "content": "@micho#33210 \n\nImao sam točno iste probleme, ja sam samo stavio \"regularizacijski\" faktor koji skalira KL div i radi tak tak sad.\n\nEDIT: + can confirm ovo s KL preznakom",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33235": {
      "poster": "Jimothy",
      "content": "@Denn#33228 \n\nPardon, krivo sam rekao, prvi sloj dekodera je fully-connected layer čije su dimenzije (latent_size, 200), a latent size = 20. Što znači da dekoder očekuje ulaz veličine 20, a ne 2.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33243": {
      "poster": "Denn",
      "content": "@micho#33210 Budi samo siguran da ćeš moć objasnit šta taj beta radi, i zašto je tvoj model i dalje \"čisti\" VAE a ne beta-VAE (https://openreview.net/forum?id=Sy2fzU9gl). \n\nInače, bez ikakvih modifikacija izgleda ovako:\n\n![](assets/2020-05-31/00026.png)\n\n131 epoha, konačni loss 104.62. Na 100. epohi je loss bio 106.97.",
      "votes": {
        "upvoters": [
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33258": {
      "poster": "Denn",
      "content": "@Jimothy#33235 Vidim sad, nova verzija ne radi dobro za dimenzije != 2. Možeš si dodat `\n    synthetic_representations = np.hstack([synthetic_representations, np.zeros((400, 18))])` čisto da proradi. Ne koristi se dimensions_to_walk argument, ali možeš složit relativno lagano ako te zanima kako izgleda kroz druge dimenzije.",
      "votes": {
        "upvoters": [
          "talos"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33262": {
      "poster": "najnman",
      "content": "Jel i vama GAN daje otprilike ovakve rezultate nakon 15 epoha?\n\n![](assets/2020-05-31/00028.png)",
      "votes": {
        "upvoters": [
          "Jimothy",
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33265": {
      "poster": "Jimothy",
      "content": "@najnman#33262 \n\nOvako je nakon 10 meni.\n\n![](assets/2020-05-31/00029.png)",
      "votes": {
        "upvoters": [
          "[deleted]",
          "najnman"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33268": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Denn#33243 Ideja Beta-VAE nije baš da se koriste Bete < 1, tako da mislim da je sve okej. Isto tako, originalni Beta-VAE nema dinamički beta. Periodički i glatko dopuštam mreži da ignorira distribucijska ograničenja i posveti se samoj reprezentaciji.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33289": {
      "poster": "Jimothy",
      "content": "@Denn#33258 \n\nHvala :)",
      "votes": {
        "upvoters": [
          "Denn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33358": {
      "poster": "InCogNiTo124",
      "content": "Nego, kad bi mogla bit nadoknada?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33361": {
      "poster": "Denn",
      "content": "@InCogNiTo124#33358 Sve su nadoknade u tjednu 8.6. - 12.6., jer je to zadnji tjedan prije ispita.",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "33492": {
      "poster": "InCogNiTo124",
      "content": "@Denn#33361 potvrdeno, danas je dosao mail",
      "votes": {
        "upvoters": [
          "Denn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "34298": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "Par dojmova\n\n- ovo što sam radio s podešavanjem težine KL divergencije može overfittati mrežu, ali interesantnije je što vjerojatno i Kaiming He inicijalizacija to donekle uzrokuje - stavio sam na GitHub jupyter bilježnicu pa tko hoće može vidjeti u čemu je riječ [ovdje](https://github.com/Yalfoosh/DUBUCE/blob/master/LAB4/notebooks/LAB4.ipynb)\n- treba trenirati mrežu tak obično, bez npr. schedulera i modifikacija težina KL divergencije zato što asistent traži da se pokažu neki događaji na grafovima - težine na KL divergenciji to totalno izbjegavaju\n\nInače sam bio napravio i GAN al ga nisam predao pa tu ne mogu dati dojmova kad to nisam odgovarao xD",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "34316": {
      "poster": "sth",
      "content": "@InCogNiTo124#33492 Tko je poslao mail? Meni nista nije stiglo..",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "34319": {
      "poster": "InCogNiTo124",
      "content": "@sth#34316 web fera, dubuce, obavijesti",
      "votes": {
        "upvoters": [
          "sth"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "35022": {
      "poster": "[deleted]",
      "content": "Za buduće generacije: ova vježba u stvari i nije tako naporna. Daleko najlakša vježba (barem implementacijski). Vjerujem da se dosta nas nije susrelo s generativnim modelima prije pa je možda tu bila najveća prepreka, odnosno trebalo je naučiti stvari xd. Nažalost, predavanja Subašića i nisu tako dobra. Meni malo z brda-z dola govori i imam osjećaj da puno toga želi reći, ali da ne zna od kud da krene pa sve to bude nepovezano.\n\nOvo su materijali koje sam ja koristio:\n1. [Autoencoders - STAT453 ](https://www.youtube.com/watch?v=iddlDHXDxc0)\n2. [Generative models - CS231n](https://www.youtube.com/watch?v=5WoItGTWV54)\n3. [GANs - STAT453](https://www.youtube.com/watch?v=aka29GqbsEM)\n\nTočno tim redosljedom bi preporučio.\n\nAko nekoga zanima još, ovo su dobre playliste - [VAE](https://www.youtube.com/playlist?list=PLdxQ7SoCLQANizknbIiHzL_hYjEaI-wUe) i [GANs](https://www.youtube.com/playlist?list=PLdxQ7SoCLQAMGgQAIAcyRevM8VvygTpCu)\n\nRBMove sam radio iz [Neural Networks and Deep Learning: A Textbook](https://link.springer.com/book/10.1007/978-3-319-94463-0).\n\nNisam bio radio DBNove tako da ne znam trenutno od kud to treba učit.\n\nUglavnom, labos se više-manje svodi na nadopunjavanje koda i interpretaciju grafova.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "Kristijan",
          "allophone",
          "danko (nerim)",
          "ls_123 (KimuraKong)",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "35070": {
      "poster": "InCogNiTo124",
      "content": "@tolecnal#35022 Labos nije tezak u smislu koda ali je smrt u smislu pretakanja jednadzbi i koncepata u kod. \"Nista mi nije jasno\" je understatement, ali treba napisat svega 20ak linijica u prva dva zadatka\n\nTo, i training time je nezanemariv",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "35082": {
      "poster": "[deleted]",
      "content": "@InCogNiTo124#35070 Da. Treba uložiti malo više vremena u čitanje jer jednostavno službena predavanja ipak nisu dovoljna, odnosno nisu dovoljno dobra.\n\nA i da, potrebno je dosta vremena za treniranje, čak i na GPU-u. I još uz to je Google Colab bio \"tražena roba u gradu.\"",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "35136": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "bruh moment je kad undervoltaš GPU na -150mV i radiš 90 sekundi pauze između epoha i svejedno ti se pregrije komp jer FOSS ekipa ne razumije što je to thermal throttle\n\nbilo bi kul kad bi imali neki Colab u pogledu faksa ali ježim se kad skužim da bi ZPR pisao API tome",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "35163": {
      "poster": "InCogNiTo124",
      "content": "> @micho#35136 bilo bi kul kad bi imali neki Colab u pogledu faksa ali ježim se kad skužim da bi ZPR pisao API tome\n\nTo bi bilo bas super, sve nas ubace u neki shared jupyterhub na aws instancama, ko coursera, imas notebookse, mogu i videe embeddat\n\nAl sanse da se to desi je <= 0",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "35275": {
      "poster": "Ma97",
      "content": "Je li obavezno rješavati vježbu(ako već imamo 40% ukupno)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "35354": {
      "poster": "InCogNiTo124",
      "content": "@Ma97#35275 nije",
      "votes": {
        "upvoters": [
          "Ma97"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "36906": {
      "poster": "InCogNiTo124",
      "content": "Jel itko rjesavo 3. zadatak u pytorchu (fine tuning dbn)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ]
      }
    },
    "36965": {
      "poster": "phuck",
      "content": "@InCogNiTo124#36906 Jesam ja, ali dobijem losije rezultate nego rbm",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "36971": {
      "poster": "InCogNiTo124",
      "content": "@phuck#36965 moji rezultati su isto katastrofa i kao da se ne uci nist",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "36978": {
      "poster": "phuck",
      "content": "@InCogNiTo124#36971 ![](assets/2020-06-08/00014.png)\n\nTo su mi rezultati za prva 3 broja. Reconstruction 1 je rbm, 2 je dbn, 3 je fine tuning dbn. Asistent mi je skinuo bodove jer su rezultati losiji, a ne bi trebali biti. Nisam uspio naći grešku, al nisam ni previse trazio da budem iskren xd. Ako skuzis u cemu je problem javi",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "36981": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@phuck#36978 ovak ti obično izgledaju overfittane stvari. Probaj pratiti što se događa tijekom treninga",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "36985": {
      "poster": "phuck",
      "content": "@micho#36981 Moguće. Treniram prvi rbm kroz 100 epoha, pa onda rbm u iducem sloju (2. zadatak) isto kroz 100 epoha i onda isto tako fine tuning (3. zadatak) kroz 100 epoha. Nek se nadje radi usporedbe\n\nAl moguće je i da imam neku implementacijsku pogrešku",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "36996": {
      "poster": "InCogNiTo124",
      "content": "At this point samo bih htio prepisat od nekog",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "wtf": [],
        "tuga": [
          "Trolololica"
        ]
      }
    },
    "37482": {
      "poster": "sth",
      "content": "![](assets/2020-06-09/00035.png)\n\nGAN. Do kojih bismo zakljucaka tu sve trebali doc?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "37634": {
      "poster": "InCogNiTo124",
      "content": "@sth#37482\n\n1. rezultati su ili a) bolji, jer su se generator i diskriminator dobro inicijalizirali pa su se zajedno poboljsavali, ili b) losiji, jer je jedan od njih bio toliko bolji da ovaj drugi nije imao sanse\n2. nisam radio al kao logicno onaj koji ima vise iteracija bit ce bolji\n3. Unsuprisingly, BN je super i bez tog mreza performira losije",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}