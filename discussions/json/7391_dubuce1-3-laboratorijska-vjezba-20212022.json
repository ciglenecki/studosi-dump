{
  "title": "[DUBUCE1] 3. laboratorijska vježba - 2021/2022",
  "creator": "Jaster111",
  "slug": "dubuce1-3-laboratorijska-vjezba-20212022",
  "tags": [
    "FER",
    "Duboko učenje 1",
    "Laboratorijske vježbe"
  ],
  "posts": {
    "295431": {
      "poster": "Jaster111",
      "content": "Što bi ovaj tu frequencies parametar trebao biti?\n\n![](assets/2022-05-10/00006.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295432": {
      "poster": "BillIK",
      "content": "Jel nekome moguća zamjena grupa na ferwebu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295433": {
      "poster": "sheriffHorsey",
      "content": "@\"BillIK\"#p295432 Meni je bila jucer dostupna, ali sad mi nema niceg",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295434": {
      "poster": "angello2",
      "content": "@\"Jaster111\"#p295431 dict u kojem su sve rijeci i broj njihovog pojavljivanja u datasetu, znaci oblika (string : int)",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295440": {
      "poster": "Jaster111",
      "content": "@\"angello2\"#p295434 hvala ti",
      "votes": {
        "upvoters": [
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295455": {
      "poster": "BillIK",
      "content": "Može li netko objasniti što bi trebalo biti sve u razredu NLPDataset? Što on točno prima kao argumente, ako prima i što bi točno ta metoda __getitem__ trebala raditi? Ne kužim prima li on kao argument ove naše vokabulare ili csv file ili nešto stoto",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295456": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "> @\"BillIK\"#p295455 Može li netko objasniti što bi trebalo biti sve u razredu NLPDataset?\n\nNeka reprezentacija dataseta, a koja, ovisi o tebi\n\n> @\"BillIK\"#p295455 Što on točno prima kao argumente\n\nŠto god isprogramiraš da prima, ali trebao bi nekako imati izvor podataka\n\n> @\"BillIK\"#p295455 što bi točno ta metoda getitem trebala raditi?\n\nekvivalent operatora indeksiranja, iliti `operator []`\n\n> @\"BillIK\"#p295455 Ne kužim prima li on kao argument ove naše vokabulare ili csv file ili nešto stoto\n\nŠto god želiš da ima smisla\n\n----\n\nUvijek je najbolje posavjetovati se s dokumentacijom: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295941": {
      "poster": "mariak (kaiak)",
      "content": "Zna itko koje prezentacije treba proci za labos",
      "votes": {
        "upvoters": [
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296325": {
      "poster": "crocorax",
      "content": "provjerite kalendare, meni su prebacili labos s cetvrtka na utorak bez da su mi javili...",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "ErnestHemingway (Alfetta)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296334": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "2. zadatak\n\nKroz epohe mi train accuracy normalno raste, do cca 95%, a validation accuracy je iz nekog razloga za svaku epohu 50%...\n\nJel itko imao slican problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296339": {
      "poster": "ErnestHemingway (Alfetta)",
      "content": "@\"crocorax\"#p296325 First time?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Daeyarn",
          "Fica (Prof)",
          "InCogNiTo124",
          "bodilyfluids (Dragi prijatelj strojnog učenja)",
          "crocorax",
          "sheriffHorsey",
          "steker",
          "wesley"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296342": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "U drugom zadatku dobivam validation accuracy cca. 50% za svaku epohu, a train accuracy raste normalno.\n\nJel imao itko sličan problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296345": {
      "poster": "Baksuz",
      "content": "Jel zna netko što bi trebalo značit \"Pri primjeni sažimanja usrednjavanjem odmah eliminirajte cijelu vremensku dimenziju (tzv. okno je veličine T)\" u drugom zadatku? Kako bi trebala izgledat implementacije tog pooling layera?",
      "votes": {
        "upvoters": [
          "yabk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296351": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"Baksuz\"#p296345 \n\nKoristeći torch.mean po vremenskoj dimenziji. Ulaz u mrežu je tenzor trećeg reda (batch, T, embedding). Kad izračunaš mean dobije se tenzor (batch, embedding), bar sam ja tak rješio",
      "votes": {
        "upvoters": [
          "Baksuz",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296355": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"Precious Bodily Fluids\"#p296342 \n\nnemojte biti ja,\n\nnemojte raditi poseban vokabular za validation dataset",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296381": {
      "poster": "Sinusan",
      "content": "@\"Precious Bodily Fluids\"#p296355 \n\nBio sam ti.\n\nOvaj komentar me spasio.",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog učenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296429": {
      "poster": "indythedog",
      "content": "U  torch.nn.utils.clip_grad_norm_ metodi, što ste stavili za max_norm parametar?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296430": {
      "poster": "indythedog",
      "content": "@\"indythedog\"#p296429 Nvm, vidim da su u 3. zadatku stavili 0.25",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296442": {
      "poster": "indythedog",
      "content": "Ima netko da mu u 2. ispada točnost 1.0 na valid/test setu? Nekako nemam osjećaj da je to baš dobro haha",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296482": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "koliko vam se vrti 3. zadatak jedna epoha na testu, ak ste na CPU?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296507": {
      "poster": "Tompa007 (𝐓𝐇𝐄 𝐒𝐄𝐂𝐑𝐄𝐓 - 𝐂𝐋𝐔𝐁)",
      "content": "Koje sve preze ulaze za ovaj labos ?",
      "votes": {
        "upvoters": [
          "Ducky",
          "Krpa1 (Janez)"
        ],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296690": {
      "poster": "miss_anthropocene (neunist.iva)",
      "content": "```\ndef collate_fn(batch):\n    texts, labels = zip(*batch)\n    lengths = torch.tensor([len(text) for text in texts]) \n    return texts, labels, lengths\n\n```\njel zna tko kak fixati error **TypeError: len() of a 0-d tensor** u ovoj funkciji?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296697": {
      "poster": "neksi (filip)",
      "content": "Što je bilo na blicu?",
      "votes": {
        "upvoters": [
          "Retard00",
          "Valentino",
          "indythedog",
          "kix7 (Fish99)",
          "miss_anthropocene (neunist.iva)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296698": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"Kernel Panic\"#p296690 Jel radiš negdje squeeze? možda je povezano s tim. \n\nMislim da error nema veze s collate_fn, nego s  necim unutar unutar NLPDataseta",
      "votes": {
        "upvoters": [
          "miss_anthropocene (neunist.iva)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296711": {
      "poster": "Jaster111",
      "content": "Jel bi mi onda za override getitem metode zapravo trebali u NLPDataset ubacit Vocab? Ne kužim, čini mi se to sve dosta redundantno.",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Fica (Prof)",
          "at5611"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296779": {
      "poster": "Jaster111",
      "content": "Ima netko kakav cheat sheet za ovaj 2. zadatak? Šta mi šaljemo gdje i šta se sa čime radi? Kako koristimo u svemu tome dataloader, a kako embeddingse?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296789": {
      "poster": "BillIK",
      "content": "može li netko reći ispituje li se na bilcu i gradivo optimizacije ili samo povratni modeli?",
      "votes": {
        "upvoters": [
          "at5611"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296805": {
      "poster": "indythedog",
      "content": "@\"Jaster111\"#p296711 Da, bar sam ja tako stavio\n\nStavio sam da se u konstruktoru NLPDataseta predaje rječnik koji se želi koristiti za pretvaranje riječi u indekse\n\nI onda svaki put kad pozovem __getitem__(self, index), dohvaćam traženu rečenicu iz dataseta, sve njene riječi pretvaram u (int) brojeve koristeći rječnik i vraćam tu rečenicu koja je sad u obliku brojeva.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296806": {
      "poster": "indythedog",
      "content": "@\"Jaster111\"#p296779 Dataloader koristiš za iteriranje po podacima za treniranje/testiranje, tipa ovako ![](assets/2022-05-16/00023.png)\n\nSamo onda ne smiješ zaboraviti da ti je izlaz iz dataloadera x_ind, tj. rečenica u kojoj su riječi zapisane preko njihovih indeksa u rječniku, dakle ovako nešto:\n\nx_ind = [28 1 388 499 7876...], a ti želiš da ti svaka riječ u rečenici bude zapisana kao 300-dimenzionalni vektor. Te vektore su ti oni već dali u onoj glove_embeddings datoteci, i znači tamo za svaku riječ iz rječnika imaš zapisan njen 300-dim vektor iliti embedding. Tu embedding matricu napraviš kako su opisali, obavezno koristeći onaj pytorch wrapper. \n\nI jednom kad imaš embedding matricu (konstruriraš je neovisno o modelu, te ju predaš kao parametar modela prilikom inicijalizacije), onaj x_ind od maloprije pretvaraš u njegovu vektorsku reprezentaciju x_vec koristeći embedding matricu pomoću ovog poziva: ![](assets/2022-05-16/00024.png)\n\nI sad ti je x_vec u obliku u kojem ga možeš slobodno ubaciti u RNN ćeliju, i tjt.",
      "votes": {
        "upvoters": [
          "wesley"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296811": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"Jaster111\"#p296779 \n\n@\"indythedog\"#p296806 \n\nDodatno u vezi embedding matrice, \n\nosim pretvorbe riječi direktno preko embedding matrice, torch nudi Embedding sloj koji se stavlja na početak mreže. Njemu na ulaz daš index riječi, a on ti vrati vektorsku reprezentaciju. Embedding layer možeš inicijalizirati nekom razdiobom ili mu možeš u konstruktor dati pretrenirane reprezentacije. Nije ga loše koristit jer možeš tijekom učenja ažurirati embedding matricu, pa tako dodatno ispoliraš embeddinge za konkretan dataset. \n\novako ga se inicijalizira\n>self.embedding = nn.Embedding.from_pretrained(embeddings=embeddings, freeze=True)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296814": {
      "poster": "Tompa007 (𝐓𝐇𝐄 𝐒𝐄𝐂𝐑𝐄𝐓 - 𝐂𝐋𝐔𝐁)",
      "content": "Jel smijemo drugi zadatak model preko kerasa slozit ?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296847": {
      "poster": "sheriffHorsey",
      "content": "Jel imao netko problem da je dio vrijednosti koje izvuce iz stoi dictionaryja krivo? Dobivam ove vrijednosti:\n\n      Numericalized text: [189, 2, 713, 7, 129, 358, 144]",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296849": {
      "poster": "sheriffHorsey",
      "content": "@\"sheriffHorsey\"#p296847 Idiote maloumni gleda se poredak iz ulazne datoteke",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Emma63194",
          "bodilyfluids (Dragi prijatelj strojnog učenja)",
          "paradizot (debeli gmaz)",
          "steker",
          "wesley"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296890": {
      "poster": "DoktorKanye",
      "content": "jel moze netko pokazati kako su napisali RNN razred, meni bez obzira koji cell koristim ispadaju slicni rezultati",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296898": {
      "poster": "Tompa007 (𝐓𝐇𝐄 𝐒𝐄𝐂𝐑𝐄𝐓 - 𝐂𝐋𝐔𝐁)",
      "content": "Po epohama mi pada accuracy modela, neznam di sam mogo prenaucit model, ima neko mozda ideju il je imo slican problem ?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296899": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"▅ ▆ ▇ █ 👽 𝒟𝐸𝒱𝐼𝒯𝓞 👽 █ ▇ ▆ ▅\"#p296898 \n\nMozda koristis vokabular naucen na validation setu. Tamo se negative pojavi cesce pa mu je index 0, pa ti model vrati suprotnu predikciju",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296900": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"DoktorKanye\"#p296890 ma to je ok, nemoj se zamarat... Ako ti je accuracy slican onome sto su oni koristili its fine, barem je tako meni bilo na usmenom\n\nMeni su sve celije isto davale slicne rezultate u 3. zadatku",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296903": {
      "poster": "Tompa007 (𝐓𝐇𝐄 𝐒𝐄𝐂𝐑𝐄𝐓 - 𝐂𝐋𝐔𝐁)",
      "content": "@\"Precious Bodily Fluids\"#p296899 Koristim vokabular iz train seta generiran :/",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296915": {
      "poster": "branimir1999",
      "content": "Meni je na baseline modelu i na LSTM modelu pocetni accuracy oko 73% pa konvergira na otprilike 78%. Je li itko zna u cemu bi mogao biti problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296916": {
      "poster": "sheriffHorsey",
      "content": "Ima li netko tko ima termin u četvrtak u 13:30 da bi se htio mijenjat za srijedu u 14? Malo su me zajebali su me s drugim labosima početkom tjedna pa mislim da neću stić riješit ovo, a nadoknadu sam nažalost već potrošio",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296922": {
      "poster": "indythedog",
      "content": "@\"sheriffHorsey\"#p296916 Posalji mail Petri Bevandic, postoji sansa da ce ti izac u susret tj. da ti da kasniji termin",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296923": {
      "poster": "sheriffHorsey",
      "content": "@\"indythedog\"#p296922 probao sam, kaze da je sve popunjeno u cetvrtak",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296945": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@\"branimir1999\"#p296915 Što misliš da je tu problem? Očekuješ oko 80% accuracy",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296956": {
      "poster": "Zero",
      "content": "Jel možemo koristiti pandas u prvom zadatku?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296958": {
      "poster": "branimir1999",
      "content": "@\"Mićo vladar ženskog tijela\"#p296945 Njihova preciznost krece od niske pa prelazi moju pa zbog toga naslucujem da mi je mozda nesto krivo. Dakle, moj baseline model i sve tri vrste celije imaju skoro pa iste performance. Ne znam je li tako treba biti, ali cini mi se cudno",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296967": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"branimir1999\"#p296958 dobro je sve",
      "votes": {
        "upvoters": [
          "branimir1999"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296970": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@\"branimir1999\"#p296958 Meni je isto ispalo da imaju slične performanse, tako vjv i treba biti\n\nIma tu razloga zašto je to tako, najelementarniji je taj da povratni modeli ne mogu baš najbolje modelirati distribucije čistog teksta, a ovo da ti je već bolje na početku se može i objasniti boljom inicijalizacijom i slabom mogućnosti učenja tih modela. Isto tako glove embeddinzi su već odradili većinu posla u smislu reprezentacije riječi, što onda mreža ne treba učiti. Kod CNN-ova treba za te stvari dulje jer niste koristili nikakve predtrenirane značajke kao npr. iz Resnetova, s kojim bi vam isto MNIST i CIFAR bili riješeni u par epoha.\n\nAko sumnjaš uvijek možeš izvrtiti evaluaciju nekoliko puta za nanovo inicijalizirani model, a ako dobiješ visoki perf nakon 1. epohe, to nije ništa previše zabrinjavajuće - ja npr. u svojim rezultatima vidim 70-75% acc nakon 1. epohe. Meni je razlog za to prilično očit - koristio sam `lr=3e-4`, koji će brže konvergirati od njihovog `lr=1e-4`. Ne znam jel je i tako kod tebe.",
      "votes": {
        "upvoters": [
          "branimir1999"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297001": {
      "poster": "Jaster111",
      "content": "Jel netko imao problem da mu se tokom treniranja u drugom zadatku loss ne smanjuje konzistentno? Cijelo vrijeme mi divergira i skače.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297019": {
      "poster": "yurnero",
      "content": "@\"Jaster111\"#p297001 Možda nije vezano al jel učiš gradijente embedding matrice, tj. jel ti freeze=False? Meni je valid accuracy plesa gore-dole dok nisam to stavia, nakon čega dobijam nekakav steady rast kroz epohe. Opet možda sam u krivu pa nek me iskusniji kolege isprave :)",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297025": {
      "poster": "at5611",
      "content": "Koliko detaljno gledaju rezultate testiranja hiperparametara iz 4. zadatka pri usmenom ispitivanju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297026": {
      "poster": "Ryder (Pepper)",
      "content": "Može li netko ako je imao napisati pitanja sa blica",
      "votes": {
        "upvoters": [
          "Tinx (pingvin)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297031": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"at5611\"#p297025 nisam radio 4. zadatak ni u pola detaljno kako je trebalo i asistent mi nije skidao bodove",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Jaster111",
          "Lyras",
          "at5611",
          "indythedog"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297042": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@\"Jaster111\"#p297001 Nije nužno krivo da loss ide gore dolje, provjeri val accuracy. Loss je samo aproksimacija performansi, ne nužno i prava slika",
      "votes": {
        "upvoters": [
          "Jaster111",
          "bodilyfluids (Dragi prijatelj strojnog učenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297089": {
      "poster": "Jaster111",
      "content": "Labos danas u 9\n\n**Blic**:\n\nGenerano ja sam dobio 5 pitanja direktno vezanih na labos tako da ako ste napravili sve, bit ce vam jednostavno. Ostatak pitanja se svodio na poznavanje RNN arhitektura. Nabrojat cu par ovako iz glave\n1. Koji smo optimizer koristili u labosu (adam)\n2. Koji od navedenih tokena se pojavljuju u labosu (pad i unk)\n3. Koju smo funkciju pogreske koristili u labosu (cross entropy)\n4. Kolko parametara ima rnn celija ako nam je poznato bla bla bla\n5. Formula za rnn (to je ono tanh(Whh * h[t-1] ... ))\n\nNote: kolega pokraj mene pak nije dobio skoro nista od pitanja vezanih na labos.\n\nUglavnom prođite malo teoriju iza RNNova.\n\nŠto se odgovaranja tiče, asistent me odmah pitao za zakljucke iz 4. Zadatka. Nakon toga me pitao šta smo radili u 3. i postavio pitanje o tome koja je razlika izmedu npr LSTMa i RNNa ili GRUa. Za 2. Zadatak me pitao samo da mu pokazem kakve su performanse baseline modela, i što se 1. Tiče, pitao je samo zašto uopće koristimo one predtrenirane embeddingse.",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ryder (Pepper)",
          "Upforpslone",
          "indythedog",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297096": {
      "poster": "garica",
      "content": "blic cega se sjecam: \n\nkoji se optimizator koristio u vjezbi\n\nkoja je derivacija tangensa hiperbolnog\n\nkoliko parametara ima sljedeca mreza...\n\nkoja se nelinearnost koristi u obicnoj povratnoj mrezi\n\njedno ili dva pitanja s izrazima za gradijente\n\no kojoj matrici ovisi hoce li eksplodirati gradijenti",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ryder (Pepper)",
          "Upforpslone",
          "indythedog",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297097": {
      "poster": "Sinusan",
      "content": "Blic:\n\nFormula za RNN: h(t)=tanh(...)\n\nFormula za LSTM: c(t)=...\n\nBroj parametara ako je poznato...\n\nKoji parametar utječe na eksploziju gradijenata?\n\nJel moguće ostvarit gubitak 0?\n\nDerivacija od tanh (zapisana preko numpya)?\n\nKoji parametar zauzima najviše memorijskog prostora?\n\nKoju funkciju gubitka smo koristili?\n\nPitanja:\n\nProšao kroz zadatke i mjerenja\n\nPitao formulu za RNN.\n\nPitao koji modeli će raditi lošije bez naučenih vektorskih reprezentacija.",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ryder (Pepper)",
          "Upforpslone",
          "indythedog",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297156": {
      "poster": "ppooww (pp)",
      "content": "Koji modeli će raditi lošije (RNN ili potpuno povezani) bez naučenih vektorskih reprezentacija (u odnosu kad imaju vektorske reprezentacije)? Pretpostavljam RNN modeli, ali koji je točan razlog?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297158": {
      "poster": "angello2",
      "content": "@\"pp\"#p297156 meni je ispalo jednako pogorsanje za oba, i to sam reko danas na labosu i rekla je da je to okej",
      "votes": {
        "upvoters": [
          "ppooww (pp)",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297161": {
      "poster": "ppooww (pp)",
      "content": "@\"angello2\"#p297158 Meni je osnovni model ostao jednak (izgubio oko 0.1%), a RNN model mi je izgubio oko 2%. Moguće da je ovisno o inicijalizacijama.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297164": {
      "poster": "sheriffHorsey",
      "content": "pitanja s blica kojih se sjećam:\n\n1) koji parametar uzrokuje eksplodirajući gradijent - ovdje pazite jer je među odgovorima [imath]W_{hh}, W_{hy}[/imath] i samo [imath]W_{hh}[/imath]\n\n2) koji je raspon slike tangensa hiperbolnog\n\n3) zadani su veličina vokabulara, dimenzija ulaza i skrivena dimenzija, koja matrica ima najviše parametara\n\n4) može li se pri treniranju pojaviti <UNK> simbol\n\n5) računanje broja parametara za RNN, ne sjećam se točnih dimenzija\n\n6) koji gubitak je korišten u laboratorijskoj vježbi\n\n7) koji je izraz za ažuriranje skrivenog stanja u RNN\n\n8) koja je derivacija tangensa hiperbolnog",
      "votes": {
        "upvoters": [
          "Ducky",
          "ppooww (pp)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297176": {
      "poster": "indythedog",
      "content": "@\"pp\"#p297156 Ja sam danas imao to pitanje i asistent mi je rekao onaj average pool model - jer fora je u tome što on uzima prosjek vektora, a ako nemaš naučene vektorske reprezentacije, onda su ti vektori slučajni, a prosjek slučajnih vektora je opet slučajni vektor koji nema neko značenje, pa je kao zaključak da baseline modelu više šteti kad nema naučene vektorske reprezentacije",
      "votes": {
        "upvoters": [
          "Upforpslone",
          "WickyWinslow",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
          "ppooww (pp)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297217": {
      "poster": "Daeyarn",
      "content": "3. zadatak, kako se za izlaz mreže gleda klasa? jel se provuce kroz sigmoidu, jel se gleda jel veci od 0 ilii?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297221": {
      "poster": "ppooww (pp)",
      "content": "@\"Daeyarn\"#p297217 Iz pytorch [dokumentacije](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) :\n\n>This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.\n\nZnaci toj funkciji predas izlaz zadnjeg potpuno povezanog sloja i ona provuce taj izlaz kroz sigmoidu i izracuna loss.",
      "votes": {
        "upvoters": [
          "Daeyarn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297223": {
      "poster": "Daeyarn",
      "content": "@\"pp\"#p297221 ok, a kako se izlaz mreze tretira kod evaluacije, koji izlazi su positive a koji negative?\n\nedit: ja sam stavio da izlazi > 0.5 su positive, a drugacije je negative",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297225": {
      "poster": "ppooww (pp)",
      "content": "@\"Daeyarn\"#p297223 positive je 0, a negative 1. barem je meni tako\n\nedit: vjv ovisi o implementaciji, odnosno koje si im indekse dao u vokabularu. ako su ti positive oznaceni s 1 onda je dobro.",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297251": {
      "poster": "ErnestHemingway (Alfetta)",
      "content": "koji je onda na kraju odgovor za eksploziju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "298007": {
      "poster": "GetSchwifty (_2D_)",
      "content": "Jesu jos nekome upisali samo bodove iz teorije?",
      "votes": {
        "upvoters": [
          "Retard00",
          "bodilyfluids (Dragi prijatelj strojnog učenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "298008": {
      "poster": "indythedog",
      "content": "@\"_2D_\"#p298007 Dap, mislim da bodove iz ispitivanja nisu još nikome upisali",
      "votes": {
        "upvoters": [
          "GetSchwifty (_2D_)",
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "300988": {
      "poster": "MarinR",
      "content": "jos nisu upisani bodovi iz ispitivanja?",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Me1 (Me)",
          "Retard00",
          "indythedog"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}