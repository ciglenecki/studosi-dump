{
  "title": "[DUBUCE1] 3. laboratorijska vjeÅ¾ba - 2021/2022",
  "creator": "Jaster111",
  "slug": "dubuce1-3-laboratorijska-vjezba-20212022",
  "tags": [
    "FER",
    "Duboko uÄenje 1",
    "Laboratorijske vjeÅ¾be"
  ],
  "posts": {
    "295431": {
      "poster": "Jaster111",
      "content": "Å to bi ovaj tu frequencies parametar trebao biti?\n\n![](assets/2022-05-10/00006.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295432": {
      "poster": "BillIK",
      "content": "Jel nekome moguÄ‡a zamjena grupa na ferwebu?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295433": {
      "poster": "sheriffHorsey",
      "content": "@\"BillIK\"#p295432 Meni je bila jucer dostupna, ali sad mi nema niceg",
      "votes": {
        "upvoters": [
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295434": {
      "poster": "angello2",
      "content": "@\"Jaster111\"#p295431 dict u kojem su sve rijeci i broj njihovog pojavljivanja u datasetu, znaci oblika (string : int)",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295440": {
      "poster": "Jaster111",
      "content": "@\"angello2\"#p295434 hvala ti",
      "votes": {
        "upvoters": [
          "angello2"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295455": {
      "poster": "BillIK",
      "content": "MoÅ¾e li netko objasniti Å¡to bi trebalo biti sve u razredu NLPDataset? Å to on toÄno prima kao argumente, ako prima i Å¡to bi toÄno ta metoda __getitem__ trebala raditi? Ne kuÅ¾im prima li on kao argument ove naÅ¡e vokabulare ili csv file ili neÅ¡to stoto",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295456": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "> @\"BillIK\"#p295455 MoÅ¾e li netko objasniti Å¡to bi trebalo biti sve u razredu NLPDataset?\n\nNeka reprezentacija dataseta, a koja, ovisi o tebi\n\n> @\"BillIK\"#p295455 Å to on toÄno prima kao argumente\n\nÅ to god isprogramiraÅ¡ da prima, ali trebao bi nekako imati izvor podataka\n\n> @\"BillIK\"#p295455 Å¡to bi toÄno ta metoda getitem trebala raditi?\n\nekvivalent operatora indeksiranja, iliti `operator []`\n\n> @\"BillIK\"#p295455 Ne kuÅ¾im prima li on kao argument ove naÅ¡e vokabulare ili csv file ili neÅ¡to stoto\n\nÅ to god Å¾eliÅ¡ da ima smisla\n\n----\n\nUvijek je najbolje posavjetovati se s dokumentacijom: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html",
      "votes": {
        "upvoters": [
          "BillIK"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "295941": {
      "poster": "mariak (kaiak)",
      "content": "Zna itko koje prezentacije treba proci za labos",
      "votes": {
        "upvoters": [
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296325": {
      "poster": "crocorax",
      "content": "provjerite kalendare, meni su prebacili labos s cetvrtka na utorak bez da su mi javili...",
      "votes": {
        "upvoters": [
          "kix7 (Fish99)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "ErnestHemingway (Alfetta)"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296334": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "2. zadatak\n\nKroz epohe mi train accuracy normalno raste, do cca 95%, a validation accuracy je iz nekog razloga za svaku epohu 50%...\n\nJel itko imao slican problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296339": {
      "poster": "ErnestHemingway (Alfetta)",
      "content": "@\"crocorax\"#p296325 First time?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Daeyarn",
          "Fica (Prof)",
          "InCogNiTo124",
          "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
          "crocorax",
          "sheriffHorsey",
          "steker",
          "wesley"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296342": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "U drugom zadatku dobivam validation accuracy cca. 50% za svaku epohu, a train accuracy raste normalno.\n\nJel imao itko sliÄan problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296345": {
      "poster": "Baksuz",
      "content": "Jel zna netko Å¡to bi trebalo znaÄit \"Pri primjeni saÅ¾imanja usrednjavanjem odmah eliminirajte cijelu vremensku dimenziju (tzv. okno je veliÄine T)\" u drugom zadatku? Kako bi trebala izgledat implementacije tog pooling layera?",
      "votes": {
        "upvoters": [
          "yabk"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296351": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"Baksuz\"#p296345 \n\nKoristeÄ‡i torch.mean po vremenskoj dimenziji. Ulaz u mreÅ¾u je tenzor treÄ‡eg reda (batch, T, embedding). Kad izraÄunaÅ¡ mean dobije se tenzor (batch, embedding), bar sam ja tak rjeÅ¡io",
      "votes": {
        "upvoters": [
          "Baksuz",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296355": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"Precious Bodily Fluids\"#p296342 \n\nnemojte biti ja,\n\nnemojte raditi poseban vokabular za validation dataset",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296381": {
      "poster": "Sinusan",
      "content": "@\"Precious Bodily Fluids\"#p296355 \n\nBio sam ti.\n\nOvaj komentar me spasio.",
      "votes": {
        "upvoters": [
          "bodilyfluids (Dragi prijatelj strojnog uÄenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "InCogNiTo124",
          "steker"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296429": {
      "poster": "indythedog",
      "content": "U  torch.nn.utils.clip_grad_norm_ metodi, Å¡to ste stavili za max_norm parametar?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296430": {
      "poster": "indythedog",
      "content": "@\"indythedog\"#p296429 Nvm, vidim da su u 3. zadatku stavili 0.25",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296442": {
      "poster": "indythedog",
      "content": "Ima netko da mu u 2. ispada toÄnost 1.0 na valid/test setu? Nekako nemam osjeÄ‡aj da je to baÅ¡ dobro haha",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296482": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "koliko vam se vrti 3. zadatak jedna epoha na testu, ak ste na CPU?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296507": {
      "poster": "Tompa007 (ğ“ğ‡ğ„ ğ’ğ„ğ‚ğ‘ğ„ğ“ - ğ‚ğ‹ğ”ğ)",
      "content": "Koje sve preze ulaze za ovaj labos ?",
      "votes": {
        "upvoters": [
          "Ducky",
          "Krpa1 (Janez)"
        ],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296690": {
      "poster": "miss_anthropocene (neunist.iva)",
      "content": "```\ndef collate_fn(batch):\n    texts, labels = zip(*batch)\n    lengths = torch.tensor([len(text) for text in texts]) \n    return texts, labels, lengths\n\n```\njel zna tko kak fixati error **TypeError: len() of a 0-d tensor** u ovoj funkciji?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296697": {
      "poster": "neksi (filip)",
      "content": "Å to je bilo na blicu?",
      "votes": {
        "upvoters": [
          "Retard00",
          "Valentino",
          "indythedog",
          "kix7 (Fish99)",
          "miss_anthropocene (neunist.iva)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296698": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"Kernel Panic\"#p296690 Jel radiÅ¡ negdje squeeze? moÅ¾da je povezano s tim. \n\nMislim da error nema veze s collate_fn, nego s  necim unutar unutar NLPDataseta",
      "votes": {
        "upvoters": [
          "miss_anthropocene (neunist.iva)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296711": {
      "poster": "Jaster111",
      "content": "Jel bi mi onda za override getitem metode zapravo trebali u NLPDataset ubacit Vocab? Ne kuÅ¾im, Äini mi se to sve dosta redundantno.",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Fica (Prof)",
          "at5611"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296779": {
      "poster": "Jaster111",
      "content": "Ima netko kakav cheat sheet za ovaj 2. zadatak? Å ta mi Å¡aljemo gdje i Å¡ta se sa Äime radi? Kako koristimo u svemu tome dataloader, a kako embeddingse?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296789": {
      "poster": "BillIK",
      "content": "moÅ¾e li netko reÄ‡i ispituje li se na bilcu i gradivo optimizacije ili samo povratni modeli?",
      "votes": {
        "upvoters": [
          "at5611"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296805": {
      "poster": "indythedog",
      "content": "@\"Jaster111\"#p296711 Da, bar sam ja tako stavio\n\nStavio sam da se u konstruktoru NLPDataseta predaje rjeÄnik koji se Å¾eli koristiti za pretvaranje rijeÄi u indekse\n\nI onda svaki put kad pozovem __getitem__(self, index), dohvaÄ‡am traÅ¾enu reÄenicu iz dataseta, sve njene rijeÄi pretvaram u (int) brojeve koristeÄ‡i rjeÄnik i vraÄ‡am tu reÄenicu koja je sad u obliku brojeva.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296806": {
      "poster": "indythedog",
      "content": "@\"Jaster111\"#p296779 Dataloader koristiÅ¡ za iteriranje po podacima za treniranje/testiranje, tipa ovako ![](assets/2022-05-16/00023.png)\n\nSamo onda ne smijeÅ¡ zaboraviti da ti je izlaz iz dataloadera x_ind, tj. reÄenica u kojoj su rijeÄi zapisane preko njihovih indeksa u rjeÄniku, dakle ovako neÅ¡to:\n\nx_ind = [28 1 388 499 7876...], a ti Å¾eliÅ¡ da ti svaka rijeÄ u reÄenici bude zapisana kao 300-dimenzionalni vektor. Te vektore su ti oni veÄ‡ dali u onoj glove_embeddings datoteci, i znaÄi tamo za svaku rijeÄ iz rjeÄnika imaÅ¡ zapisan njen 300-dim vektor iliti embedding. Tu embedding matricu napraviÅ¡ kako su opisali, obavezno koristeÄ‡i onaj pytorch wrapper. \n\nI jednom kad imaÅ¡ embedding matricu (konstruriraÅ¡ je neovisno o modelu, te ju predaÅ¡ kao parametar modela prilikom inicijalizacije), onaj x_ind od maloprije pretvaraÅ¡ u njegovu vektorsku reprezentaciju x_vec koristeÄ‡i embedding matricu pomoÄ‡u ovog poziva: ![](assets/2022-05-16/00024.png)\n\nI sad ti je x_vec u obliku u kojem ga moÅ¾eÅ¡ slobodno ubaciti u RNN Ä‡eliju, i tjt.",
      "votes": {
        "upvoters": [
          "wesley"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296811": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"Jaster111\"#p296779 \n\n@\"indythedog\"#p296806 \n\nDodatno u vezi embedding matrice, \n\nosim pretvorbe rijeÄi direktno preko embedding matrice, torch nudi Embedding sloj koji se stavlja na poÄetak mreÅ¾e. Njemu na ulaz daÅ¡ index rijeÄi, a on ti vrati vektorsku reprezentaciju. Embedding layer moÅ¾eÅ¡ inicijalizirati nekom razdiobom ili mu moÅ¾eÅ¡ u konstruktor dati pretrenirane reprezentacije. Nije ga loÅ¡e koristit jer moÅ¾eÅ¡ tijekom uÄenja aÅ¾urirati embedding matricu, pa tako dodatno ispoliraÅ¡ embeddinge za konkretan dataset. \n\novako ga se inicijalizira\n>self.embedding = nn.Embedding.from_pretrained(embeddings=embeddings, freeze=True)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296814": {
      "poster": "Tompa007 (ğ“ğ‡ğ„ ğ’ğ„ğ‚ğ‘ğ„ğ“ - ğ‚ğ‹ğ”ğ)",
      "content": "Jel smijemo drugi zadatak model preko kerasa slozit ?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296847": {
      "poster": "sheriffHorsey",
      "content": "Jel imao netko problem da je dio vrijednosti koje izvuce iz stoi dictionaryja krivo? Dobivam ove vrijednosti:\n\n      Numericalized text: [189, 2, 713, 7, 129, 358, 144]",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296849": {
      "poster": "sheriffHorsey",
      "content": "@\"sheriffHorsey\"#p296847 Idiote maloumni gleda se poredak iz ulazne datoteke",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [
          "Emma63194",
          "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
          "paradizot (debeli gmaz)",
          "steker",
          "wesley"
        ],
        "wtf": [],
        "tuga": []
      }
    },
    "296890": {
      "poster": "DoktorKanye",
      "content": "jel moze netko pokazati kako su napisali RNN razred, meni bez obzira koji cell koristim ispadaju slicni rezultati",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296898": {
      "poster": "Tompa007 (ğ“ğ‡ğ„ ğ’ğ„ğ‚ğ‘ğ„ğ“ - ğ‚ğ‹ğ”ğ)",
      "content": "Po epohama mi pada accuracy modela, neznam di sam mogo prenaucit model, ima neko mozda ideju il je imo slican problem ?",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296899": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"â–… â–† â–‡ â–ˆ ğŸ‘½ ğ’Ÿğ¸ğ’±ğ¼ğ’¯ğ“ ğŸ‘½ â–ˆ â–‡ â–† â–…\"#p296898 \n\nMozda koristis vokabular naucen na validation setu. Tamo se negative pojavi cesce pa mu je index 0, pa ti model vrati suprotnu predikciju",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296900": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"DoktorKanye\"#p296890 ma to je ok, nemoj se zamarat... Ako ti je accuracy slican onome sto su oni koristili its fine, barem je tako meni bilo na usmenom\n\nMeni su sve celije isto davale slicne rezultate u 3. zadatku",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296903": {
      "poster": "Tompa007 (ğ“ğ‡ğ„ ğ’ğ„ğ‚ğ‘ğ„ğ“ - ğ‚ğ‹ğ”ğ)",
      "content": "@\"Precious Bodily Fluids\"#p296899 Koristim vokabular iz train seta generiran :/",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "WP_Deva (IdeGas)"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296915": {
      "poster": "branimir1999",
      "content": "Meni je na baseline modelu i na LSTM modelu pocetni accuracy oko 73% pa konvergira na otprilike 78%. Je li itko zna u cemu bi mogao biti problem?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296916": {
      "poster": "sheriffHorsey",
      "content": "Ima li netko tko ima termin u Äetvrtak u 13:30 da bi se htio mijenjat za srijedu u 14? Malo su me zajebali su me s drugim labosima poÄetkom tjedna pa mislim da neÄ‡u stiÄ‡ rijeÅ¡it ovo, a nadoknadu sam naÅ¾alost veÄ‡ potroÅ¡io",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296922": {
      "poster": "indythedog",
      "content": "@\"sheriffHorsey\"#p296916 Posalji mail Petri Bevandic, postoji sansa da ce ti izac u susret tj. da ti da kasniji termin",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296923": {
      "poster": "sheriffHorsey",
      "content": "@\"indythedog\"#p296922 probao sam, kaze da je sve popunjeno u cetvrtak",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296945": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "@\"branimir1999\"#p296915 Å to misliÅ¡ da je tu problem? OÄekujeÅ¡ oko 80% accuracy",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296956": {
      "poster": "Zero",
      "content": "Jel moÅ¾emo koristiti pandas u prvom zadatku?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296958": {
      "poster": "branimir1999",
      "content": "@\"MiÄ‡o vladar Å¾enskog tijela\"#p296945 Njihova preciznost krece od niske pa prelazi moju pa zbog toga naslucujem da mi je mozda nesto krivo. Dakle, moj baseline model i sve tri vrste celije imaju skoro pa iste performance. Ne znam je li tako treba biti, ali cini mi se cudno",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296967": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"branimir1999\"#p296958 dobro je sve",
      "votes": {
        "upvoters": [
          "branimir1999"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "296970": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "@\"branimir1999\"#p296958 Meni je isto ispalo da imaju sliÄne performanse, tako vjv i treba biti\n\nIma tu razloga zaÅ¡to je to tako, najelementarniji je taj da povratni modeli ne mogu baÅ¡ najbolje modelirati distribucije Äistog teksta, a ovo da ti je veÄ‡ bolje na poÄetku se moÅ¾e i objasniti boljom inicijalizacijom i slabom moguÄ‡nosti uÄenja tih modela. Isto tako glove embeddinzi su veÄ‡ odradili veÄ‡inu posla u smislu reprezentacije rijeÄi, Å¡to onda mreÅ¾a ne treba uÄiti. Kod CNN-ova treba za te stvari dulje jer niste koristili nikakve predtrenirane znaÄajke kao npr. iz Resnetova, s kojim bi vam isto MNIST i CIFAR bili rijeÅ¡eni u par epoha.\n\nAko sumnjaÅ¡ uvijek moÅ¾eÅ¡ izvrtiti evaluaciju nekoliko puta za nanovo inicijalizirani model, a ako dobijeÅ¡ visoki perf nakon 1. epohe, to nije niÅ¡ta previÅ¡e zabrinjavajuÄ‡e - ja npr. u svojim rezultatima vidim 70-75% acc nakon 1. epohe. Meni je razlog za to priliÄno oÄit - koristio sam `lr=3e-4`, koji Ä‡e brÅ¾e konvergirati od njihovog `lr=1e-4`. Ne znam jel je i tako kod tebe.",
      "votes": {
        "upvoters": [
          "branimir1999"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297001": {
      "poster": "Jaster111",
      "content": "Jel netko imao problem da mu se tokom treniranja u drugom zadatku loss ne smanjuje konzistentno? Cijelo vrijeme mi divergira i skaÄe.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297019": {
      "poster": "yurnero",
      "content": "@\"Jaster111\"#p297001 MoÅ¾da nije vezano al jel uÄiÅ¡ gradijente embedding matrice, tj. jel ti freeze=False? Meni je valid accuracy plesa gore-dole dok nisam to stavia, nakon Äega dobijam nekakav steady rast kroz epohe. Opet moÅ¾da sam u krivu pa nek me iskusniji kolege isprave :)",
      "votes": {
        "upvoters": [
          "Jaster111"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297025": {
      "poster": "at5611",
      "content": "Koliko detaljno gledaju rezultate testiranja hiperparametara iz 4. zadatka pri usmenom ispitivanju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297026": {
      "poster": "Ryder (Pepper)",
      "content": "MoÅ¾e li netko ako je imao napisati pitanja sa blica",
      "votes": {
        "upvoters": [
          "Tinx (pingvin)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297031": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog uÄenja)",
      "content": "@\"at5611\"#p297025 nisam radio 4. zadatak ni u pola detaljno kako je trebalo i asistent mi nije skidao bodove",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Jaster111",
          "Lyras",
          "at5611",
          "indythedog"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297042": {
      "poster": "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
      "content": "@\"Jaster111\"#p297001 Nije nuÅ¾no krivo da loss ide gore dolje, provjeri val accuracy. Loss je samo aproksimacija performansi, ne nuÅ¾no i prava slika",
      "votes": {
        "upvoters": [
          "Jaster111",
          "bodilyfluids (Dragi prijatelj strojnog uÄenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297089": {
      "poster": "Jaster111",
      "content": "Labos danas u 9\n\n**Blic**:\n\nGenerano ja sam dobio 5 pitanja direktno vezanih na labos tako da ako ste napravili sve, bit ce vam jednostavno. Ostatak pitanja se svodio na poznavanje RNN arhitektura. Nabrojat cu par ovako iz glave\n1. Koji smo optimizer koristili u labosu (adam)\n2. Koji od navedenih tokena se pojavljuju u labosu (pad i unk)\n3. Koju smo funkciju pogreske koristili u labosu (cross entropy)\n4. Kolko parametara ima rnn celija ako nam je poznato bla bla bla\n5. Formula za rnn (to je ono tanh(Whh * h[t-1] ... ))\n\nNote: kolega pokraj mene pak nije dobio skoro nista od pitanja vezanih na labos.\n\nUglavnom proÄ‘ite malo teoriju iza RNNova.\n\nÅ to se odgovaranja tiÄe, asistent me odmah pitao za zakljucke iz 4. Zadatka. Nakon toga me pitao Å¡ta smo radili u 3. i postavio pitanje o tome koja je razlika izmedu npr LSTMa i RNNa ili GRUa. Za 2. Zadatak me pitao samo da mu pokazem kakve su performanse baseline modela, i Å¡to se 1. TiÄe, pitao je samo zaÅ¡to uopÄ‡e koristimo one predtrenirane embeddingse.",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ryder (Pepper)",
          "Upforpslone",
          "indythedog",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297096": {
      "poster": "garica",
      "content": "blic cega se sjecam: \n\nkoji se optimizator koristio u vjezbi\n\nkoja je derivacija tangensa hiperbolnog\n\nkoliko parametara ima sljedeca mreza...\n\nkoja se nelinearnost koristi u obicnoj povratnoj mrezi\n\njedno ili dva pitanja s izrazima za gradijente\n\no kojoj matrici ovisi hoce li eksplodirati gradijenti",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ryder (Pepper)",
          "Upforpslone",
          "indythedog",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297097": {
      "poster": "Sinusan",
      "content": "Blic:\n\nFormula za RNN: h(t)=tanh(...)\n\nFormula za LSTM: c(t)=...\n\nBroj parametara ako je poznato...\n\nKoji parametar utjeÄe na eksploziju gradijenata?\n\nJel moguÄ‡e ostvarit gubitak 0?\n\nDerivacija od tanh (zapisana preko numpya)?\n\nKoji parametar zauzima najviÅ¡e memorijskog prostora?\n\nKoju funkciju gubitka smo koristili?\n\nPitanja:\n\nProÅ¡ao kroz zadatke i mjerenja\n\nPitao formulu za RNN.\n\nPitao koji modeli Ä‡e raditi loÅ¡ije bez nauÄenih vektorskih reprezentacija.",
      "votes": {
        "upvoters": [
          "Ducky",
          "Ryder (Pepper)",
          "Upforpslone",
          "indythedog",
          "neksi (filip)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297156": {
      "poster": "ppooww (pp)",
      "content": "Koji modeli Ä‡e raditi loÅ¡ije (RNN ili potpuno povezani) bez nauÄenih vektorskih reprezentacija (u odnosu kad imaju vektorske reprezentacije)? Pretpostavljam RNN modeli, ali koji je toÄan razlog?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297158": {
      "poster": "angello2",
      "content": "@\"pp\"#p297156 meni je ispalo jednako pogorsanje za oba, i to sam reko danas na labosu i rekla je da je to okej",
      "votes": {
        "upvoters": [
          "ppooww (pp)",
          "sheriffHorsey"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297161": {
      "poster": "ppooww (pp)",
      "content": "@\"angello2\"#p297158 Meni je osnovni model ostao jednak (izgubio oko 0.1%), a RNN model mi je izgubio oko 2%. MoguÄ‡e da je ovisno o inicijalizacijama.",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297164": {
      "poster": "sheriffHorsey",
      "content": "pitanja s blica kojih se sjeÄ‡am:\n\n1) koji parametar uzrokuje eksplodirajuÄ‡i gradijent - ovdje pazite jer je meÄ‘u odgovorima [imath]W_{hh}, W_{hy}[/imath] i samo [imath]W_{hh}[/imath]\n\n2) koji je raspon slike tangensa hiperbolnog\n\n3) zadani su veliÄina vokabulara, dimenzija ulaza i skrivena dimenzija, koja matrica ima najviÅ¡e parametara\n\n4) moÅ¾e li se pri treniranju pojaviti <UNK> simbol\n\n5) raÄunanje broja parametara za RNN, ne sjeÄ‡am se toÄnih dimenzija\n\n6) koji gubitak je koriÅ¡ten u laboratorijskoj vjeÅ¾bi\n\n7) koji je izraz za aÅ¾uriranje skrivenog stanja u RNN\n\n8) koja je derivacija tangensa hiperbolnog",
      "votes": {
        "upvoters": [
          "Ducky",
          "ppooww (pp)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297176": {
      "poster": "indythedog",
      "content": "@\"pp\"#p297156 Ja sam danas imao to pitanje i asistent mi je rekao onaj average pool model - jer fora je u tome Å¡to on uzima prosjek vektora, a ako nemaÅ¡ nauÄene vektorske reprezentacije, onda su ti vektori sluÄajni, a prosjek sluÄajnih vektora je opet sluÄajni vektor koji nema neko znaÄenje, pa je kao zakljuÄak da baseline modelu viÅ¡e Å¡teti kad nema nauÄene vektorske reprezentacije",
      "votes": {
        "upvoters": [
          "Upforpslone",
          "WickyWinslow",
          "micho (MÌµÍ‘Í€ÍÌ©Ì§iÌ¶Ì‚Ì‰ÍÄ‡Ì´Ì¾ÌÌ€ÌoÌ¶Í‚Ì½ÌºÌŸÌ£)",
          "ppooww (pp)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297217": {
      "poster": "Daeyarn",
      "content": "3. zadatak, kako se za izlaz mreÅ¾e gleda klasa? jel se provuce kroz sigmoidu, jel se gleda jel veci od 0 ilii?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297221": {
      "poster": "ppooww (pp)",
      "content": "@\"Daeyarn\"#p297217 Iz pytorch [dokumentacije](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) :\n\n>This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.\n\nZnaci toj funkciji predas izlaz zadnjeg potpuno povezanog sloja i ona provuce taj izlaz kroz sigmoidu i izracuna loss.",
      "votes": {
        "upvoters": [
          "Daeyarn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297223": {
      "poster": "Daeyarn",
      "content": "@\"pp\"#p297221 ok, a kako se izlaz mreze tretira kod evaluacije, koji izlazi su positive a koji negative?\n\nedit: ja sam stavio da izlazi > 0.5 su positive, a drugacije je negative",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297225": {
      "poster": "ppooww (pp)",
      "content": "@\"Daeyarn\"#p297223 positive je 0, a negative 1. barem je meni tako\n\nedit: vjv ovisi o implementaciji, odnosno koje si im indekse dao u vokabularu. ako su ti positive oznaceni s 1 onda je dobro.",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "297251": {
      "poster": "ErnestHemingway (Alfetta)",
      "content": "koji je onda na kraju odgovor za eksploziju?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "298007": {
      "poster": "GetSchwifty (_2D_)",
      "content": "Jesu jos nekome upisali samo bodove iz teorije?",
      "votes": {
        "upvoters": [
          "Retard00",
          "bodilyfluids (Dragi prijatelj strojnog uÄenja)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "298008": {
      "poster": "indythedog",
      "content": "@\"_2D_\"#p298007 Dap, mislim da bodove iz ispitivanja nisu joÅ¡ nikome upisali",
      "votes": {
        "upvoters": [
          "GetSchwifty (_2D_)",
          "Retard00"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "300988": {
      "poster": "MarinR",
      "content": "jos nisu upisani bodovi iz ispitivanja?",
      "votes": {
        "upvoters": [
          "Daeyarn",
          "Me1 (Me)",
          "Retard00",
          "indythedog"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}