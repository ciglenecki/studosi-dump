{
  "title": "[DUBUCE] Gradivo",
  "creator": "neZnamNista",
  "slug": "dubuce-gradivo",
  "tags": [
    "FER",
    "Duboko učenje"
  ],
  "posts": {
    "164047": {
      "poster": "neZnamNista",
      "content": "je li netko zna zasto pycharm ne moze naci im2col_cython?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "164069": {
      "poster": "InCogNiTo124",
      "content": "@neZnamNista#164047 Kako si ga instalirao?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "164082": {
      "poster": "neZnamNista",
      "content": "zabaravio sam pokrenuti naredbu python3 setup_cython.py build_ext --inplace koja rjesava taj problem, piše u dokumentaciji samo što nisam provjerio",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "165681": {
      "poster": "MJ3",
      "content": "jel se cython za python3 treba instalirat na neki drugi način umjesto pip install Cython? jer mi naredba \"python3 setup_cython.py build_ext --inplace\" ne radi za python3, a kad stavim python onda ne može pronaći setup_cython.py",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "165854": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@MJ3#165681 ako koristiš python3, onda vjv i trebaš pip3. Ubuduće najbolje koristiti conda env gdje su python i pip aliasi za python3 i pip3. Isto tako ovo da ne može naći setup je sumnjivo, pripazi da si pozicioniran u pravi folder",
      "votes": {
        "upvoters": [
          "MJ3"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "165983": {
      "poster": "InCogNiTo124",
      "content": "@MJ3#165681 Probaj `python3 -m pip install Cython`",
      "votes": {
        "upvoters": [
          "MJ3",
          "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "166410": {
      "poster": "Yasuke (Bono)",
      "content": "Instalirao sam Cython, ali javlja mi se greška kad pokrenem python setup_cython.py build_ext --inplace.\n\nKaže mi error: Unable to find vcvarsall.bat\n\nJel zna možda neko kako to sredit?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "166470": {
      "poster": "InCogNiTo124",
      "content": "@Yasuke#166410 Jel sigurno instaliras sa pythonom v3 a ne v2?\n\nI provjeri si imas li msv build tools",
      "votes": {
        "upvoters": [
          "Yasuke (Bono)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "166850": {
      "poster": "[deleted]",
      "content": "Jel zna netko objasnit kako izračunati receptivno polje?",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "166866": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@msus#166850 @InCogNiTo124#11191",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "Louverture (Žuti Kišobran)",
          "[deleted]"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "175378": {
      "poster": "member",
      "content": "Zadatak 5.a) MI 2019, profesor kaže da je br. parametara modela 4 za prvi sloj i 4 za treći. Nije mi jasno kako je došao do toga. (u 1.a) zadatku mi je jasno kako se dođe do br. parametara)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "175736": {
      "poster": "login",
      "content": "Jel moze neko objasniti kako bi isao backprop kod konvolucijskih mreža ako za sloj provodimo konvoluciju a da je \n\nstride > 1. U prezentaciji ima nekakva formula al nije mi bas najjasnija",
      "votes": {
        "upvoters": [
          "feel_d_boot (iNut)",
          "member",
          "narval13068 (Dima)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "175956": {
      "poster": "MJ3",
      "content": "![](assets/2021-04-22/00005.png)\n\n![](assets/2021-04-22/00006.png)\n\njel bi se u b) zadatku srednja vrijednost i standardna devijacija trebale računat posebno za dvije mini-grupe pa onda njihov prosjek kao što je navedeno u slajdu? na predavanju je profesor riješio kao da je sve jedna grupa",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "175991": {
      "poster": "tonkec",
      "content": "@MJ3#175956 Kod učenja se koriste pojedini batchevi za izračun srednje vrijednosti i std. devijacije, a kod eksploatacije cijela populacija. Ova notacija iz slajda znači da se prođe kroz sve batcheve i onda izračuna očekivanje srednje vrijednosti i std. devijacije na temelju pojedinih batcheva. \n\nPoledaj u https://arxiv.org/abs/1502.03167.",
      "votes": {
        "upvoters": [
          "MJ3",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176007": {
      "poster": "tonkec",
      "content": "[imath]L = ...[/imath]\n\n[imath]s = w^Th [/imath]\n\nTreba izračunati [imath]\\frac{\\partial L}{\\partial w}[/imath] što je [imath]\\frac{\\partial L}{\\partial s} \\cdot \\frac{\\partial s}{\\partial w}[/imath]\n\nIma neki jednostavan način da se skuži kada treba transponirati ako se derivira [imath]s[/imath] po [imath]w[/imath] ili [imath]h[/imath] ili da samo pripašem pa da dimenzije odgovaraju prethodnoj parcijalnoj derivaciji ovisno o tome što treba izračunati?",
      "votes": {
        "upvoters": [
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176021": {
      "poster": "[deleted]",
      "content": "@tonkec#176007 U matematici je sve dobro definirano, samo su oni pretpostavili da mi to znamo, odnosno da se sjećamo s Matematike 2 (tamo smo bili upoznati s Jakobijanom ...) .\n\nUglavnom, stvar je definirana ovako. Ako imaš funkciju [imath]f : \\mathbb{R^n} \\to \\mathbb{R}^m[/imath], onda je [imath]\\nabla_xf \\in \\mathbb{R}^{m \\times n}[/imath], gdje je [imath]x \\in \\mathbb{R}^n[/imath]. Što ti govori funkcija [imath]f[/imath]? Funkciju [imath]f[/imath] možeš gledati kao [imath]m[/imath] skalarnih funkcija vektorske varijable (što u stvari ona i je upravo to), gdje je tvoja vektorska varijabla upravo iz [imath]\\mathbb{R}^n[/imath].\n\nŠto onda možemo pročitati iz toga da je [imath]\\nabla_xf \\in \\mathbb{R}^{m \\times n}[/imath]. To nam govori da je **redak** matrice jednak sljedećem vektoru: [imath][\\frac{df_i}{x_1} \\ldots \\frac{df_i}{x_n}][/imath] i tako za [imath]m[/imath] redaka, odnosno [imath]i \\in \\{1, \\ldots, m \\}[/imath].\n\nŠto to govori za tvoj slučaj (rekao bi da se radi o binarnoj logističkoj regresiji). Iz izraza se vidi da je [imath]s \\in \\mathbb{R}[/imath], naravno, funkcija gubitka je isto skalarna funkcija, dakle [imath]L \\in \\mathbb{R}[/imath], a [imath]w \\in \\mathbb{R}^d[/imath]. Stoga je [imath]\\frac{dL}{ds} \\in \\mathbb{R}[/imath], a [imath]\\frac{dL}{dw} \\in \\mathbb{R}^{1 \\times d}[/imath].\n\nSada kada to znaš odrediti - dimenzije gradijenata ... - sve ostalo slijedi iz toga.\n\nZa više si pročitaj 5.2 i 5.3. iz [Mathematics for Machine Learning](https://mml-book.github.io/book/mml-book.pdf). Ima 10 stranica i lagano se čita.",
      "votes": {
        "upvoters": [
          "Joji",
          "Louverture (Žuti Kišobran)",
          "login",
          "member",
          "tonkec"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176040": {
      "poster": "Joji",
      "content": "@tonkec#176007 Osim ovog što je @tolecnal#176021 naveo, preporučam i ovaj [dokument](https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf). Spominju se slične stvari, samo što tu imaš i konkretan primjer.",
      "votes": {
        "upvoters": [
          "[deleted]",
          "tonkec"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176061": {
      "poster": "MJ3",
      "content": "@tonkec#175991 meni ovo i dalje znači da se srednja vrijednost i stdev za eksploataciju trebaju računat pomoću srednjih vrijednosti svih pojedinih batcheva i njihovih stdev-a (izračunatih prilikom učenja)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176117": {
      "poster": "narval13068 (Dima)",
      "content": "Jel ima itko link na ispit MI 2019 s konzultacija",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176118": {
      "poster": "Yasuke (Bono)",
      "content": "@narval13068#176117 \n\n[http://www.zemris.fer.hr/~ssegvic/du/exams/mi19.pdf](http://www.zemris.fer.hr/~ssegvic/du/exams/mi19.pdf)",
      "votes": {
        "upvoters": [
          "narval13068 (Dima)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176119": {
      "poster": "peaceko",
      "content": "@Yasuke#176118 \n\nNisam mogao bit na tim konzultacijama gdje se rjesavao MI 2019, ima li itko mozda rjesenja tog ispita?",
      "votes": {
        "upvoters": [
          "[deleted]",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176177": {
      "poster": "member",
      "content": "![](assets/2021-04-22/00018.png)\n\nJel bi mogao netko pokazat kako doć do p jer ne razumijem zašto je WA =  [[-1,1]] tako prikazana? Zašto W nije dimenzija 2xhidden?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176194": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@member#175378 Mislim parametri su ti doslovno napisani, samo ih pobrojiš na papiru 😅",
      "votes": {
        "upvoters": [
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176306": {
      "poster": "Yasuke (Bono)",
      "content": "@peaceko#176119   Ima u temi o predmetu link na snimku auditornih.",
      "votes": {
        "upvoters": [
          "peaceko"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176310": {
      "poster": "Yasuke (Bono)",
      "content": "Iz MI 2016, jel izracunao neko dimenzije slike? Meni ispadne 8x12, al nisam baš siguran da je dobro?\n\n![](assets/2021-04-22/00024.png)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176347": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Yasuke#176310 \n\nPo meni:\n- spljošteni tenzor ima 8 značajki, vidljivo iz W\n- 2x2 max pool reducira 4 značajke u jednu, dakle prije maxpoola je bilo 8*4 = 32 značajke\n- 2 jezgre znači 2 kanala, što znači da su 32 značajke zapravo 16 + 16 značajki, tj. da jedna jezgra obavlja 16 operacija hadamardovog množenja\n- e sad, tu je problem, 16 operacija hadamardovog množenja može biti 1x16, 2x8, 4x4, 8x2 ili 16x1, tak da ima 5 rješenja:\n   - 3 x (3 + 15) = 3 x 18\n   - (3 + 1) x (3 + 7) = 4 x 10\n   - (3 + 3) x (3 + 3) = 6 x 6\n   - (3 + 7) x (3 + 1) = 10 x 4\n   - (3 + 15) x 3 = 18 x 3</LI>\n\nIz ovog b) dijela bi se dalo zaključiti da je riješenje 2., 3., ili 4. ponuđeno, jer 1. i 5. ne može biti zbog dimenzija.",
      "votes": {
        "upvoters": [
          "Yasuke (Bono)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176390": {
      "poster": "antesha",
      "content": "@micho#176347 \n\nNapisano je da su jezgre 3x3 dimenzija, i kako su ih dvije to znači da je svaka od njih proizvela mapu 4x4\n\nšto bi dalje značilo da je je izvorna slika bila 6x6 dimenzije",
      "votes": {
        "upvoters": [
          "Yasuke (Bono)",
          "cotfuse",
          "ls_123 (KimuraKong)",
          "member",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176393": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@antesha#176390 Ne mora biti nužno 4x4 feature mapa, spljošćivanje ti je ubilo informaciju o omjerima visine i širine, može konvolucija proizvesti i 1x16, 2x8, 8x2 i 1x16 feature mape\n\nIako vidim da sam sjebao, 1x16 i 16x1 ne može biti zbog 2x2 maxpoola, al opet, to su ti 3 rješenja.\n\nEDIT: S tim da ak je ovaj max pool s pomakom 1, onda bi dobio da je slika bila sačinjena od 8 značajki po jezgri pa bi praktički moralo biti 2x4 ili 4x2 množenje, tj. 4x6 ili 6x4 slika. Tak da ima puno pitanja za šetače u ovom zadatku.",
      "votes": {
        "upvoters": [
          "Yasuke (Bono)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176462": {
      "poster": "BigD",
      "content": "Što radi konvolucijski sloj ako ima više kanala izlaza nego ulaza? Konkretno MI 2017 zad 4 drugi conv ima 2 ulazna kanala i 1 izlazni i ima 2 jezgre. Ako konvoluira jednu jezgru s jednim ulazom onda nam još uvijek preostaju 2 izlaza. Kako ih pretvoriti u 1 kanal?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176466": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@BigD#176462 Niš posebno, obično matrično množenje\n\nTežine su ti oblika `(out_channels, in_channels, kernel_size, kernel_size)`\n\nAk misliš kak se dogodi `in_channels -> out_channels` transformacija, pa za svaki `out_channel` se feature mape `in_channel`a sumiraju.\n\nZnači u slučaju gdje ti imaš Conv2D(2 in, 1 out, 3x3), imat ćeš 2 jezgre (tj. imat ćeš 1 grupu koja ima 2 kernela). Svaka ta jezgra ide na zaseban kanal ulaza i daje zasebnu mapu značajki. I onda se te mape značajki sumiraju i dobiješ mapu istih dimenzija samo s 1 kanalom, i to ide na izlaz.\n\nEDIT: [Tu ti je to malo slikovitije opisano](https://d2l.ai/chapter_convolutional-neural-networks/channels.html)",
      "votes": {
        "upvoters": [
          "BigD"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176487": {
      "poster": "Koalalica (zaba)",
      "content": "MI 2017./2018. 3. e) zna netko?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176493": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@Koalalica#176487 Micanje softmaxa jedino ne utječe na kapacitet po meni, i to samo zato što je klasifikacijski zadatak.\n\n- ako makneš ReLU, ubila si jedan sloj kapaciteta jer sad imaš ekspresivnost jednog linearnog sloja\n- ako zamijeniš ReLU s npr. tanh, povećat ćeš kapacitet modela\n- ako makneš ijednu matricu ili pomak smanjila si ekspresivnost modela\n    - micanjem matrice si praktički ubila sloj jer se ne može preslikati u (jako) različiti hiperprostor\n    - micanjem pomaka si se pobrinula da ti je sad sve centrirano oko nule u tom sloju</LI>\n\nKad zadatak ne bi bio klasifikacijski, onda bi ti i micanje softmaxa utjecalo na kapacitet, povećalo bi ga. To jest, točnije bi bilo reći da bi ga potencijalno povećalo, a potencijalno smanjilo, ovisno o tome nad kakvim brojkama radiš regresiju. Kapacitet bi ostao isti jedino ako bi radila mapiranje [imath]\\vec{x} \\in R^n \\rightarrow \\vec{y} \\in R^m[/imath] gdje [imath]\\sum{\\vec{y}} = 1[/imath], jer je to upravo ono što softmax radi, pa bi ti se težine samo namještale da se prilagode eksponencijalnoj funkciji.",
      "votes": {
        "upvoters": [
          "Koalalica (zaba)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176499": {
      "poster": "InCogNiTo124",
      "content": "> @micho#176493 ako zamijeniš ReLU s npr. tanh, povećat ćeš kapacitet modela\n\nOtkud ovo? Po meni je isti kapacitet s obje",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176501": {
      "poster": "micho (M̵̧̩͑̀͝î̶͍̉ć̴̝̾́̀o̶̺̟̣͂̽)",
      "content": "@InCogNiTo124#176499 ReLU ubija informaciju u negativnim značajkama, tanh ne\n\nU praksi ćeš imati slične performanse mreže, tanh obično bolje (ali sporiji trening i inference), ali kod tanh jednostavno nemaš mrtve neurone koji ti smanjuju ekspresivnost, sam trebaš paziti na numeričku stabilnost i nestajuće gradijente, što nije vezano uz ekspresivnost.\n\nOvo nije slučaj kod samoregujućih relu varijanti, koje ne uništavaju info u negativi, one su čak po nekim eksperimentima veće ekspresivnosti, al iskreno znam premalo matematike da bih mogao reći jel to istina il ne.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "Koalalica (zaba)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176502": {
      "poster": "[deleted]",
      "content": "@InCogNiTo124#176499 Možda zato što ReLU ima problem dying neurona pa služi kao regularizator. Čime efektirvno smanjuješ kapacitet modela",
      "votes": {
        "upvoters": [
          "InCogNiTo124"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176511": {
      "poster": "[deleted]",
      "content": "@Koalalica#176487 Slažem se s kolegom @micho#176493 . Micanjem softmax-a ćeš na izlazu dobiti nenormalizirane vjerojatnosti, odnosno klasifikacijske mjere. Primjeti, to si imala u prvoj laboratorijskoj vježbi gdje se na ulaz u [CELoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) očekuje upravo nenormalizirane klasifikacijske mjere. Softmax nam samo omogućava da to interpretiramo kao vjerojatnosti i da, budući da imamo one-hot encodirane ispravne klase, iskoristimo cross entropy kao usporedbu dobivene i očekivane distribucije.",
      "votes": {
        "upvoters": [
          "Koalalica (zaba)",
          "moji_prsti_prsti_klize_po_njoj"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "176959": {
      "poster": "moji_prsti_prsti_klize_po_njoj",
      "content": "https://docs.google.com/document/d/1hwdYDL7MHhEIACwH3Mac0fxOlgMYcnWSRawWVvxVBBc/edit#\n\novaj fajl je od prosle godine sakupljeno sve sto se moglo od meduispita i zavrsnih s rjesenjima \n\nmislin da njegovo postojanje nije toliko javno koliko bi tribalo bit hahahaha pa da cisto zato repostan u slucaju da neko ne zna 💀♥",
      "votes": {
        "upvoters": [
          "Fran_- (random_trooper)",
          "InCogNiTo124",
          "Quentin",
          "Yasuke (Bono)",
          "ls_123 (KimuraKong)",
          "neZnamNista",
          "tonkec"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "191947": {
      "poster": "BigD",
      "content": "Je li moramo uopće predavati laboratorijske vježbe ako smo već zadovoljili onaj osnovni prag?",
      "votes": {
        "upvoters": [
          "Masli"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "192080": {
      "poster": "pushPop",
      "content": "Rješavao sam zadatke s ispita iz RNN-a za pripremu za petak. Samo neki od njih su rijeseni u Google docs dokumentu, a ovdje sam rijesio sve koje sam nasao na materijalama i na stranici predmeta. Zamolio bih ako netko moze provjeriti i objasniti mi ako je nesta krivo jer nisam skroz siguran, bio bih zahvalan. I mozda odgovoriti na stvari koje nisam siguran. Hvala!\n\nZI 17.: [http://www.zemris.fer.hr/~ssegvic/du/exams/zi2017.pdf]\n\n5.) **W_hh = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n\nW_hy = [[1, 1, 1]]\n\nb_h = 0\n\nb_o = -2**\n\nZI 18.: [http://www.zemris.fer.hr/~ssegvic/du/exams/zi2018.pdf]\n\n4.) **h_max = 6**\n\ndim(W_hh) = h x h\n\ndim(W_xh) = h x V (**dimenzija ulaza x = velicina vokabulara V - ovo nisam bas siguran?**)\n\ndim(W_hy) = h x h (**dimenzija izlaza y = dimenzija skrivenog sloja h - ovo nisam bas siguran?**)\n\n5.) **W_xh = 4\n\nW_hh = 0.5\n\nb_h = -4**\n\nZIM. ROK 16/17 (materijali dubuce/ispiti/rokovi):\n\n4.) **dim(W_hh) = 200 x 200**\n\n**dim(W_xh) = 200 x 80** (-> **isto kao gore - je li dim(x) = V (velicina vokabulara)?**)\n\n**dim(W_hy) = 200 x 200** (-> **isto kao gore - je li dim(y) = h?**)\n\n**dim(b_h) = 200**\n\n**dim(b_o) = 200** (-> **je li dim(y) = h?**)\n\n5.) **W_xh = [[-1, 0], [0, -1]]\n\nW_hy = [[-1, 0], [0, -1]]\n\nb_h = 0\n\nb_o = 0**\n\nZI 20: [http://www.zemris.fer.hr/~ssegvic/du/exams/zi2020.pdf]\n\n4.) **broj parametara = 5 204 000**\n- **je li dim(x) = 300?**\n- **je li y = h?**\n\n5.) **h(2) = [0.745, 0.558]**\n\nmedjukorak: h(1) = [4/5, 1/3]",
      "votes": {
        "upvoters": [
          "JustinCase",
          "Quentin",
          "korisnik_studosa (wildcard)",
          "ls_123 (KimuraKong)",
          "member",
          "orange",
          "tre_besty (luk)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "192691": {
      "poster": "pushPop",
      "content": "@pushPop#192080 \n\nSam sebi odgovaram jer sam neke stvari ispravio (ne vidim vise opciju editiranja prethodnog posta). Jos nisam siguran oko **boldanih** stvari. Hvala.\n\nZIM. ROK 16/17 (materijali dubuce/ispiti/rokovi):\n\n4.) dim(W_hh) = 200 × 200\n\ndim(W_xh) = 200 × 80\n\ndim(W_hy) = 80 × 200\n\ndim(b_h) = 200\n\ndim(b_o) = 80\n\n5.) **W_xh = [[-1, 0], [0, -1]]\n\nW_hy = [[-1, 0], [0, -1]]\n\nb_h = 0\n\nb_o = 0**\n\nZI 20: [http://www.zemris.fer.hr/~ssegvic/du/exams/zi2020.pdf]\n\n4.) broj parametara = 3 604 000\n\n5.) **h(2) = [0.745, 0.558]**\n\nmedjukorak: h(1) = [⅘, ⅓]\n\nZI 17.: [http://www.zemris.fer.hr/~ssegvic/du/exams/zi2017.pdf]\n\n5.) W_hh = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n\nW_hy = [[1, 1, 1]]\n\nb_h = 0\n\nb_o = -2\n\nf_activ = min(x, 1)\n\nZI 18.: [http://www.zemris.fer.hr/~ssegvic/du/exams/zi2018.pdf]\n\n4.) h_max = 6\n\ndim(W_hh) = h x h\n\ndim(W_xh) = h x V = h x 10\n\ndim(W_hy) = V x h = 10 x h\n\n5.) W_xh = 4\n\nW_hh = 0.5\n\nb_h = -4",
      "votes": {
        "upvoters": [
          "Vrba",
          "member",
          "tre_besty (luk)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "193875": {
      "poster": "MJ3",
      "content": "@pushPop#192691 ZIM. ROK 16/17 zadatak 4 - zar nije dim(W_xh) = 200x1 i dim(W_hy)=1x200 pa onda i b_o=1? u zadatku piše \"iz laboratorijske vježbe\", pa mislim da je to binarna klasifikacija. a i parametri su dijeljeni pa ne znam kako bi išta ovisilo o veličini vokabulara",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "193887": {
      "poster": "cotfuse",
      "content": "@MJ3#193875 Kaze ti da je problem jezicnog modeliranja, sto znaci da imas seq2seq model, odnosno i ulaz ti je sekvenca rijeci i izlaz ti je sekvenca rijeci, sto znaci da se predvidja koja rijec iz vokabulara je izlaz, pa su tezine za izlazni dio 80x200",
      "votes": {
        "upvoters": [
          "MJ3"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "196897": {
      "poster": "login",
      "content": "Ekipa od prosle godine, jel ima kakva dobra alternativa za predavanje o generativnim modelima? Ova sluzbena predavanja mi ne sjedaju najbolje pa me zanima jel ima nes a da pokriva sve sto moramo znati",
      "votes": {
        "upvoters": [
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "196920": {
      "poster": "InCogNiTo124",
      "content": "@login#196897 Ne bas ://\n\nGanove mozes tu dobro naucit http://d2l.ai/chapter_generative-adversarial-networks/gan.html ili cak iz originalnog papera\n\nAutoencoderi i VAE mozes nac videe online ili, opet, originalni paper\n\nA sa boltzmannovim strojem neka ti bog pomogne xD",
      "votes": {
        "upvoters": [
          "login"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": [
          "Fran_- (random_trooper)",
          "login"
        ]
      }
    },
    "208297": {
      "poster": "member",
      "content": "ZI 19/20:  \"Razmatramo dvoslojni LSTM s dimenzijom skrivenog stanja500te dimenzijom ulaznih repre-zentacija prvog sloja300. Odredite ukupan broj parametara navedene mreže.\"\n\nJel  (500 * 500 + 300 * 500 + 500) * 4?\n\n(4 zbog  f, i, c kapa, o)",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208344": {
      "poster": "MJ3",
      "content": "@member#208297 ja mislim ovako: 4*(300 * 500 + 500 + (500 * 500+500) * 2), gdje se zadnja zagrada odnosi na dva sloja koji imaju različite parametre",
      "votes": {
        "upvoters": [
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208808": {
      "poster": "Ziher",
      "content": "Moze onda pomoc oko tih formula za receptivno polje? Dok se racunalo na MI, rijesio sam na nacin na koji sam shvatio (iz onih Segvicevih videa gdje rijesava zadatke) i dok sam se javio za uvide, samo su mi rekli da je krivo :/",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208818": {
      "poster": "Rasa",
      "content": "Zna li itko kako se racuna derivacija loss-a po out-u za GAN? Kako racunamo dva out-a, za D(x) i D(G(z)) zbunjujuce je, a ako racunam derivaciju L-a po G(z), ispada mi krivo...",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208848": {
      "poster": "Vrba",
      "content": "![](assets/2021-06-17/00025.png)\n\n![](assets/2021-06-17/00026.png)\n\nJel zna netko tocne odgovore?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208879": {
      "poster": "member",
      "content": "@Vrba#208848 1a, 2d, 3a?, 4a, 5c, 6c, 7b, 8b?, 9a, 10d",
      "votes": {
        "upvoters": [
          "Vrba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208889": {
      "poster": "Vrba",
      "content": "@member#208879 ![](assets/2021-06-17/00028.png)\n\npo docu je 3. b",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208914": {
      "poster": "DodgeCharger",
      "content": "@Vrba#208889 Možeš molim te poslat link od tog doca?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208925": {
      "poster": "Vrba",
      "content": "@DodgeCharger#208914 https://docs.google.com/document/d/1hwdYDL7MHhEIACwH3Mac0fxOlgMYcnWSRawWVvxVBBc/edit",
      "votes": {
        "upvoters": [
          "DodgeCharger"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208953": {
      "poster": "Rasa",
      "content": "@Rasa#208818 dakle skuzila sam, ako ikog drugog zanima: racuna se prvo backpropagation za real data i onda za fake data, ti se gradijenti zbroje pa se onda tek update-aju parametri diskriminatora",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "member"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208964": {
      "poster": "Solaire",
      "content": "@MJ3#208344 500 u drugoj zagradi je jedan viška ja mislim",
      "votes": {
        "upvoters": [],
        "downvoters": [
          "steker"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208968": {
      "poster": "MJ3",
      "content": "@Solaire#208964 da istina",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208969": {
      "poster": "member",
      "content": "@pushPop#192691 Kako si došao do br. param = 3604000 ,  ZI 20?",
      "votes": {
        "upvoters": [
          "danko (nerim)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208975": {
      "poster": "danko (nerim)",
      "content": "@Ziher#208808 \n\npočetno za ulaz : rf = 1; f = 1\n\nkod konvolucije i poola : rf = rf +(k-1)*f ;\n\nf=f*s\n\npotpuno povezani slojevi: cijela slika\n\nnelinearne aktivacije: nema promjene\n\nflatten: nema promjene",
      "votes": {
        "upvoters": [
          "Ziher",
          "atp0lar (‮ 🏳️‍⚧️‍⃠ 🏳️‍🌈⃠ 🇮🇱⃠at⁭p⁩⁫0⁮lar)"
        ],
        "downvoters": [
          "RogerRoger"
        ]
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "208989": {
      "poster": "Yasuke (Bono)",
      "content": "Jel ima neko postupak za 6. zad iz prošlogodišenjeg završnog?",
      "votes": {
        "upvoters": [
          "frle10 (Frle)",
          "luba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "209078": {
      "poster": "Vrba",
      "content": "@Solaire#208964 Jel mozes objasnit taj zadatak s parametrima 500 i 300?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "209133": {
      "poster": "DodgeCharger",
      "content": "@Vrba#209078 LSTM ćelija ima one svoje 4 funkcije (f, i, c kapica, o) kodnog imena 'fićo'. Svaka ta funkcija ima svoje matrice [imath]W_{hh}[/imath], [imath]W_{xh}[/imath] i [imath]b_h[/imath]. To je ova četvorka u formuli. [imath]W_{hh}[/imath] je veličine 500 x 500. [imath]W_{xh}[/imath] je veličine 300 x 500. Jer imamo dva sloja, imamo i dvije verzije matrice [imath]W_{hh}[/imath] i [imath]b_h[/imath]. To je ova dvojka u formuli.  Tako sam ja to shvatio. Ako je nešto krivo, neka me netko ispravi.",
      "votes": {
        "upvoters": [
          "InCogNiTo124",
          "danko (nerim)"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "209198": {
      "poster": "Rasa",
      "content": "@Yasuke#208989 \n\nhttps://docs.google.com/presentation/d/1HOp14LXrbCYUEZ-BuO1HI8qPhJgWXmGqtV6yx3k12mU/edit#slide=id.gd7fff66912_0_7",
      "votes": {
        "upvoters": [
          "DodgeCharger",
          "Solaire",
          "Watson (112)",
          "Yasuke (Bono)",
          "alfajastog",
          "luba"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "284115": {
      "poster": "steker",
      "content": "Jel valjaju ovi stari videi s jutuba za ucenje dubokog ucenja 1",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "284124": {
      "poster": "bodilyfluids (Dragi prijatelj strojnog učenja)",
      "content": "@\"steker\"#p284115 mozda ne 100% jer mislim da su predavanja bila \"obrnuta ucionica\", al kako god  segvic je karakter i isplati se doc uzivo imo",
      "votes": {
        "upvoters": [
          "Ducky",
          "steker"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [
          "ErnestHemingway (Alfetta)"
        ],
        "tuga": []
      }
    },
    "285496": {
      "poster": "Daeyarn",
      "content": "jel prvi labos 0. vjezba ili 1. vjezba(Osnove dubokih modela, PyTorch, MNIST)?",
      "votes": {
        "upvoters": [],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    },
    "285500": {
      "poster": "indythedog",
      "content": "@\"Daeyarn\"#p285496 1. vjezba je ono što se ispituje na 1. labosu, 0. vježba je neobavezna (ali preporučena) za rješavanje i nigdje se ne predaje",
      "votes": {
        "upvoters": [
          "Daeyarn"
        ],
        "downvoters": []
      },
      "reactions": {
        "haha": [],
        "wtf": [],
        "tuga": []
      }
    }
  }
}